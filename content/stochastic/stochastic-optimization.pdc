---
title: "Prelim: Stochastic optimization"
weight: 01
categories:
  - stochastics
tags:
  - stochastic optimization
  - principle of irrelevant information
---

Let's start with the simplest optimization problem. A decision maker has to
choose an action $u \in \ALPHABET U$. Upon choosing action $u$, the decision
maker incurs a cost $c(u)$. What action should the decision maker pick to
minimize the cost? 

Formally, the above optimization problem may be written as
$$ \begin{equation} \label{eq:static-optimization}
 \min_{u \in \ALPHABET U} c(u).
\end{equation}$$

When the _action space_ $\ALPHABET U$ is finite, say $\ALPHABET U = \{1,
\dots, m\}$, solving the optimization problem \\eqref{eq:static-optimization} is straight-forward:
enumerate the cost of all possible actions, i.e., enumerate the set 
$C = \{ c(u) : u \in \ALPHABET U \}$ and find the smallest element. 

When the action space $\ALPHABET U$ is continuous, say a compact subset of a
Euclidean space, solving the optimization problem
\\eqref{eq:static-optimization} is conceptually
straight-forward only when the cost function $c$ satisfies some regularity
conditions. For example, when $c$ is convex, the optimal action can be
obtained for solving 
$$ \dfrac {d c(u) }{ du } = 0. $$

---

Now we consider optimization problem with randomness. The simplest instance
with randomness is as follows. A decision maker has to choose an action $u \in
\ALPHABET U$. Upon choosing action $u$, the decision maker incurs a cost
$c(u,W)$, where $W \in \ALPHABET W$ is a random variable with known
probability distribution. We assume that the decision maker is _risk neutral_
and, therefore, wants to minimize $\EXP[ c(u, W) ]$, where the expectation is
with respect to the random variable $W$. 

Formally, the above optimization problem may be written as
$$\begin{equation} \label{eq:stochastic-optimization-1}
  \min_{u \in \ALPHABET U} \EXP[ c(u, W) ]. 
\end{equation}$$

Define $J(u) = \EXP[ c(u, W) ]$. Then
Problem \\eqref{eq:stochastic-optimization-1} is conceptually the same as
Problem \\eqref{eq:static-optimization} with the cost function $J(u)$.
Numerically, Problem \\eqref{eq:stochastic-optimization-1} is more
difficult because computing $J(u)$ involves evaluating an expectation. 

---

In the stochastic optimization problems which we considered above, the
decision maker had no information when it took a decision. In many situations,
the decision maker has some information, which is captured by the following
model. Suppose $\ALPHABET
X$, $\ALPHABET U$, $\ALPHABET W$ are finite sets and let $X \in \ALPHABET X$
and $W \in \ALPHABET W$ be random variables defined on a common probability
space. A decision maker observes the realization of $X$ and chooses an
action $U \in \ALPHABET U$ according to a _decison rule_ $g$, i.e.,
$$ U = g(X) $$
and incurs a cost
$$J(g) = \EXP[ c(X, g(X), W) ],$$
where the expectation is taken with respect to the joint probability
distribution of $(X,W)$. 

::: proclaim :::
**The basic stochastic optimization problem** is
\begin{equation} \label{eq:basic}
  \min_{g} \EXP[ c(X, g(X), W) ] 
\end{equation}
i.e., choose a _function_ $g$ to minimize the _functional_ $J(g)$. 
:::

Problem \\ref{eq:basic} can be interpreted as follows. Before the system starts
running, the decision maker wants to pick a policy $g$ to determine an action
for each realization of his observation $X$. What policy should he pick to
minimize the expected cost?

Since we assume $\ALPHABET X$ and $\ALPHABET U$ are finite sets, there are
finite number of functions from $\ALPHABET X$ to $\ALPHABET U$. So, in
principle, we can view it as an instance of
Problem \\eqref{eq:static-optimization} and solve it as follows: for each
policy $g$ compute $J(g)$ and then pick the policy $g$ with the smallest
expected cost. 

Such an _exhaustive search_ is not satisfying for two reasons. First, it has a
high computational cost. There are $| \ALPHABET U |^{| \ALPHABET X |}$
policies and, for each policy, we have to evaluate an expectation, which can
be expensive. Second, the above enumeration procedure does not work when
$\ALPHABET X$ or $\ALPHABET U$ are continuous sets.

There is an alternative way of viewing the problem that simplifies it
considerably. Instead of viewing the optimization problem before the system
starts running, imagine that the decision maker waits until he sees the
realization $x$ of $X$. He then asks what action $u$ should he take to
minimize the expected _conditional_ cost $\EXP[ c(x,u, W) | X = x]$, i.e., he
considers the problem

\begin{equation} \label{eq:cond-1}
  \min_{u \in \ALPHABET U} \EXP[ c(x,u,W) | X = x].
\end{equation}

Thus, we have reduced a functional optimization problem
(Problem \\ref{eq:basic}) to a collection of parameter optimization problems
(Problem \\ref{eq:cond-1}): one for each possible of $x$. 

Now define
$$ \begin{equation} \label{eq:cond}
  g^*(x) = \arg \min_{u \in \ALPHABET U} \EXP[ c(x,u, W) | X = x]
\end{equation} $$
where ties (in the minimization) are broken arbitrarily. 

::: proclaim :::
**Basic fact.**
The decision rule $g^*$ defined in \\eqref{eq:cond} is optimal for Problem \\ref{eq:basic}.
:::

Remark

:   In the beginning we restricted attention to $\ALPHABET X$, $\ALPHABET U$,
$\ALPHABET W$ being finite. This is to avoid any measurability issues. If
$\ALPHABET X$ and $\ALPHABET U$ are continuous sets, we need to restrict to
_measurable_ $g$ in Problem \\ref{eq:basic} (otherwise the expectation is not
well defined; of course the cost $c$ also has to be measurable). However, it
is not immediately obvious that $g^*$ defined in \\eqref{eq:cond} is measurable.
Conditions that ensure this are known as _measurable selection theorems_. 

#### Proof

Let $g$ be any other decision rule. Then,
$$ \begin{align*}
  \EXP[ c(X, g(X), W) ] &\stackrel{(a)}= \EXP[ \EXP[c(X, g(X), W) | X ] ] \\
  &\stackrel{(b)}\ge \EXP[\EXP[ c(X, g^*(X), W) | X ] ] \\
  &\stackrel{(c)}= \EXP[ c(X, g^*(X), W) ],
\end{align*} $$
where $(a)$ and $(c)$ follow from the law of iterated expectations and $(b)$
follows from the definition of $g^*$ in \\eqref{eq:cond}. 

---

In many scenarios, the decision maker may observe data which is irrelevant for
evaluating performance. In such instances, the decision maker may ignore such
information without affecting performance. Formally, we have the following
result, which is known as **Blackwell's principle of irrelevant information**.

::: highlight :::
Theorem #thm:blackwell

:   Let $\ALPHABET X$, $\ALPHABET Y$, $\ALPHABET W$, and $\ALPHABET U$ be standard Borel
    spaces and $X \in \ALPHABET X$, $Y \in \ALPHABET Y$, $W \in \ALPHABET W$ be random variables
    defined on a common probability space.
    
    A decision maker observes $(X,Y)$ and chooses $U$ to minimize
    $\EXP[c(X,U,W)]$, where $c \colon \ALPHABET X \times \ALPHABET U \times
    \ALPHABET W \to \reals$ is a measurable function.

    **Then, if $W$ is conditionally independent of $Y$ given $X$, then
    there is no loss of optimality in choosing $U$ only as a function
    of $X$.**

    Formally, there exists a $g^* \colon \ALPHABET X \to \ALPHABET U$ such
    that for all $g \colon \ALPHABET X \times \ALPHABET Y \to \ALPHABET U$,
    $$ \EXP[c(X, g^*(X), W)] \le \EXP[ c(X, g(X,Y), W) ]. $$
:::

#### Proof

We prove the result for the case when $\ALPHABET X$, $\ALPHABET Y$, $\ALPHABET
W$, $\ALPHABET U$ are finite. 

Define $$g^*(x) = \arg \min_{u \in \ALPHABET U} \EXP[ c(x,u, W) | X = x]. $$
Then, by construction, for any $x \in \ALPHABET X$ and $u \in \ALPHABET U$, we
have that
$$ \EXP[ c(x, g^*(x), W ) | X = x]  \le \EXP[ c(x,u,W) | X = x]. $$
Hence, for any $g \colon \ALPHABET X \times \ALPHABET Y \to \ALPHABET U$, and
for any $x \in \ALPHABET X$ and $y \in \ALPHABET Y$, we have
$$ \begin{equation} \label{eq:opt}
  \EXP[ c(x, g^*(x), W) | X = x] \le \EXP[ c(x, g(x,y),W) | X = x]. 
\end{equation} $$
The result follows by taking the expectation of both sides of \\eqref{eq:opt}. 

The above proof doesn't work for general Borel spaces because $g^*$ defined
above may not exist (inf vs min) or may not be measurable. See @Blackwell1964
for a formal proof. 


## Exercise

1. Suppose $\ALPHABET X = \{1, 2 \}$, $\ALPHABET U = \{1, 2, 3\}$, and $\ALPHABET
   W = \{1, 2, 3\}$. Let $(X,W)$ be random variables taking values in
   $\ALPHABET X × \ALPHABET W$ with joint distribution $P$ shown below.
    
   $$ P = \MATRIX{ 0.25 & 0.15 & 0.05  \\ 0.30 & 0.10 & 0.15 } $$

   Here the row corresponds to the value of $x$ and the column corresponds to
   the value of $w$. For example $\PR(X=2, W=1) = P_{21} = 0.30$. 

   The cost function $c \colon \ALPHABET X \times \ALPHABET U \times \ALPHABET
   W \to \reals$ is shown below

   $$
    c(\cdot,\cdot,1) = \MATRIX{3 & 5 & 1 \\ 2 & 3 & 1 }, \quad
    c(\cdot,\cdot,2) = \MATRIX{4 & 3 & 1 \\ 1 & 2 & 8 }, \quad
    c(\cdot,\cdot,3) = \MATRIX{1 & 2 & 2 \\ 4 & 1 & 3 }.
   $$

   Here the row corresponds to the value of $x$ and the column corresponds to
   the value of $u$. For example $c(x=1,u=2,w=1) = 5$. 

   Find the policy $g \colon \ALPHABET X \to \ALPHABET U$ that minimizes
   $\EXP[ c(X, g(X), W) ]$. 

2. Suppose $\ALPHABET X = \{1, 2\}$, $\ALPHABET Y = \{1, 2\}$, $\ALPHABET U =
   \{1, 2, 3\}$, and $\ALPHABET W = \{1, 2, 3\}$. Let $(X,Y,W)$ be random
   variables taking values in $\ALPHABET X × \ALPHABET Y × \ALPHABET W$, with
   joint distribution $Q$ shown below.
   $$
    Q_{Y = 1} = \MATRIX{0.15 & 0.10 & 0.00 \\ 0.15 & 0.05 & 0.10}
    \qquad
    Q_{Y = 2} = \MATRIX{0.10 & 0.05 & 0.05 \\ 0.15 & 0.05 & 0.05}
   $$
   For a fixed value of $y$, the row corresponds to the value of $x$ and the
   column corresponds to the value of $w$. For example $\PR(X = 1, Y = 1, W =
   3) = 0$.

   The cost function $c \colon \ALPHABET X × \ALPHABET U × \ALPHABET W \to
   \reals$ is the same as the previous exercise. 

   a. Find the policy $g \colon \ALPHABET X × \ALPHABET Y \to \ALPHABET U$
      that  minimizes $\EXP[c(X, g(X,Y), W)]$. 

   b. Compare the solution with the solution of the previous exercise in view
      of Blackwell's principle of irrelevant information. Clearly
      explain your observations.

## References

Theorem @thm:blackwell is due to @Blackwell1964 in a short 2.5 page paper. A similar
result was used by @Witsenhausen1979 to show the structure of optimal coding
strategies in real-time communication. Also see the [blog post] by Maxim
Ragisnsky.

[blog post]: https://infostructuralist.wordpress.com/2010/11/08/deadly-ninja-weapons-blackwells-principle-of-irrelevant-information/
