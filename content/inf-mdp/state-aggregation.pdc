---
title: "Theory: State aggregation or discretization or quantization"
weight: 11
categories:
  - MDP
tags:
  - infinite horizon
  - discounted cost
  - Lipschitz continuity
  - approximation bounds
  - state aggregation
---


So far, we have studied exact solutions to the dynamic program. When the state
space is large (or possibly continuous), an exact solution is not possible due
to computational limitations. So, we need to look at approximate solutions. 

The simplest form of approximate solution is **state aggregation**, in which
we partition the state space into equivalence classes and assign one state in
each class as a representative element of that class. When the state space is
continuous, the procedure is called **state discretization** or **state
quantization**. We will use the state quantization terminology in these notes.

# System model

Consider an MDP with abstract state space $\ALPHABET S$ and finite action
space $\ALPHABET A$. We denote this MDP by $M = (\ALPHABET S, \ALPHABET A, c,
p)$. For simplicity, we assume that $\ALPHABET S$ is continuous (and compact),
and that the $p$ is the density of the transition kernel. Note that we are
using the term "probability density" in the engineering sense (so, it may be a
combination of a continuous function and delta functions) rather than in the
precise measure theoretic sense (where it is the Radon-Nikodym derivative with
respect to the Lebesque measure).

If exact computations were possible, we can find an optimal solution by
solving the following dynamic program:
$$ V = \mathcal B V, $$
that is
$$ V(s) = 
\min_{a \in \ALPHABET A} \biggl\{ c(s,a) 
+ \gamma \int_{\ALPHABET S} p(s'|s,a) V(s') ds' \biggr\},
\quad \forall s \in \ALPHABET S.
$$
Let $V^*$ denote the optimal value function and $π^*$ denote the optimal
policy.

However, since the state space is continuous, we cannot compute the value
functions exactly. The simplest way to proceed is to discretize or quantize the state
space $\ALPHABET S$. In particular, let $\{\ALPHABET S_1, \dots \ALPHABET
S_n\}$ denote a partition of $\ALPHABET S$ (i.e., $\bigcup_{i=1}^n \ALPHABET
S_i = \ALPHABET S$ and for any $i \neq j$, $\ALPHABET S_i \cap \ALPHABET S_j =
\emptyset$). Pick a representative point $\hat s_i \in \ALPHABET S_i$. We can
think of the "grid points" $\hat {\ALPHABET S} = \{\hat s_1, \dots, \hat
s_n\}$ as quantization of the state space $\ALPHABET S$. In particular, we
think of the quantization function $φ \colon \ALPHABET S \to \hat {\ALPHABET
 S}$ as a quantization function which maps points in $\ALPHABET S_i$ to the
 representative element $\hat s_i$. 


We consider a finite state MDP $\hat M = (\hat {\ALPHABET S}, \ALPHABET A,
\hat c, \hat P)$, where $\hat c$ is the restriction of $c$ onto $\hat
{\ALPHABET S}$, and $\hat P$ is given by $$\hat P(\hat s_j | \hat s_i, a) =
\int_{\ALPHABET S_j} p(s' | \hat s_i, a) dy = p(\ALPHABET S_j | \hat s_i, a).
$$

Suppose $\hat W^* \colon \hat S \to \reals$ be the optimal value function and
$\hat μ^* \colon \hat {\ALPHABET S} \to \ALPHABET A$ be the optimal policy for
the approximate model. Define $W^* \colon \ALPHABET S \to
\reals$ and $μ^* \colon \ALPHABET S \to \reals$ to be piecewise constant
extrapolation of $\hat W^*$ and $\hat μ^*$ from $\hat {\ALPHABET S}$ to
$\ALPHABET S$, i.e.,
$$
W^*(s) = \hat W^*(φ(s)) 
\quad\text{and}\quad
μ^*(s) = \hat μ^*(φ(s)).
$$
Note that the policy $μ^*$ chooses the same action on all states in a
quantization cell $\ALPHABET S_i$. 


We are interested in two questions:

1. What is the error if $W^*$ is used as an approximation for $V^*$?
2. What is the error if the policy $μ^*$ is used instead of
   the optimal policy $π^*$? 

## Preliminary results

We start by some preliminary results to build the intuition behind the
approximation bounds. We start with a property of the discretized transition matrix.

::: highlight :::

Lemma #lemma:pmf

:   For any $\hat V \colon \hat {\ALPHABET S} \to \reals$, let $V \colon \ALPHABET
    S \to \reals$ be its piecewise constant extrapolation from $\hat
    {\ALPHABET S}$ to $\ALPHABET S$ (i.e., $V = \hat V \circ φ$). Then, for
    any $\hat s \in \ALPHABET S$ and $a \in \ALPHABET A$, we have
    $$
    \int_{\ALPHABET S} p(s' | s,a) V(s') ds' 
    =
    \sum_{\hat s' \in \hat {\ALPHABET S}} \hat P(\hat s' | \hat s, a) 
    \hat V(\hat s).
    $$

:::

<details>
<summary>
#### Proof {-}
</summary>
<div>
Recall that $\{\ALPHABET S_1, \dots, \ALPHABET S_n\}$ is a partition of
$\ALPHABET S$ and $\ALPHABET S_i = φ^{-1}(\hat s_i)$. Therefore,
$$\begin{align*}
\int_{\ALPHABET S} p(s'|\hat s, a) V(s') ds' 
&= \sum_{\hat s' \in \hat {\ALPHABET S}} 
\int_{φ^{-1}(\hat s')} p(s' | \hat s; a) \hat V(φ(s')) ds'
\\
&= \sum_{\hat s' \in \hat {\ALPHABET S}} \hat V(\hat s') 
\int_{φ^{-1}(\hat s')} p(s' | \hat s; a) ds'
\\
&= \sum_{\hat s' \in \hat {\ALPHABET S}} \hat V(\hat s') 
\hat P(\hat s' | \hat s, a).
\end{align*}$$
</div>
</details>

An immediate consequence of @lemma:pmf is the following:

::: highlight :::

Lemma #lemma:one-step

:   For any $\hat V \colon \hat {\ALPHABET S} \to \reals$, let $V \colon \ALPHABET
    S \to \reals$ be its piecewise constant extrapolation from $\hat
    {\ALPHABET S}$ to $\ALPHABET S$ (i.e., $V = \hat V \circ φ$). Define,
    one-step update functions:
    $$\begin{align}
      W(s) &= \min_{a \in \ALPHABET A}\biggl\{
      c(s,a) + γ \int_{\ALPHABET S} p(s' | s,a) V(s') ds' \biggr\}, 
      \label{eq:one-step-a}\\ 
      \hat W(\hat s) &= \min_{a \in \ALPHABET  A} \biggl\{
      \hat c(\hat s,a) + γ \sum_{\hat s \in \ALPHABET S} \hat P(\hat s' | s,a) \hat
      V(\hat s') \biggr\}.
      \label{eq:one-step-b}
    \end{align}$$
    Then,
    $$\begin{equation}\label{eq:one-step}
      W(\hat s) = \hat W(\hat s), \quad \forall \hat s \in \hat {\ALPHABET S}.
    \end{equation}$$

:::

<details>
<summary>
#### Proof {-}
</summary>
<div>
Let $π$ be the optimal policy for \\eqref{eq:one-step-a} and $\hat π$ be the
optimal policy for \\eqref{eq:one-step-b}. Fix a state $\hat s \in \hat
{\ALPHABET S}$ and let $a = π(\hat s)$ and $\hat a = \hat π(\hat s)$. Then,
$$\begin{align*}
W(\hat s) &= c(\hat s, a) + γ \int_{\ALPHABET S}
  \hat P(\hat s' | s, a) \hat V(s') ds'
\\
&\stackrel{(a)}= \hat c(\hat s, a) + γ
\sum_{\hat s' \in \hat {\ALPHABET S}} \hat P(\hat s'|\hat s, a) \hat V(\hat
s')
\\
&\ge \hat W(\hat s),
\end{align*}$$
where $(a)$ follows from definition of $\hat c$ and @lemma:pmf.

Similarly, we have 
$$\begin{align*}
\hat W(\hat s) &= \hat c(\hat s, \hat a) + γ
\sum_{\hat s' \in \hat {\ALPHABET S}} \hat P(\hat s'|\hat s, \hat a) \hat V(\hat
s')
\\
&\stackrel{(b)}= c(\hat s, \hat a) + γ \int_{\ALPHABET S}
  \hat P(\hat s' | s, \hat a) \hat V(s') ds'
\\
&\ge W(\hat s),
\end{align*}$$
where $(b)$ follows from definition of $\hat c$ and @lemma:pmf.

Thus, $W(\hat s) = \hat W(\hat s)$.
</div>
</details>


@lemma:pmf shows that for any quantization point $\hat s$ and action $a$, computing the
expectation of the future cost to go function $\hat V \colon \hat {\ALPHABET
S} \to \reals$ with respect to the measure $\hat P$ is the same as computing
the expectation of the piecewise linear extrapolation $V$ of $\hat V$ with
respect to the original measure $p$. 
@lemma:one-step shows that the one step Bellman update of a function $\hat V$
coincides with the one-step Bellman update of its piecewise constant
extrapolation $V$ at quantization points $\hat s \in \hat {\ALPHABET S}$.

Note that these equivalences are valid only at quantization points $\hat s \in
\hat {\ALPHABET S}$ and not for other points in $\ALPHABET S$. 

## Bounding the error for value function approximation

So far, we haven't used any regularity property of the model. @lemma:pmf and
@lemma:one-step depend only on the construction of the quantized model. 

Now suppose $\ALPHABET S$ is a bounded metric space with metric $d_S$. Suppose the
original MDP $M$ satisfies some regularity properties such that the value
function $V^*$ is Lipschitz with Lipschitz constant $\NORM{V^*}_L$, i.e., for any
$s,s' \in \ALPHABET S$
$$ \bigl| V^*(s) - V^*(s') \bigr| \le \NORM{V^*}_L d_S(s,s'). $$
This means that for any $s \in \ALPHABET S$, 
$$\begin{equation}\label{eq:lip}
\bigl| V(s) - V(φ(s)) \bigr| \le \NORM{V^*}_L D, 
\end{equation}$$
where $D = \sup_{s \in \ALPHABET S} d_S(s,φ(s))$ is the largest _radius_ of
the quantization cells. Note that since $\ALPHABET S$ is assumed to be a
bounded metric space, $D$ is finite. 

Using this idea, we can answer our first question. 

::: highlight :::
Proposition #prop:value

:   $$\NORM{ V^* - W^*}_∞ \le \frac{D}{1-γ} \NORM{V^*}_L. $$

:::

<details>
<summary>
#### Proof {-}
</summary>
<div>
Consider any $s \in \ALPHABET S$. Then,
$$\begin{align}
  \bigl| V^*(s) - W^*(s) \bigr| 
  &\le \bigl| V^*(s) - V^*(φ(s)) \bigr| + \bigl| V^*(φ(s)) - \hat W^*(φ(s)) \bigr|
  \notag \\
  &\le \NORM{V^*}_L D + \bigl| V^*(φ(s)) - \hat W^*(φ(s)) \bigr|
  \label{eq:step-a-1}
\end{align}$$

For the ease of notation let $\mathcal B$ and $\hat {\mathcal B}$ denote the
Bellman operators for model $M$ and $\hat M$, respectively. Now, we know that 
$\hat W^* = \hat {\mathcal B} \hat W^*$ and by @lemma:one-step $[\hat {\mathcal B}
\hat W^*](\hat s) = [\mathcal B W^*](\hat s)$. Thus, we can write the second term
of \\eqref{eq:step-a-1} as follows:
$$\begin{align*}
  \bigl| V^*(φ(s)) - \hat W^*(φ(s)) \bigr| 
  &=
  \bigl| [\mathcal B V^*](φ(s)) - [ \mathcal B W^* ](φ(s)) \bigr| 
  \\
  &\le γ \NORM{V^* - W^*}_∞.
\end{align*}$$
Substituting back in \\eqref{eq:step-a-1}, we get
$$\bigl| V^*(s) - W^*(s) \bigr| \le \NORM{V^*}_L D + γ \NORM{V^* - W^*}_∞.$$
We get the result by supermizing over $s$ and rearranging the terms.
</div>
</details>

## Bounding the error for policy approximation

Using the same idea as @prop:value, it is possible to show that 
$$
\NORM{V^{μ^*} - W^*}_∞ \le \frac{D}{1-γ} \NORM{V^{μ^*}}_L.
$$
Combining this with @prop:value, we get
$$
\NORM{V^{μ^*} - V^*}_∞ \le \NORM{V^{μ^*} - W^*}_∞ + \NORM{V^* - W^*}_∞
\le \frac{D}{1-γ} [ \NORM{V^*}_L + \NORM{V^{μ^*}}_L ].
$$

If we assume that the model is Lipschitz, then we can get a bound on
$\NORM{V^*}_L$ in terms of Lipschitz constants on the cost function and the
transition dynamics. However, it is difficult to bound $\NORM{V^μ}_L$ because
that bound will be interms of the Lipschitz constant of the policy $μ^* = \hat
μ^* \circ φ$. So, we provide an alternative bound on $\NORM{V^{μ^*} - W^*}_∞$
in this section.


We assume that the model $M$ is a $(L_c, L_p)$-Lipschitz MDP. 

Assumpt. #ass:lip

:   * For every $a \in \ALPHABET A$, $c(\cdot, a)$ is $L_c$-Lipschitz.
    * For every $a \in \ALPHABET A$, $p(\cdot | s, a)$ is $L_p$-Lipschitz
      (with respect to the Kantorovich distance on probability measures). 

Under this assumption, we can show the following:

::: highlight :::
Proposition #prop:policy

:   Under @ass:lip, we have
    $$\NORM{V^{μ^*} - V^*}_∞ \le 
      \frac{D}{1-γ} \biggl[ L_c + γ L_p \NORM{V^*}_L + 
      \frac{1 + γ}{1-γ} \NORM{V^*}_L \biggr]. $$

    Furthermore, if $γ L_p < 1$, then from properties of Lipschitz MDPs, we
    know that $\NORM{V^*}_L \le L_c/(1- γ L_p)$. Thus,
    $$\NORM{V^{μ^*} - V^*}_∞ \le 
      \frac{2 D L_c }{ (1-γ)^2 (1-γ L_p) }. $$

:::

<details>
<summary>
#### Proof {-}
</summary>
<div>
Fix a state $s \in \ALPHABET S$. Let $\hat s = φ(s)$ and $a = \hat
μ^*(\hat s) = μ(s)$. By construction, $W^*(s) = \hat W^*(\hat s)$. Thus, 
$$\begin{align*}
W^*(s) &= \hat W^*(\hat s) = c(\hat s, a) + γ \sum_{\hat s' \in \hat {\ALPHABET S}}
\hat P(\hat s' | \hat s, a) \hat W^*(\hat s').
\\
&= c(\hat s, a) + γ \int_{\ALPHABET S} p(s' | \hat s, a) W^*(s') ds'.
\end{align*}$$
Moreover, 
$$
V^{μ^*}(s) = c(s, a) + γ \int_{\ALPHABET S} 
p(s'|s,a) V^{μ^*}(s') ds'.
$$
Thus,
$$\begin{align}
\bigl| V^{μ^*}(s) - W^*(s) \bigr| &\stackrel{(a)}\le
\bigl| c(s,a) - c(φ(s),a) \bigr| \notag \\
&\quad + γ \biggl| \int_{\ALPHABET S} p(s'|s,a) V^{μ^*}(s') ds' 
                -  \int_{\ALPHABET S} p(s'|s,a) W^*(s') ds' \biggr| \notag \\
&\quad + γ \biggl| \int_{\ALPHABET S} p(s'|s,a) W^{*}(s') ds' 
                -  \int_{\ALPHABET S} p(s'|s,a) V^*(s') ds' \biggr| \notag \\
&\quad + γ \biggl| \int_{\ALPHABET S} p(s'|s,a) V^{*}(s') ds' 
                -  \int_{\ALPHABET S} p(s'|\phi(s),a) V^*(s') ds' \biggr| \notag \\
&\quad + γ \biggl| \int_{\ALPHABET S} p(s'|\phi(s),a) V^{*}(s') ds' 
                -  \int_{\ALPHABET S} p(s'|\phi(s),a) W^*(s') ds' \biggr| 
\label{eq:step-b-1}
\end{align}$$
where $(a)$ follows from the triangle inequality. Now, we bound each of the
terms in \\eqref{eq:step-b-1}. Since $c$ is Lipschitz, we have
$$\begin{equation} \label{eq:step-b-2}
\bigl| c(s,a) - c(φ(s),a) \bigr| \le L_c D.
\end{equation}$$
Moreover,
$$\begin{equation} \label{eq:step-b-3}
\biggl| \int_{\ALPHABET S} p(s'|s,a) V^{μ^*}(s') ds' 
      -  \int_{\ALPHABET S} p(s'|s,a) W^*(s') ds' \biggr| 
\le \NORM{ V^{μ^*} - W^*}_∞.
\end{equation}$$
From @prop:value we have
$$\begin{equation} \label{eq:step-b-4}
\biggl| \int_{\ALPHABET S} p(s'|s,a) W^{*}(s') ds' 
      -  \int_{\ALPHABET S} p(s'|s,a) V^*(s') ds' \biggr| 
\le \NORM{ W^* - V^*}_∞ \le \frac{D}{1-γ} \NORM{V^*}_L
\end{equation}$$
From the Kantorovich-Rubinstein duality, we have 
$$\begin{equation} \label{eq:step-b-5}
\biggl| \int_{\ALPHABET S} p(s'|s,a) V^{*}(s') ds' 
      -  \int_{\ALPHABET S} p(s'|\phi(s),a) V^*(s') ds' \biggr| 
\le \mathcal {W}(p( \cdot | s,a), p(\cdot | φ(s), a)) \NORM{V^*}_L
\le L_p D \NORM{V^*}_L.
\end{equation}$$
Finally, from @prop:value, we have
$$\begin{equation} \label{eq:step-b-6}
\biggl| \int_{\ALPHABET S} p(s'|\phi(s),a) V^{*}(s') ds' 
      -  \int_{\ALPHABET S} p(s'|\phi(s),a) W^*(s') ds' \biggr| 
\le \NORM{V^* - W^*}_∞ \le \frac{D}{1-γ} \NORM{V^*}_L.
\end{equation}$$
Substituting \\eqref{eq:step-b-2}--\\eqref{eq:step-b-6} in \\eqref{eq:step-b-1}
and rearranging, we get
$$\begin{equation}
  \NORM{V^{μ^*} - W^*}_∞ \le \frac{D}{1-γ} \biggl[
  L_c + γ L_p \NORM{V^*}_L + \frac{2γ}{1-γ} \NORM{V^*}_L \biggr]
\end{equation}$$

This proves the first result of the Proposition. The second result follows
from simple algebra.
</div>
</details>

