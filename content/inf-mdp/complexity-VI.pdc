---
title: "Theory: Sample complexity of value iteration"
weight: 05
categories: 
  - MDP
tags:
  - infinite horizon
  - discounted cost
  - sample complexity
  - value iteration
---

How many computations are needed to run the value or policy iteration
algorithm to obtain a policy that in within $ε$ of the optimal? In this
section, we provide an answer for this question for the value iteration
algorithm. 

Conisder an MDP with a finite state space $\ALPHABET X = \{1, \dots, n \}$
with a finite non-empty set of actions $\ALPHABET U(x)$ available at each $x
\in \ALPHABET X$. Each action set consists of $M_x$ actions with a total
number of $M = \sum_{x=1}^n M_x$ actions. This number can be interpreted as
the total number of state-action pairs. Let $β \in (0, 1)$ be the discount
factor. We present the value iteration algorithm from the [notes on discounted
MDP][discounted] to achieve a pre-specified accuracy $ε$.

::: highlight :::

**Value Iteration Algorithm**

For given MDP, discount factor $β \in (0,1)$, and constant $ε > 0$

1. Start with any $V_0 \in \reals^n$.
2. Recursively compute $V_{k} = \mathcal B V_{k-1} = \mathcal B_{g_{k-1}} V_{k-1}.$
3. Define 
   $$ Δ_k = \max\{ V_k(x) - V_{k-1}(x) \} - \min \{ V_k(x) - V_{k-1}(x) \}. $$
4. If $Δ_k > \frac{1 - β}{β} ε$, continue to step 2. Else carry out one more
   step of value update and choose the policy $g_k$. 
   
:::  

As established in the [notes on discounted MDP][discounted], the algorithm
stops in a finite number of iterations and the resulting policy is
$ε$-optimal.

[discounted]: ../discounted-mdp#value-iteration-algorithm

# Span norm contraction

Let $\SPAN(v) = \max(v) - \min(v)$ denotes the span semi-norm. We start by
stating some basic properties of span semi-norm.

1. $\SPAN(v) \ge 0$ for all $v \in \reals^n$
2. $\SPAN(v + w) \le \SPAN(v) + \SPAN(w)$ for all $v, w \in \reals^n$.
3. $\SPAN(m v) \le |m| \SPAN(v)$ for all $v \in \reals^n$ and $m \in \reals$.
4. $\SPAN(v + m \mathbf{1}) = \SPAN(v)$ for all $m \in \reals$.
5. $\SPAN(v) = \SPAN(-v)$.
6. $\SPAN(v) \le 2\|v\|$. 

Properties 1--3 imply that $\SPAN(v)$ is a semi-norm. However, it is not a
norm because of property 4; that is, $\SPAN(v) = 0$ does not imply that $v =
0$. If $\SPAN(v) = 0$, then $v = m \mathbf{1}$ for some scalar $m$. 

A basic result for our analysis is the following:

::: highlight :::

Prop. #prop:span-matrix

: Let $v \in \reals^n$ and $P$ be any matrix of compatible dimensions. Then,
  $$ \SPAN(P v) \le γ_P \SPAN(v), $$
  where
  $$\begin{equation} \label{eq:span-matrix}
    γ_P = 1 - \min {x, y \in \ALPHABET X}
    \sum_{z \in \ALPHABET X} \min\{ P_{xz}, P_{yz} \}.
  \end{equation}$$
  Furhermore, $γ_P \in [0, 1]$ and there exists a $v \in \reals^n$ such that
  $\SPAN(Pv) = γ_P \SPAN(v)$.

:::

@prop:span-matrix illustrates the "averaging" property of a transition matrix. By
multiplying a vector by a transition matrix, the resulting vector has
components which are more nearly equal. When $P$ is a square matrix, the
quantity $γ_P$ is called the ergodicity coefficient, which is often written in
an alternative form by using the relation $|a - b| = (a + b) - 2 \min(a,b)$:
$$
  γ_P = \frac12
  \max_{x,y \in \ALPHABET X} \sum_{z \in \ALPHABET X}
  \bigl| P_{xz} - P_{yz} \bigr|. $$
The ergodicity coefficient is an upper bound on the second largest eigenvalue
of $P$. $γ_P$ equals $0$ if all rows of $P$ are equal and equals $1$ if at
least two rows of $P_d$ are orthogonal. From a different perspective, $γ_P <
1$ if for each pair of states there exists at least one state which they both
can reach with positive probability in one step. 

Remark #rem:bound

:   Note that
    $$ γ_P \le 1 - \sum_{z \in \ALPHABET X} \min_{x \in \ALPHABET X} P_{xz} 
    =: γ_P' $$
    which is easier to compute. 

#### Proof {-}

Note that for any $v \in \reals^n$
\begin{align*}
\SPAN(Pv) &= \max_{x \in \ALPHABET X} \sum_{z \in \ALPHABET X} P_{xz} v_z 
- \min_{x \in \ALPHABET X} \sum_{z \in \ALPHABET X} P_{yz} v_z \\
&= \max_{x, y \in \ALPHABET X} 
  \sum_{z \in \ALPHABET X} P_{xz} v_z - \sum_{z \in \ALPHABET X} P_{yz} v_z 
\end{align*}
Let $B(z; x,y) = \min\{ P_{xz}, P_{yz} \}$. Then consider
\begin{align*}
  \sum_{z \in \ALPHABET X} P_{xz} v_z - \sum_{z \in \ALPHABET X} P_{yz} v_z 
  &=
  \sum_{z \in \ALPHABET X} [ P_{xz} - B(z; x,y) ] v_z - 
  \sum_{z \in \ALPHABET X} [ P_{yz} - B(z; x,y) ] v_z \\
  &\le 
  \sum_{z \in \ALPHABET X} [ P_{xz} - B(z; x,y) ] \max(v) -
  \sum_{z \in \ALPHABET X} [ P_{yz} - B(z; x,y) ] \min(v) 
  &= \biggl[ 1 - \sum_{z \in \ALPHABET X} B(z; x, y) \biggr] \SPAN(v).
\end{align*}
Hence,
$$ \SPAN(Pv) \le \max_{x, y \in \ALPHABET X} \biggl[
  1 - \sum_{z \in \ALPHABET X} B(z; x, ) \biggr] \SPAN(v). $$

Now we show that there exists a $v$ such that \\eqref{eq:span-matrix} holds
with equality. If $γ_P = 0$, then $P$ has equal rows, so
that $\SPAN(Pv) = 0 = 0 \cdot \SPAN(v)$ for all $v \in \reals^n$. Suppose $γ_P
> 0$. Using the identity $[ a - b]^{+} = a - \min(a,b)$, we can write
$$
`γ_P = \max_{x,y \in \ALPHABET X} 
\sum_{z \in \ALPHABET  X} \bigl[ P_{xz} - P_{yz} \bigr]^{+}.
$$
Let $x^*$ and $y^*$ be such that
$$
  γ_P = \sum_{z \in \ALPHABET X}  
\sum_{z \in \ALPHABET  X} \bigl[ P_{x^*z} - P_{y^*z} \bigr]^{+}.
$$
Define $v$ by
$$ 
  v_z = \IND\{ P_{x^*z} > P_{y^*z} \}.
$$
Then, note that $\SPAN(v) = 1$ and 
\begin{align*}
  \SPAN(Pv) &\ge 
  \sum_{z \in \ALPHABET X} P_{x^* z} v_z - 
  \sum_{z \in \ALPHABET X} P_{y^* z} v_z \\
  =
  \sum_{z \in \ALPHABET  X} \bigl[ P_{x^*z} - P_{y^*z} \bigr]^{+}
  \\
  &= γ_P \SPAN(v).
\end{align*}
Combining with \\eqref{eq:span-matrix}, we get $\SPAN(Pv) = γ_P
\SPAN(v)$. $\Box$


Define the contraction factor
$$\begin{equation}\label{eq:contraction}
  γ = \max_{\substack{ x,y \in \ALPHABET X \\ u \in \ALPHABET U(x), w \in
  \ALPHABET U(y)}}
  \biggl[ 1 - \sum_{z \in \ALPHABET X} 
    \min\{ P(z | x,u), P(z | y, w) \biggr].
\end{equation}$$
Note that $γ \in [0, 1]$. 

::: highlight :::

Theorem #span-contraction

: For any $V_1, V_2 \in \reals^n$, 
  $$ \SPAN(\mathcal B V_1 - \mathcal B V_2) \le β γ\, \SPAN(V_1 - V_2). $$

:::

#### Proof {-}

Let $g_i$ be such that $\mathcal B V_i = \mathcal B_{g_i}V_i$. 
Let 
\begin{align*}
  x^* &= \arg \max_{x \in \ALPHABET X}(\mathcal B V_1(x) - \mathcal B V_2(x)), 
  \\
  x_* &= \arg \min_{x \in \ALPHABET X}(\mathcal B V_1(x) - \mathcal B V_2(x)),
\end{align*}
Then, 
$$
  \mathcal B V_1(x^*) - \mathcal B V_2(x^*) \le 
  \mathcal B_{g_2} V_1(x^*) - \mathcal B_{g_2} V_2(x^*) 
  = β P_{g_2}(V_1 - V_2)(x^*)
$$
and
$$
  \mathcal B V_1(x_*) - \mathcal B V_2(x_*) \ge 
  \mathcal B_{g_1} V_1(x^*) - \mathcal B_{g_1} V_2(x^*) 
  = β P_{g_1}(V_1 - V_2)(x^*).
$$
Therefore, 
\begin{align*}
  \SPAN(\mathcal B V_1 - \mathcal B V_2) &\le
  β P_{g_2}(V_1 - V_2)(x^*) - β P_{g_1}(V_1 - V_2)(x_*) \\
  &\le \max_{x \in \ALPHABET X} β P_{g_2} (V_1 - V_2)(x) -
  \min_{x \in \ALPHABET X} β P_{g_1}(V_1 - V_2)(x)
  \\
  &\le \SPAN(β\, \ROWS(P_{g_2}, P_{g_1})(V_1 - V_2).
\end{align*}
By applying @prop:span-matrix, we get
$$ \SPAN(\mathcal B V_1 - \mathcal B V_2) \le βγ_{\bar P} \SPAN(V_1 - V_2), $$
where $γ_{\bar P}$ is given by \\eqref{eq:span-matrix} with $\bar P =
\ROWS(P_{g_2}, P_{g_1})$. The result follows by noting that $γ_{\bar P}$ is at
most $γ$. $\Box$ 

# Sample complexity of value iteration

Note that $γ \in [0, 1]$. We will first rule out the case $γ = 0$. If $γ = 0$,
then $P(z | x, u) = P(z | y, w)$ for all $x, y, z \in \ALPHABET X$ and $u \in
\ALPHABET U(x)$ and $w \in \ALPHABET U(y)$, which implies that all
deterministic policies have the same transition probabilities. Therefore, a
deterministic policy $g$ is optimal if and only if it minimize the one-step
cost. Thus, the case with $γ = 0$ is trivial. So, in the rest of the analysis,
we assume that $γ \in (0, 1)$.


Suppose $Δ_1 > 0$ (else
we obtained an optimal policy at iteration 1). Define:
$$\begin{equation}\label{eq:K*}
  K^*(β) = \max \left\{ \left\lceil
  \frac{ \log \frac{(1-β) ε γ}{Δ_1} } {\log(βγ)}
  \right\rceil
  ,1 \right\}.
\end{equation}$$

::: highlight :::

Theorem #VI-bound

: For any $ε > 0$, value iteration finds an $ε$-optimal policy in no more than
  $K^*(β)$ iterations. In addition, each iteration uses at most $O(nM)$
  operations.

:::

#### Proof {-}

If follows from the definition of Bellman operator that each iteration uses at
most $O(nM)$ iterations (to compute the $Q$ function, for each state-action
pair, we need to compute a sum over $n$ terms).

From @theorem:span-contraction, we get that $Δ_k \le (βγ)^{k-1} Δ_1$.
Therefore, the minimum number of iterations required to achieve $Δ_k \le
\frac{1-β}{β}ε$ is given $K^*(β)$. $\Box$ 

Remark #rem:simple

: Note that finding the value of $γ$ requires computing the sum
in \\eqref{eq:contraction} for all couples $\{ (x,u), (y,w) \}$ of state
action pairs such that $(x,u) \neq (y,w)$. The total number of such pairs are
$M(M-1)/2 = O(M^2)$. Therefore, the number of arithematic operators
in \\eqref{eq:contraction}, which are additions, is $n$ for each couple.
Therefore, computation of $γ$ requires $O(nM^2)$ operations, which can be
significantly larger than the complexity of computing an $ε$-optimal policy
which is given by @theorem:VI-bound! Based on @rem:bound, we can replace $γ$ by
in \\eqref{eq:K*} by
$$
  γ' = 1 - \sum_{z \in \ALPHABET X} \min_{x \in \ALPHABET X, u \in \ALPHABET U}
       P(z | x,u)
$$
which requies $O(nM)$ operations. 
       

# References {-}

The material presented here is taken from @Feinberg2020. Note that @theorem:VI-bound
is essentially a corollary of Theorems 6.6.5 and 6.6.6 of @Puterman2014, but
the explict form was not stated there. 


