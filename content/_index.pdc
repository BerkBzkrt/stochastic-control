Location

:   ENGTR 2100 (Tuesday and Thursday 10:05am to 11:25am) <br />
    Starting from 31 March 2020, the class will be help online on Zoom. Use
    the following link to join: 
    [https://mcgill.zoom.us/j/304330076](https://mcgill.zoom.us/j/304330076).
    You can also join via phone: +1 (438) 809-7799 (meeting id: 304330076)


Office hours

:   Thursday, 2:00pm to 3:00pm, MC 533.

Course Outline

:   Modeling of stochastic control systems, controlled Markov
    processes, dynamic programming, imperfect and delayed observations,
    ~~linear quadratic and Gaussian (LQG) systems,~~ team theory,
    information structures, static and dynamic teams, dynamic
    programming for teams, ~~multi-armed bandits.~~

Course pre-requisites

:   -   A graduate course on Probability (ECSE 509 or equivalent) is a
        *required* pre-requisite.
    -   A graduate course on Stochastic processes (ECSE 510
        or equivalent) is a *recommended* co-requisite.


Grading policy

:   -   **~~20%~~ <ins>35%</ins> weekly assignments**. Depending on the availability of
        graders, only a few questions, at random, will be graded. Late
        submissions will be penalized by 10% per day.
    -   **~~25%~~ <ins>35%</ins> mid-terms**. In class, March 10.
    -   **~~20%~~ <ins>30%</ins> term project**. A month long project to be
        done ~~in groups of two~~ <ins>individually</ins>. Present one or two
        papers on any topic of your interest related to the material covered
        in class. A 10 to 15 page report. ~~and a 10 minute in-class
        presentations.~~
    -   ~~**35% final**. During the exam period, scheduled by
        the university.~~

Textbooks

:   -   Kumar and Varaiya, [*Stochastic Systems: Estimation,
        Identification, and Adaptive
        Control,*](http://bookstore.siam.org/cl75/) Prentice Hall, 1986.
        Reprinted by SIAM 2015

    -   Bertsekas, [*Dynamic programming and optimal
        control*,](http://www.athenasc.com/dpbook.html) vol 1 and
        2, Athena Publications, 2005.

        Perhaps the most comprehensive book of different topics in
        dynamic programming.

    -   Puterman, [*Markov decision processes: discrete time dynamic
        programming*](http://onlinelibrary.wiley.com/book/10.1002/9780470316887), Wiley 1994.

        Excellent source algorithms for perfectly observed systems, in
        particular, infinite horizon dynamic programs.

    For most of the course, I will loosely follow the notation of Kumar
    and Varaiya. Many of the examples done in class are taken
    from Bertsekas. Some material on numerical implementation is
    from Puterman.

Reference books

:   -   Ross, [*Introduction to Stochastic Dynamic
Programming,*](https://www.elsevier.com/books/introduction-to-stochastic-dynamic-programming/ross/978-0-12-598420-1) Academic
        Press, 1983.

        Excellent introduction to dynamic programming, from the
        point-of-view of applied mathematics.

    -   Dernardo, *Dynamic Programming: Models and Applications,*
        Prentice Hall, 1982.

        Excellent introduction to dynamic programming, from the
        point-of-view of operations research.

    -   Powell, [*Approximate Dynamic Programming*](http://adp.princeton.edu),
        John Wiley and Sons, 2011.

        Comprehensive overview of approximate dynamic programming

