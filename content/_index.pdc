Location

:   Zoom (Tuesday and Thursday 10:05am to 11:25am) <br />

      The course will start as an online course until announced otherwise.
      Classes will take place via [zoom].

      ~~The course will be delivered in-person. I teach in a 'chalk and board'
      style in a room which does not have video recording facilities. So, it
      is strongly recommended that you register for the course only if you can
      attend classes in person.~~


[zoom]: https://mcgill.zoom.us/j/82656188558?pwd=eEVjQU9RbGpPcXgwVUIrN0Nxd2Y4dz09

Office hours

:   TBA

Course Outline

:   Modeling of Markov decision processes, dynamic programming, stochastic
    monotonicity and the structure of optimal policies, value iteration,
    policy iteration, approximate dynamic programming, imperfect and delayed
    observations, linear quadratic and Gaussian (LQG) systems, team theory,
    information structures, static and dynamic teams, dynamic
    programming for teams.

Course pre-requisites

:   -   A graduate course on Probability (ECSE 509 or equivalent) is a
        *required* pre-requisite.
    -   A graduate course on Stochastic processes (ECSE 510
        or equivalent) is a *recommended* co-requisite.


Grading policy

:   -   **25% weekly assignments**. Typically only one question per-assignment
        will be graded. Late submissions will be penalized by 10% per day.
        The lowest assignment will be dropped. 

    -   **40%  mid-terms**. If in-person classes resume, then we will have an
        in-class mid-term on March 29th. If classes remain online, we will
        have an online mid-term in the week of March 28th: the exam will be
        posted on 9:00am on March 28th and will remain available for 72 hours.
        Once you start the exam, you will have 2.5 hours to finish the exam. 

    -   **25%  term project**. A month long project to be
        done either along or in groups of two. Present one or two
        papers on any topic of your interest related to the material covered
        in class. Deliverables are a 10--15 page report and a 10 minute in-class
        presentations.
    <!--
    -   **35% final**. During the exam period, scheduled by
        the university.
   -->

Textbooks

:   -   Kumar and Varaiya, [*Stochastic Systems: Estimation,
        Identification, and Adaptive
        Control,*](http://bookstore.siam.org/cl75/) Prentice Hall, 1986.
        Reprinted by SIAM 2015

    -   Bertsekas, [*Dynamic programming and optimal
        control*,](http://www.athenasc.com/dpbook.html) vol 1 and
        2, Athena Publications, 2005.

        Perhaps the most comprehensive book of different topics in
        dynamic programming.

    -   Puterman, [*Markov decision processes: discrete time dynamic
        programming*](http://onlinelibrary.wiley.com/book/10.1002/9780470316887), Wiley 1994.

        Excellent source algorithms for perfectly observed systems, in
        particular, infinite horizon dynamic programs.


    The flow of the course is largely based on my interpretation of the
    research landscape in Stochastic Control. The emphasis is on developing a
    strong theoretical foundations and selected material is taken from all
    three books listed above (in addition to specific material taken from
    research papers).

Reference books

:   -   Ross, [*Introduction to Stochastic Dynamic
Programming,*](https://www.elsevier.com/books/introduction-to-stochastic-dynamic-programming/ross/978-0-12-598420-1) Academic
        Press, 1983.

        Excellent introduction to dynamic programming, from the
        point-of-view of applied mathematics.

    -   Dernardo, *Dynamic Programming: Models and Applications,*
        Prentice Hall, 1982.

        Excellent introduction to dynamic programming, from the
        point-of-view of operations research.

    -   Powell, [*Approximate Dynamic Programming*](http://adp.princeton.edu),
        John Wiley and Sons, 2011.

        Comprehensive overview of approximate dynamic programming

    -   Krishnamurty, [*Partially Observable Markov Decision
        Processes*](https://www.cambridge.org/core/books/partially-observed-markov-decision-processes),
        Cambridge University Press, 2016.

        Comprehensive overview of POMDPs
