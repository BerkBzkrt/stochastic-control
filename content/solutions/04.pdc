---
title: Assignment 4 (solution)
---

## Problem 1

a.  This is an optimal stopping problem. Let $X_t$ denote the population
    at time $t$ and $U_t \in \{0,1\}$ deote the decision to stop ($U_t =
    0$) or not ($U_t = 1$). If the hunter has not made a stopping
    decision, the dynamics of $\{X_t\}_{t \ge 1}$ are given by
    $$
      X_{t+1} = 
      \begin{cases}
        X_t, & \text{with probability $1 - p(X_t)$} \\
        X_t - 1, & \text{with probability $p(X_t)$}
      \end{cases}
    $$

    Thus, the transition probability matrix is
    $$
      P = \MATRIX{
      1& 0& 0& \ldots& 0\\
      p(1)& 1 - p(1)& 0& \ldots& 0\\
      0& p(2)& 1 - p(2)& \ldots& 0\\
      \ldots& \ldots& \ldots& \ldots& \ldots\\
      0& 0& 0& \ldots& 1 - p(n) }
    $$

    The expected continuing reward at time $t$ is given by
    $$
      r_t(x) = -c + p(x).
    $$

    The stopping reward reward is
    $$
      s_t(x) = 0.
    $$

    Hence, the above system is a MDP and an optimal solution is given by
    the solution to the following dynamic program.
    $$ \begin{align}
       V_T(x) &= \max\{0, -c + p(x)\} \\
       V_t(x) 
        &= \max\{0, -c + p(x) + (1-p(x))V_{t+1}(x-1) + p(x)V_{t+1}(x) \}
        \\
    \end{align} $$
    In the above equations, the first term corresponds to $u_t = 1$ and the
    second to $u_t = 0$. 

b.  As stated in the hint, the result can be proved based on the following
    result.

    ::: highlight :::
    Lemma

    :   For all $t$, $V_t(x) = 0 \iff x \le λ$.

    :::

    First observe that $V_t(x) \ge 0$ for all $x$ and $t$. Then the above
    lemma implies that $g_t(x) = \IND\{p(x) \ge x\}$, and hence, it is
    optimal to stop hunting when the current population falls below $λ$.

    We prove the Lemma backward induction. For $t=T$. 
    $$
      V_T(x) = \max\{0, -c + p(x) \}.
    $$
    Thus,
    $$
      V_T(x) = 0 \iff p(x) \le c \iff x \le λ.
    $$
    This forms the basis of induction. Now assume that the lemma is true
    for $t+1$ and consider $V_t(x)$.
    $$
      V_t(x) = 
      \max\{0, -c + p(x) + (1-p(x))V_{t+1}(x-1) + p(x)V_{t+1}(x) \}
    $$

    If $x \le λ$, then $p(x) -c \le 0$ and by the assertion of the
    induction hypothesis, $V_{t+1}(x) = V_{t+1}({x-1}) = 0$.

    On the other hand, if $x > λ$, $p(x) -c > 0$, and since $V_{t+1}(⋅)
    \ge 0$, we have that $V_t(x) > 0$. 

    Thus, the assertion is true for $t$, and, by the principle of
    induction, true for all values of $t$.

## Problem 2

a.  This is an optmal stopping problem. The continuation reward is given
    by $-c$ while the stopping reward is given by $r(x)$. Therefore, the
    dynamic program is given by 
    $$ \begin{align}
      V_{T}(x) &= r(x) \\
      V_t(x)   &= \max\{r(x), -c + \sum_{y \in \mathbb N} P_{xy}
        V_{t+1}(y) \}
    \end{align} $$
    In the above equation, the first term corresponds to stopping
    ($u_t  = 1$) and the second to continuing ($u_t = 0$).

b.  From [Assignment 2](../../assignments/02), we know that to show
    monotonicity in time, we need to show $V_{T-1}(x) \ge V_T(x)$. This
    follows immediately from the definition of $V_{T-1}(x)$. 

c.  For any $t$, let $x \in H_t$. Then,
    $$
       r(x) \ge 
       -c + \sum_{y \in \mathbb N} P_{xy} V_{t+1}(y) 
       \ge
       -c + \sum_{y \in \mathbb N} P_{xy} V_{t+2}(y) 
    $$
    where the first inequality follows because $x \in H_t$ and the second
    inequality follows from the monotonicity of the value function (in
    time). 

    The second inequality implies that $x \in H_{t+1}$. Thus, $H_t
    \subseteq H_{t+1}$.

    Now, assume that **(P1)** is true. We claim that under
    **(P1)**, $H_t = H_{T-1}$ for all $t$. To prove the claim, we
    proceed by backward induction.

    The result is trivially true for $T-1$. This forms the basis of
    induction. Suppose that the result is true for $t+1$, i.e., 
    $$
      H_{t+1} = H_{t+1} = \cdots H_{T-1}
    $$
    Moreover, for any $x \in H_{T-1}$,
    $$ \begin{align}
       V_{t+1}(x) = r(x) &\ge
          -c + \sum_{y \in \mathbb N} P_{xy} V_{t+2}(y) 
        \\
      &\stackrel {(a)}=
          -c + \sum_{{y \in H_{T-1}}} P_{xy} V_{t+2}(y)
        \\
      &\stackrel {(b)}=
          -c + \sum_{{y \in H_{T-1}}} P_{xy} r(y)
    \end{align} $$
    where $(a)$ follows from property (P1) and $(b)$ follows from the
    fact that for any $y \in H_{T-1} = H_{t+1}$, it is optimal to
    exploit; therefore, $V_{t+2}(y) = r(y)$.

    Now, consider $x \in H_{T-1}$.
    $$ \begin{align}
      -c + \sum_{y \in \mathbb N} P_{xy} V_{t+1}(y) 
      &= -c + \sum_{y \in H_{T-1}} P_{xy} V_{t+1}(y) 
      \\
      &\stackrel {(a)}=
      -c + \sum_{y \in H_{T-1}} P_{xy} r(y) 
      \\
      &\stackrel {(b)}\le r(x)
    \end{align} $$
    where $(a)$ follows from property (P1) and $(b)$ follows from
    the previous equation. Thus, $x \in H_t$. This implies that $H_{T-1}
    \subseteq H_t$.

    We had already shown that $H_t \subseteq H_{T-1}$. Thus, $H_t =
    H_{T-1}$. This completes the proof of the claim.


