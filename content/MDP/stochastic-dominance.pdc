---
title: "Prelim: Stochastic dominance"
weight: 21
categories:
  - stochastics
tags:
  - stochastic orders
  - stochastic dominance
  - stochastic monotonicity
scripts:
  - plotly
---

Stochastic dominance is a partial order on random variables. 
Let $\ALPHABET X$ be a totally ordered finite set, say $\{1, \dots, n\}$ and
let $\Delta(\ALPHABET X)$ denote the state of pmfs on $\ALPHABET X$.  

Definition

:   Suppose $X$ and $Y$ are $\ALPHABET X$ valued random variables where $X
    \sim \pi$ and $Y \sim \mu$. We say $X$ _stochastically dominates_ $Y$ if
    for any $x \in \ALPHABET X$,
    $$\begin{equation}\label{eq:inc-prob}
      \PR(X \ge x) \ge \PR(Y \ge x). 
    \end{equation}$$

    Stochastic domination is denoted by $X \succeq_s Y$ or $\pi \succeq_s
    \mu$. 

Let $\Pi$ and ${\rm M}$ denote the CDF of $\pi$ and $\mu$. Then
\\eqref{eq:inc-prob} is equivalent to the following:
$$\begin{equation}\label{eq:cdf}
  \Pi_i \le {\rm M}_i, \quad \forall i \in \{1, \dots, n\}. 
\end{equation}$$
Thus, visually, $X \succeq_s Y$ means that the CDF of $X$ _lies below_ the CDF of $Y$. 

Example

:   $\left[0, \frac 14, \frac 14, \frac 12\right]
    \succeq_s
    \left[\frac 14, 0, \frac 14, \frac 12 \right]
    \succeq_s
    \left[\frac 14, \frac 14, \frac 14, \frac 14 \right].$


     <div class="flex">
       <div id="distribition:1" style="width:200px; height:250px;"></div>
       $\succeq_s$
       <div id="distribition:2" style="width:200px; height:250px;"></div>
       $\succeq_s$
       <div id="distribition:3" style="width:200px; height:250px;"></div>
     </div>

<script>
  var x  = [1, 2, 3, 4];
  var D1 = [0, 0.25, 0.25, 0.5];
  var D2 = [0.25, 0, 0.25, 0.5];
  var D3 = [0.25, 0.25, 0.25, 0.25];

  function show_distribution(dom, x, y, xtitle, ytitle) {
    var cx = [0, x[0]];
    var cy = [0, 0];
    var val = 0;

    for(var i = 0; i < x.length; i++) {
       val += y[i];
       cx.push(x[i]);
       cy.push(val);

       if (x[i+1]) {
         cx.push(x[i+1]);
         cy.push(val);
      } else {
         cx.push(x[i] + 0.5);
         cy.push(val);
      }
    }

    var pmf = { 
        x: x,
        y: y,
        type: "bar", 
        name: 'PMF'
    };

    var cmf = { 
        x: cx,
        y: cy,
        mode: "lines", 
        name: 'CMF'
    }

    var data = [cmf,pmf];

    var layout = { 
        paper_bgcolor: "#fffff8",
        plot_bgcolor:  "#fffff8",
        xaxis : {
          title: xtitle,
          showgrid: false,
          zeroline: true,
          showline: false,
          showticklabels: false,
          range: [-0.1, 5.0],
        },
        yaxis : {
          showgrid: false,
          showline: false,
          zeroline: true,
          showticklabels: false,
          range: [-0.1, 1.05],
        },

        legend : { 
          x : 0.1,
          y : 1.2, 
          orientation: "h"
        },

        title : ytitle,
        width: 200,
        height: 250,
        automargin: true,
        margin: {
          l : 15,
          r : 15,
          b : 15,
          t : 35,
          pad : 15
        } ,
        hovermode: false,

        bargap: 0.65,
    };

    var options = {
        staticPlot: true,
        displayModeBar: false,
    };

    Plotly.plot(dom, data, layout, options);
  }

  show_distribution("distribition:1", x, D1, "$\\left[0, \\frac 14, \\frac 14, \\frac 12\\right]$", "");
  show_distribution("distribition:2", x, D2, "$\\left[\\frac 14, 0, \\frac 14, \\frac 12\\right]$", "");
  show_distribution("distribition:3", x, D3, "$\\left[\\frac 14, \\frac 14, \\frac 14, \\frac 14\\right]$", "");

</script>


Stochastic dominance is important due to the following property.

<div class="highlight">
Theorem

:   Let $f \colon \ALPHABET X \to \reals$ be a (weakly) increasing function 
    and $X \sim \pi$ and $Y \sim \mu$ are random variables defined on
    $\ALPHABET X$. Then $X \succeq_s Y$ if and only if
    $$\begin{equation}\label{eq:inc-fun}
      \EXP[f(X)] \ge \EXP[f(Y)]. 
    \end{equation}$$

</div>

#### Proof

We first prove the “if” part. For ease of notation, we use $f_i$ to denote
$f(i)$ and define $\Pi_0 = {\rm M}_0 = 0$. Consider the following:
$$ \begin{align*}
    \sum_{i=1}^n f_i \pi_i 
    &= \sum_{i=1}^n f_i (\Pi_i - \Pi_{i-1})
    \\
    &= \sum_{i=1}^n \Pi_{i-1} (f_{i-1} - f_{i}) + f_n \Pi_n
    \\
    &\stackrel{(a)}{\ge}
    \sum_{i=1}^n {\rm M}_{i-1} (f_i - f_{i-1}) + f_n {\rm M}_n
    \\
    &= \sum_{i=1}^n f_i ({\rm M}_i - {\rm M}_{i-1})
    \\
    &= \sum_{i=1}^n f_i \mu_i, 
  \end{align*}
$$ 
which completes the proof. In the above equations, $(a)$ uses the following
facts:

1. For any $i$, $\Pi_{i-1} \le {\rm M}_{i-1}$ (because of \\eqref{eq:cdf}) and
   $f_{i-1} - f_{i} < 0$ (because $f$ is increasing function). Thus,
   $$\Pi_{i-1}(f_{i-1} - f_i) \ge {\rm M}_{i-1}(f_{i-1} - f_i). $$
2. $\Pi_n = {\rm M}_n = 1$. 



Now consider the “only if” part. Suppose for any increasing function $f$,
\\eqref{eq:inc-fun} holds. Given any $i \in \{1, \dots, n\}$, define the function
$f_i(k) = \IND\{k > i\}$, which is an increasing function of $k$. Then,
$$ \EXP[f_i(X)] = \sum_{k=1}^n f_i(k) \pi_k = \sum_{k > i} \pi_k = 1 - \Pi_i.
$$
By a similar argument, we have
$$ \EXP[f_i(Y)] = 1 - {\rm M}_i. $$
Since $\EXP[f_i(X)] \ge \EXP[f_i(Y)]$, we have that $\Pi_i \le {\rm M}_i$. 

---

# Stochastic monotonicity {#stochastic-monotonicity}

It is possible to extend the notion of stochastic dominance to Markov chains.

Suppose $\ALPHABET X$ is a totally ordered set and $\{X_t\}_{t \ge 1}$ is a
time-homogeneous Markov chain on $\ALPHABET X$ with transition probability
matrix $P$. Let $P_i$ denote the $i$-th row of $P$. Note that $P_i$ is a
PMF. 

Definition

:   A Markov chain with transition matrix $P$ is stochastically monotone if 
    $$ P_i \succeq_s P_j, \quad \forall i > j. $$

An immediate implication is the following.

::: highlight :::
Theorem

:   Let $\{X_t\}_{t \ge 1}$ be a Markov chain with transition matrix $P$ and 
    $f \colon \ALPHABET X \to \reals$ is a weakly increasing function.
    Then, for any $x, y \in \ALPHABET X$ such that $x > y$, 
    $$ \EXP[f(X_{t+1}) | X_t = x] \ge \EXP[ f(X_{t+1}) | X_t = y], $$
    if and only if $P$ is stochatically monotone.
:::

---

## Exercises

1. Let $T$ denote a lower triangular matrix with 1's on or below the diagonal
   and 0's above the diagonal. Then 
   $$ T^{-1}_{ij} = \begin{cases}
      1, & \text{if } i = j, \\
     -1, & \text{if } i = j + 1, \\
      0, & \text{otherwise}.
    \end{cases}$$

    For example, for a $4 \times 4$ matrix
    $$
      T = \MATRIX{1 & 1 & 1 & 1 \\ 0 & 1 & 1 & 1 \\ 0 & 0 & 1 & 1 \\ 0 & 0 & 0 & 1},
      \quad
      T^{-1} = \MATRIX{1 & -1 & 0 & 0 \\ 0 & 1 & -1 & 0 \\ 0 & 0 & 1 & -1 \\ 
      0 & 0 & 0 & 1 }.
    $$

    Show the following:

      a. $\pi \succeq_s \mu$ iff $\pi T \ge \mu T$.
      b. $P$ is stochastic monotone iff $T^{-1} P T \ge 0$. 

2. Show that the following are equivalent:

    a. $P$ is stochastically monotone
    b. For any $\pi \succeq_s \mu$, $P \pi \succeq_s P \mu$. 

3. Show that if $P$ and $Q$ have the same dimensions and are stochastically
   monotone, then so are:

    a. $\lambda P + (1 - \lambda) Q$, where $\lambda \in (0,1)$.
    b. $P Q$
    c. $P^k$, for $k \in \integers_{> 0}$.

4. Let $\pi_t$ denote the distribution of a Markov chain at time $t$. Suppose
   $\pi_0 \succeq_s \pi_1$. Then $\pi_t \succeq_s \pi_{t+1}$. 


## References

Stochastic dominance has been employed in various areas of economics, finance,
and statistics since the 1930s. See @Levy1992 and @Levy2015 for detailed
overviews. The notion of stochastic monotonicity for Markov chains is due to
@Daley1968. The characterization of stochastic monotonicity in Exercises 1--4
are due to @Keilson1977.
