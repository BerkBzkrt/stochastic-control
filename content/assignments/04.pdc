---
title: Assignment 4
due: 9 Feb, 2018
marks: 10
---

1.  A hunter is interested in optimal scheduling of hunting during an
    expedition that may last up to $T$ days. The hunter has two options on
    each day: he may go out to hunt or he may decide to stop the expedition
    and go back home.

    * Going out to hunt costs $c$ units per day with the possibility of
      capturing one animal. The probability of capture depends on the
      population $n$: probability of a capture is $p(n)$; 
      probability of no capture is $1 - p(n)$. In case of a capture, the
      hunter gets a reward of one unit; otherwise, he gets no reward.
    * If he decides to stop the hunting expedition, the hunter does not
      get any opportunity to hunt in the future, and as such receives no
      reward in the future. There is no cost associated with taking this
      action. 
    * The hunter must return back at the end of $T$ days.

    Assume the following:

    i) The hunter knows the initial population $N$.
    ii) The time scale is such that the population does not change due to
        natural causes (birth or death).
    iii) The probability that the hunter makes more than one capture a day
        is negligible.
    iv) The function $p(n)$ is monotonically increasing in $n$. 

    For the above system:

    a.  Write a dynamical model with the state as the current population.
        Argue that the above is an optimal stopping problem with perfect state
        observations and write the dynamic program for this system.

        **Note**: You can write the dynamic program in two ways: either to
        maximize reward or to minimize cost. You may use either of these
        alternatives.

    b.  Let $位$ be the smallest integer such that $p(位) > c$. Show that
        it is optimal to stop hunting when the current population falls below
        $位$.

        **Hint**: The above result is equivalent to saying that the value
        function is zero if and only if the current population is less
        than $位$. 



2.  Consider a discrete-time time-homogeneous Markov chain with state space
    $\integers _ {> 0}$ and transition probabilities $\{ P(i,j) : i, j \in
    \integers _ {> 0} \}$. 

    At each time instant, a decision maker perfectly observes the state of the
    system and decides to either: (i) explore further and incurs an per-step
    cost of $c$; (ii) exploit the system in its current state, that gives a
    terminal reward of $r(X_t)$. The exploit decision is terminal in the sense
    that once an exploit decision is made, no further costs or rewards occur.
    At time $T$, the decision maker must choose the exploit option.

    a.  Write down the dynamic programming equation for the above model.
        (Expand the expectation in the DP equation in terms of the variables
        defined above).

    b.  Show that for a fixed $x$, the value function is non-increasing in
        $t$. 

    c.  Define for $t = 1, \dots, T-1$ the set
        $$H_t = \{ x \in \integers_{ > 0 } : g^*_t(x) = \text{exploit} \}.$$  
        Assume that $H_{T-1}$ has the following property:
        
        **(P1)** 
        Whenever $i \in H_{T-1}$ and $j \not\in H_{T-1}$, then $P(i,j) = 0$. 

        Show that under property (P1): $$H_{T-1} = H_{T-2} = \cdots = H_1.$$

    d.  Suppose that for every $x \in \integers _ {> 0}$:
        $$ P(x,x) = P(x,x+1) = \frac 12 
           \quad\text{and}\quad
           r(x) = k ( 1 - 2^{-x})$$
        where $k$ is a positive constant. Prove that in this case it is
        optimal to stop at the first instant of time the Markov chain enters
        the set
        $$ M = \{ m, m + 1, m + 2, \dots \}$$
        where
        $$ m = \min \{ x \ge 0 : 2^x \ge k/(4c) \}$$

