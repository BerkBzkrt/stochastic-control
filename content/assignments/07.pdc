---
title: Assignment 7
marks: 10
due: 4 April, 2018
draft: true
---

1. A person is offered $N$ free plays to be distributed as he pleases between
   two slot machines $A$ and $B$. Machine $A$ pays $\alpha$ dollars with known
   probability $s$ and nothing with probability $(1-s)$. Machine $B$ pays
   $\beta$ dollars with probability $p$ and nothing with probability $(1-p)$.
   The person does not know $p$ but has an a priori probability distribution
   function $f(p)$ for $p$. The problem is to find a playing policy that
   maximizes expected profit.

     Suppose at the $t$-th time step, the person has played machine $B$, $m + n$
     times, where $m$ denotes the number of successes and $n$ the number of
     failures. Let $\xi(m,n)$ denote the probability that the next play of
     machine $B$ will yield a success, that is,
     $$\xi(m,n) = \frac {\int_{0}^1 p^{m+1} (1 - p)^n f(p) dp }
                        {\int_{0}^1 p^m     (1 - p)^n f(p) dp }$$
     Note that $\xi(m,n)$ can be precomputed for all values of $m$ and $n$. 

     a. Show that $(m,n)$ is an information state for the above problem. 
     b. Write down a dynamic program in terms of $(m,n)$. 
     c. Find an optimal strategy for $T = 6$, $\alpha = \beta = 1$, $s = 0.6$,
        $f(p) = 1$ for $0 \le p \le 1$. (For each time, you need to identify the
        pairs $(m,n)$ where machine $B$ should be playerd.)

2. Consider the following modification of the sequential hypothesis testing
   problem considered in class. As in the model discussed in class, there are
   two hypothesis $h_0$ and $h_1$. The a priori probability that the hypothesis
   is $h_0$ is $p$.

      In contrast to the model discussed in class, there are $N$ sensors. If
      sensor $m$ is used at time $t$ and the underlying hypothesis is $h_i$,
      then the observation $Y_t$ is distrubted according to pdf (or pmf)
      $f^m_j(y)$. The cost of using sensor $m$ is $c_m$. 

      Whenever the decision maker takes a measurement, he picks a sensor $m$
      uniformly at random from $\{1, \dots, N\}$ and observes $Y_t$ according to
      the distribution $f^m_j(\cdot)$ and incurs a cost $c_m$. 

      The system continues for a finite time $T$. At each time $t < T$, the
      decision maker has three options: stop and declare $h_0$, stop and declare
      $h_1$, or continue to take another measurement. At time $T$, the continue
      alternative is unavailable.

      a. Formulate the above problem as a POMDP. Identify an information state
         and write the dynamic programming decomposition for the problem.

      b. Show that the optimal control law has a threshold property, similar to
         the threshold propertly for the model considered in class.

