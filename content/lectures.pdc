---
title: Lectures
---

Whenever possible, I will post notes on some of the material covered in class,
but that is not guaranteed. This is a graduate class and you are responsible
for taking notes in class and reading the appropriate chapters of the
textbooks.

The notes will be updated as we move along in the course. Please check the
dates on the first page to keep track. If you find any typos/mistakes in the
notes, please let me know. [Pull requests
welcome](https://github.com/adityam/stochastic-control/tree/master/content).

Tue, Jan 7
:   **Introduction and course overview**.

    * Reading: Kumar and Varaiya (Ch 1, 2); Bertsekas (Ch 1).
    * Notes on [stochastic optimization](../mdp/stochastic-optimization)

Thu, Jan 9
:   **Introduction to Markov decision processes (MDPs)**

    * Notes on [MDP theory]
    * Example of [optimal gambling]

Tue, Jan 14
:   **Proof of main results for MDPs**

    * See notes of [MDP theory]

Thu, Jan 16
:   **Linear quadratic regulator**

    * See notes on [LQR]

Tue, Jan 21
:   **Structural properties of MDPs**

    * Inventory management, post-decision state, and control-limit policies. 
      See notes on [inventory management]
    * [Matrix formulation] of MDPs

Thu, Jan 23
:   **Monotonicity of MDPs**

    * [Stochastic dominance, monotonicity][SD], and submodularity
    * [Sufficient conditions for value function and optimal policy to be
      monotone][monotonicity].

Tue, Jan 28

:   * [Power delay tradeoff in wireless communication][power-delay]

Thu, Jan 30

:   * Optimal stopping 
    * Examples of [optimal choice] and [call options]

Tue, Feb 4

:   * Monotonicity of [optimal stopping policies]
    * Introduction to infinite horizon MDPs

Thu, Feb 6

:   * Infinite horizon discounted cost problems
    * Bellman operator, contraction mappings, and Banach fixed point Theorem.

Tue, Feb 11

:   * Bellman operators and their properties. 
    * Introduction to value iteration algorithm.

Thu, Feb 13

:   * Value iteration, policy iteration, and linear programming for discounted
MDPs

Tue, Feb 18

:   * Approximate MDP

Thu, Feb 20

:   * Average cost MDPs

Tue, Feb 25

:   * Relative value iteration and policy iteration
    * Partially observed models, information state

Thu, Feb 27

:   * LQR with exchangeable components

[optimal gambling]: ../mdp/optimal-gambling
[MDP theory]: ../mdp/mdp-functional
[LQR]: ../linear-systems/lqr
[inventory management]: ../mdp/inventory-management
[Matrix formulation]: ../mdp/mdp-matrix
[SD]: ../mdp/stochastic-dominance
[monotonicity]: ../mdp/monotonicity
[power-delay]: ../mdp/power-delay-tradeoff
[optimal choice]: ../optimal-stopping/optimal-choice
[call options]: ../optimal-stopping/call-options
[optimal stopping policies]: ../optimal-stopping/monotonicity-optimal-stopping
