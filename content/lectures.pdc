---
title: Lectures
---

Whenever possible, I will post notes on some of the material covered in class,
but that is not guaranteed. This is a graduate class and you are responsible
for taking notes in class and reading the appropriate chapters of the
textbooks.

The notes will be updated as we move along in the course. Please check the
dates on the first page to keep track. If you find any typos/mistakes in the
notes, please let me know. [Pull requests
welcome](https://github.com/adityam/stochastic-control/tree/master/content).

Wed, Jan 10
:   **Introduction and course overview**.

    * Reading: Kumar and Varaiya (Ch 1, 2); Bertsekas (Ch 1).
    * Notes on [stochastic optimization](../theory/stochastic-optimization)

Fri, Jan 12
:   **Introduction to Markov decision processes (MDPs)**

    * Notes on [MDP theory]
    * Example of [optimal gambling]

Wed, Jan 17
:   **Proof of main results for MDPs**

    * See notes of [MDP theory]

Fri, Jan 19
:   **Linear quadratic regulator**

    * See notes on [LQR]

Wed, Jan 24
:   **Structural properties of MDPs**

    * Inventory management, post-decision state, and control-limit policies. 
      See notes on [inventory management]
    * [Matrix formulation] of MDPs

Fri, Jan 26
:   **Monotonicity of MDPs**

    * [Stochastic dominance, monotonicity][SD], and submodularity
    * [Sufficient conditions for value function and optimal policy to be
      monotone][monotonicity].

Wed, Jan 31

:   * [Power delay tradeoff in wireless communication][power-delay]

Fri, Feb 2

:   * Optimal stopping 
    * Examples of [optimal choice] and [call options]

Wed, Feb 7

:   * Monotonicity of [optimal stopping policies]
    * Introduction to infinite horizon MDPs

Fri, Feb 9

:   * Infinite horizon discounted cost problems
    * Bellman operator, contraction mappings, and Banach fixed point Theorem.

Wed, Feb 14

:   * Bellman operators and their properties. 
    * Introduction to value iteration algorithm.

Fri, Feb 16

:   * Value iteration, policy iteration, and linear programming for discounted
MDPs

Wed, Feb 21

:   * Approximate MDP

Fri, Feb 23

:   * Average cost MDPs

Wed, Feb 28

:   * Relative value iteration and policy iteration
    * Partially observed models, information state

Fri, Mar 2

:   * LQR with exchangeable components

[optimal gambling]: ../examples/optimal-gambling
[MDP theory]: ../theory/mdp-functional
[LQR]: ../theory/lqr
[inventory management]: ../examples/inventory-management
[Matrix formulation]: ../theory/mdp-matrix
[SD]: ../theory/stochastic-dominance
[monotonicity]: ../theory/monotonicity
[power-delay]: ../theory/power-delay-tradeoff
[optimal choice]: ../examples/optimal-choice
[call options]: ../examples/call-options
[optimal stopping policies]: ../theory/monotonicity-optimal-stopping
