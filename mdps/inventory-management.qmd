---
title: Inventory Management
keywords:
  - inventory management
  - post-decision state
  - base-stock policy
  - structural results
execute:
  echo: false
  freeze: true
  cache: true
---

::: {.column-margin}
![Image credit:
https://hbr.org/2015/06/inventory-management-in-the-age-of-big-data][inventory]

[inventory]: ../images/banners/inventory.jpg "How to manage inventory" { width=100% style='max-width:30em;' }
:::

:::{.callout-note icon=false appearance="simple"}
# <i class="bi bi-journal-text text-primary"></i> Summary
The inventory management example illustrates that a dynamic programming formulation is useful even when a closed form solution does not exist. This model also introduces the idea of *post-decision state*, which is useful in many contexts.
:::

Imagine a retail store that stockpiles products in its warehouse to
meet random demand. Suppose the store procures new stocks at the end of each
day (and that there is no lead time and stocks are available next morning).
Let 

* $S_t \in \integers$ denote the amount of stock at the beginning of day $t$,
* $A_t \in \integers_{\ge 0}$ denote the stock ordered (and immediately delivered) at the beginning of day $t$, and
* $W_t \in \integers_{\ge 0}$ denote the demand during day $t$. 

The random variables $\{W_t\}_{t \ge 1}$ are i.i.d. with known probability
distribution. 

Excess demand is backlogged and filled when new inventory becomes available.
Thus, the stock evolves according to
$$S_{t+1} = S_t + A_t - W_t,$$
where negative stock denotes backlogged demand. 

The cost incurred during day $t$ consists of two components:

*   A procurement cost of $p A_t$, where $p$ is the cost per unit. 
*   At the end of the day, if the stock $S_{t+1}$ is positive, then there is a
    holding cost of $c_h S_{t+1}$ for storing excess inventory; if $S_{t+1}$ is
    negative, then a shortage cost of $-c_s S_{t+1}$ for unfilled demand. 

      We denote this cost by $h(S_{t+1})$, where
      $$ h(s) = \begin{cases} 
         c_h s, & \text{if } s \ge 0 \\
        -c_s s, & \text{if } s < 0
      \end{cases}$$

## Dynamic programming decomposition

$\def\S{\mathbb{S}}$ 

The above model is a Markov decision process.[^cost] Therefore, the optimal solution is given by dynamic programming. 

Instead of $\integers$, we use $\S$ to denote the possible values of states. The reason is that we will later consider the case when the state space is the set of reals, and we can still use the same equations.

[^cost]: Part of the per-step cost depends on the _future_ state $S_{t+1}$.
  It is easy to show that the standard MDP model works even when the per-step
  cost is a function of $(S_t, A_t, S_{t+1})$

:::{#prp-inventory-DP}
## Dynamic programming
Define the following value functions $V_t \colon \S \to \reals$ 
$$V_{T+1}(s) = 0$$
and for $t \in \{T, \dots, 1\}$
$$ Q_t(s, a) = p a + \EXP[ h(s + a - W_t) + V_{t+1}( s + a - W_t ) ]$$
and
$$ \begin{align*}
  V_t(s) &= \min_{a \in \S_{\ge 0}} Q_t(s,a) \\
  π_t(s) &= \arg \min_{a \in \S_{\ge 0}} Q_t(s,a) 
  \end{align*}
$$
Then the strategy $π = (π_1, \dots, π_T)$ is optimal. 
::: 

It is possible to simplify the above dynamic program by exploiting a feature
of the model. Notice that the dynamics can be split into two parts: 
$$ \begin{align*}
    Z_t &= S_t + A_t,  \\
    S_{t+1} &= Z_t - W_t.
   \end{align*}
$$
The first part, $Z_t$, depends only on the current state and action. The
second part depends only on $Z_t$ and a primitive random variable. 
In this particular model, $Z_t$ is a deterministic function of $S_t$ and
$A_t$; but, in general, it could be stochastic as well; what is important is
that the second part should only depend on $Z_t$ and a primitive random
variable. The variable $Z_t$ is sometimes called the __post-decision state__. 

Now write the dynamic program in terms of the post-decision state as follows.
Define
$$ H_t(z) = \EXP[ h(z - W) + V_{t+1}(z-W) ].$$
Then the value function and optimal policy at time $t$ can be written as:
$$ \begin{align*}
  V_t(s) &= \min_{a \in \S_{\ge 0}} \bigl\{ pa + H_t(s + a) \bigr\}, \\
  π_t(s) &= \arg \min_{a \in \S_{\ge 0}} \bigl\{ pa + H_t(s + a) \bigr\}.
\end{align*} $$

Note that the problem at each step is similar to the [newsvendor] problem. So,
similar to that model, we try to see if we can establish qualitative
properties of the optimal solution.

[newsvendor]: ../../stochastic/newsvendor

```{julia}
#| output: false
# Install packages
using Pkg; Pkg.activate(".")
# for pkg in ["IJulia", "Revise", "Distributions", "OffsetArrays", "DataFrames", "JSON"]
#    Pkg.add(pkg)
# end
# for url in [ "https://github.com/adityam/MDP.jl.git"]
#   Pkg.add(url=url)
# end
# # Installing Jupyter Cache
# Pkg.add("Conda")
# using Conda
# Conda.add("jupyter-cache")

using Revise

using Distributions: Binomial, pdf, cdf
using OffsetArrays
using MDP

using DataFrames
```

```{julia}

n, q = 50, 0.4
ch, cs, p = 2, 5, 1

Pw = Binomial(n,q)

demand_df = DataFrame(demand=Float64[], probability=Float64[], cumulative=Float64[])
for k in 0:n
  push!(demand_df, (k, pdf(Pw,k), cdf(Pw,k)) )
end
ojs_define(W = demand_df, ch=ch, cs=cs, p=p)
```

To fix ideas, let's solve this dynamic program for a specific instance. 

```{ojs}
//| label: fig-demand
//| fig-cap: Demand Distribution
//| column: margin
demandPlot = Plot.plot({
  grid: true,
  marks: [
    // Axes
    Plot.ruleX([0]),
    Plot.ruleY([0]),
    // Data
    Plot.line(W, {x:"demand", y:"probability",curve:"step-after"})
  ]
})
```

We assume that the demand is distributed according to a Binomial(50,0.4) distribution, as shown in @fig-demand.
We assume that the model parameters are as given below:

$$
c_h = 2,\quad c_s = 5,\quad p = 1. 
$$

We consider a horizon $T = 15$, and solve the dynamic program shown above. The optimal value function and policy are shown below:

```{julia}
L = 500
S = -L:L
A = 0:2L+1
W = 0:n

T = 15
ojs_define(T=T)

function generate_binomial_demand(n,q,ch,cs,p,T)
  Pw = Binomial(n,q)
  h(s) = (s >= 0) ? ch*s : -cs*s

  function bellmanUpdate!(v_next, π_next, v; discount=1.0)
      # Assume that v is of size 2L + 1
      # Construct a post-decision state value function
      H = OffsetArray(zeros(3L+1),-L:2L)
      # h(z) = E[ h(z-W) + γ V(z-W) ]
      for z ∈ -L:2L, w ∈ W
          next_s = clamp(z-w, -L, L)
          H[z] += ( h(z-w) + discount * v[next_s] )* pdf(Pw,w)
      end

      # V(s) = min_{a } { p*a + H(s+a) }
      for s ∈ S
          opt = 0
          val = H[s]

          for a ∈ A
              next_z = clamp(s+a, -L, 2L)
              newVal = p*a + H[next_z]
              if newVal <= val
                  opt = a
                  val = newVal
              end
          end
          v_next[s] = val
          π_next[s] = opt
      end
  end
  model = DynamicModel(bellmanUpdate!; objective=:Min)
  v_final = OffsetArray(zeros(size(S)), S)
  (V, π) = finiteHorizon(model, v_final, horizon=T)
  return (S,V,π)
end

df = DataFrame(time=Int[], state=Int[], value=Float64[], policy=Int[], shortage=Float64[])

Cs = range(start=0.5, step=0.5, stop=5.0)

for cs in Cs
  (S,V,π) = generate_binomial_demand(n,q,ch,cs,p,T)
  for t in 1:T, s in S
    push!(df, (t, s, V[t][s], π[t][s],cs))
  end
end

ojs_define(DP = df)
```

```{ojs}
//| layout-ncol: 2
viewof time = Object.assign(Inputs.range([1, T], {label: "t", step: 1, value: 1 }), {style: '--label-width:20px'})
viewof cs_val = Object.assign(Inputs.range([0.5, 5], {label: "cs", step: 0.5, value: cs }), {style: '--label-width:20px'})
```

```{ojs}
//| layout-ncol: 2
//| fig-cap: Dynamic programming solution for the example
//| fig-subcap:
//|     - Value function
//|     - Optimal policy
valuePlot = Plot.plot({
  grid: true,
  y: { domain: [0, 500] },
  x: { domain: [-50, 50] },
  marks: [
    // Axes
    Plot.ruleX([0]),
    Plot.ruleY([0]),
    // Data
    Plot.line(DP.filter(d => d.time == time && d.shortage == cs_val), {x:"state", y:"value", curve:"step-after"})
  ]
})

actionPlot = Plot.plot({
  grid: true,
  y: { domain: [0, 35] },
  x: { domain: [-10, 30] },
  marks: [
    // Axes
    Plot.ruleX([0]),
    Plot.ruleY([0]),
    // Data
    Plot.line(DP.filter(d => d.time == time && d.shortage == cs_val), {x:"state", y:"policy", curve:"step-after"})
  ]
})
```

The plots above suggest that the optimal policy has a structure. Play around
with the value of the shortage cost to see if that structure is retained.


We will now see how to prove the structure of optimal policy.

## Structure of optimal solution

In this section, we assume that the state space $\S$ is equal to $\reals$ (instead of $\integers$). See @exr-inventory-discrete for the case when $\S$ is equal to $\integers$.

For this setting, the optimal policy is then characterized as follows.

:::{#thm-inventory-structure}
Define 
$$ s^*_t = \arg \min_{z \in \reals} \bigl\{ p z + H_t(z) \bigr\} . $$
Then, 
\begin{equation} \label{eq:V}
V_t(s) = \begin{cases}
  H_t(s_t) + p (s_t - s), &\text{if } s \le s^*_t \\
  H_t(s)   , & \text{otherwise }
\end{cases} 
\end{equation}
and
\begin{equation}\label{eq:pi}
  π_t(s) = \begin{cases}
  s^*_t - s, &\text{if } s \le s^*_t \\
  0, & \text{otherwise }
\end{cases}\end{equation}

Furthermore, for all $t$, $H_t(z)$ and $V_t(s)$ are convex in $z$
and $s$, respectively. 
:::

::: {.callout-tip collapse="false"}

## Base-stock policy
The optimal policy given by \\eqref{eq:pi} is called a _base-stock_
policy. It states that there is a base-stock level $\{s^*_t\}_{t \ge 1}$
for every time step. If, at the beginning of time $t$, the value of the
current stock is below the base stock level $s^*_t$, then the optimal
decision is to order more goods so that the level of the stock equals the
base stock level. 
:::

```{ojs}
points = {
  const n = 100
  const Smax = 10

  const f = function(s) { return (s-5)**2 }

  var points = new Array()
  var W = [0, 1, 2 ]
  var Pw = [1/3, 1/3, 1/3]

  var idx = 0
  for( var i = 0; i < n; i++) {
    var s = Smax*i/n
    var sum = 0
    var min = 10000 // CHECK: Large positive number
    for(var w = 0; w < W.length; w++) {
      sum += f(s + W[w])
      min = Math.min(min, f(s+W[w]))
      points[idx++] = { state: s, value: f(s + W[w]), noise:W[w], type: "noise" }
    }
    points[idx++] = { state: s, value: sum/W.length, type: "average" }
    points[idx++] = { state: s, value: min, type: "minimum" }
  }
  return points
  }
```

We first establish some preliminary results.

```{ojs}
//| column: margin
//| fig-cap: An example showing that the average of convex functions is convex
averagePlot = Plot.plot({
  grid: true,
  y: { domain: [0, 25] },
  marginRight: 40,
  marginTop: 40,

  marks: [
    // Axes
    Plot.ruleX([0]),
    Plot.ruleY([0]),
    // Data
    Plot.line(points, {filter: d =>  d.value <= 25 && d.type == "noise", 
                       x:"state", y:"value", z:"noise", stroke:"gray"}),
    Plot.text(points, Plot.selectLast({
      filter: d => d.value <= 25 && d.type == "noise", 
      x: "state",
      y: "value",
      z: "noise",
      text: d => "w = " + d.noise,
      textAnchor: "start",
      dx: 3
    })),
    Plot.line(points, {filter: d => d.value <= 25 && d.type == "average", 
                       x:"state", y:"value", stroke:"red", strokeWidth: 4}),
    Plot.text(points, Plot.selectLast({
      filter: d => d.value <= 25 && d.type == "average", 
      x: "state",
      y: "value",
      z: "noise",
      text: "type",
      textAnchor: "start",
      fill:"red",
      dy: -10
    }))
  ]
})
```
1. For any convex function $f \colon \reals \to \reals$, 
   $F(s) = \EXP[ f(s - W) ]$ is convex.

   **Proof** For any realization of $W$, $f(s - w)$ is convex in $s$.
   The expectation w.r.t. $W$ is simply the sum of convex functions and is,
   therefore, convex. 


2. For any convex function $f \colon \reals \to \reals$, 
   let $s^* =  \arg \min_{s \in \reals} f(s)$.[^unique] Then,
   $$\arg \min_{a \in \reals_{\ge 0}} f(s + a) = \begin{cases}
   0, & \text{if } s > s^*, \\
   s^* - s, & \text{if } s \le s^*
   \end{cases}$$
   and
   $$F(s) = \min_{a \in \reals_{\ge 0}} f(s+a) = \begin{cases}
    f(s), & \text{if } s > s^* \\
    f(s^*), & \text{if } s \le s^*
    \end{cases}$$
    and $F(s)$ is convex in $s$.


[^unique]: Note that $s^*$ is unique if $f$ is strictly convex. If not, we take $s^*$ to be the _smallest_ arg min.

```{ojs}
//| column: margin
//| label: fig-min
//| fig-cap: An example showing the minimum of $f(s)$, $f(s+1)$, $f(s+2)$. 
minimumPlot = Plot.plot({
  grid: true,
  y: { domain: [0, 25] },
  marginRight: 60,
  marginTop: 40,

  marks: [
    // Axes
    Plot.ruleX([0]),
    Plot.ruleY([0]),
    // Data
    Plot.line(points, {filter: d =>  d.value <= 25 && d.type == "noise", 
                       x:"state", y:"value", z:"noise", stroke:"gray"}),
    Plot.text(points, Plot.selectLast({
      filter: d => d.value <= 25 && d.type == "noise", 
      x: "state",
      y: "value",
      z: "noise",
      text: d => "f(s +" + d.noise + ")",
      textAnchor: "start",
      dx: 3
    })),
    Plot.line(points, {filter: d => d.value <= 25 && d.type == "minimum", 
                       x:"state", y:"value", stroke:"red", strokeWidth: 4}),
    Plot.text(points, Plot.selectLast({
      filter: d => d.value <= 25 && d.type == "minimum", 
      x: "state",
      y: "value",
      text: "type",
      textAnchor: "start",
      fill:"red",
      dy: -10
    }))
  ]
})
```


We first see an illustration of $F(s) = \min\{ f(s), f(s+1), f(s+2) \}$ in @fig-min. Note
that the resulting function is not convex because $a$ takes only discrete
values. But the plot shows that the minimum will look like when we allow
$a$ to take continuous values. 


If there were no constraint on $a$, then the minimizer will be $a = s^* -
s$. If $s \le s^*$, then $a = s^* -s \in \reals_{\ge 0}$ is the minimizer for
the constrained problem as well. On the other hand, if $s \ge s^*$, then
the function $f(s + a)$ is increasing as a function of $a$. Hence,
the minimizer for the constrained problem is $a = 0$. 


::: {.callout-note collapse="true"}
#### Proof of the structural result {-}
Now to prove the result, we define 
$$ f_t(z) = py + H_t(z). $$
Then,
$$ V_t(s) = \min_{a \in \reals_{\ge 0}} \bigl\{ p(s + a) + H_t(s + a)
\bigr\} - p s 
= \min_{a \in \reals_{\ge 0}} f_t(s+a) - p s.
$$
As usual, we prove the result by backward induction. For $t=T$, 
$$\bar Q_T(z) = \EXP[ h(z - W) ] $$
which is convex because $h(z)$ is convex. $f_T(z) = p z + Q_T(z)$ is the
sum of a linear function and convex function and is, therefore, convex. 
Then, by fact 2 above,
$$π_T(s) = \arg \min_{a \in \reals_{\ge 0}} f_T(s+a) = \max(s^*_T - s, 0)
$$
and
$$V_T(s) = \min_{a \in \reals_{\ge 0}} f_T(s + a) - px = 
  \begin{cases}
    f_T(s) - p s, & \text{if } s > s^*_T \\
    f_T(s^*_T) - px, & \text{if } s \le s^*_T.
  \end{cases}
$$
Substituting $f_t(z) = p z + H_t(z)$, we get that both
$V_T$ and $π_T$ have the desired form and $V_T$ is convex. This forms the basis of
induction.

Now assume that $V_{t+1}(s)$ is convex and of the form \\eqref{eq:V}. Now note
that, by fact 1,
$$ H_t(z) = \EXP[ h(z - W) + V_{t+1}(z - W) ]$$
is convex. Hence, $f_t(z)$ is convex. Therefore, 
by fact 2 above,
$$ π_t(s) = \max(s^*_t - s, 0)$$
and $V_t(s)$ is of the desired form and convex. 

Thus, the result is holds by induction.
:::



## Exercises {-}

::: {#exr-inventory-discretization}

Consider the case when the state space $\S$ is equal to $\integers$ (i.e., all $S_t, A_t, W_t \in \integers$). In this case, we need the option of discrete convexity, which we explain below.

{{< include ../snippets/discrete-convexity.qmd >}}

1. Argue that the preliminary properties of convex functions established in the preliminary results also hold for discrete convex functions $f \colon Z \to \reals$.

2. Argue that the structure of optimal policies continue to hold, i.e., there exists a sequence $\{s_t^*\}$, $s_t \in \integers$ such that the policy 
   $$
    π_t(s) = \begin{cases}
    s^*_t - s, & \text{if $s \le s_t^*$} \\
    0, & \text{otherwise}.
    \end{cases}
   $$


_Remark_: Exactly the same argument works if the state space $\{ n \Delta : n \in \integers \}$.    
:::

## Notes {-}

Inventory management models with deterministic demand were introduced by @Harris1913. The mathematical model of inventory management considered here was originally proposed by @Arrow1951. The optimality of base-stock policy was established by @Bellman1955. See the notes on [infinite horizon](inventory-management-revisited.html) version of this model to see how to find the threshold in closed form. 

A model where $\S = \reals$ but $\ALPHABET A = \integers_{\ge 0}$ is considered in @Veinott1965. It's generalization with non-zero ordering cost is considered in @Tsitsiklis1984. 
