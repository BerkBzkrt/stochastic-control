<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<head>
  <meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="author" content="Aditya Mahajan" />
  <meta name="title" content="ECSE 506: Stochastic Control and Decision Theory" />
  <title>ECSE 506: Stochastic Control and Decision Theory</title>
  

  <link rel="stylesheet" href="https://adityam.github.io/stochastic-control//css/style.css" type="text/css" /><script type="text/javascript"
    src="https://adityam.github.io/stochastic-control/js/mathjax-local.js" defer>
  </script>
  <script type="text/javascript" id="MathJax-script" defer
    src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-svg.js">
  </script>

  <script type="module" defer
    src="//instant.page/3.0.0"
    integrity="sha384-OeDn4XE77tdHo8pGtE1apMPmAipjoxUQ++eeJa6EtJCfHlvijigWiJpD7VDPWXV1">
  </script>
</head>
<body>
<div id="content">
<div class="title">
  <h1>ECSE 506: Stochastic Control and Decision Theory </h1>
  <h2><a href="http://www.cim.mcgill.ca/~adityam/">Aditya Mahajan</a> <br/>
      Winter 2020
  </h2>
  <h3><a href="https://adityam.github.io/stochastic-control/ ">About</a>
	&nbsp;<small><small>|</small></small>&nbsp;
    <a href="https://adityam.github.io/stochastic-control//lectures">Lectures</a></span>
	&nbsp;<small><small>|</small></small>&nbsp;
    <a href="https://adityam.github.io/stochastic-control//notes">Notes</a></span>
	&nbsp;<small><small>|</small></small>&nbsp;
    <a href="https://adityam.github.io/stochastic-control//coursework">Coursework</a>
</h3>
</div>



<div class="h1-title">Prelim: Change of Measure</div>

<h1 data-number="1" id="change-of-measure-of-a-single-random-variable."><span class="header-section-number">1</span> Change of measure of a single random variable.</h1>
<div class="highlight">
<dl>
<dt><span id="thm:change-of-measure" class="pandoc-numbering-text thm"><strong>Theorem 1</strong></span></dt>
<dd><p>Let <span class="math inline">\((\Omega, \mathcal F, P)\)</span> be a probability space and <span class="math inline">\(\Lambda\)</span> be an almost surely non-negative random variable such that <span class="math inline">\(\EXP[\Lambda] = 1\)</span>. For any <span class="math inline">\(A \in \mathcal F\)</span>, define <span class="math display">\[ P^\dagger(A) = \int_A \Lambda(\omega) dP(\omega). \]</span> Then,</p>
<ul>
<li><span class="math inline">\(P^\dagger\)</span> is a probability measure.</li>
<li>For any random variable <span class="math inline">\(X\)</span>, <span class="math display">\[ \EXP^\dagger[X] = \EXP[ \Lambda X]. \]</span></li>
<li>If <span class="math inline">\(\Lambda\)</span> is almost surely positive, then <span class="math display">\[ \EXP[X] = \EXP^\dagger \left[ \frac{X}{\Lambda} \right]. \]</span></li>
</ul>
</dd>
</dl>
</div>
<h4 class="unnumbered" data-number="" id="proof">Proof</h4>
<p>By definition. <span class="math inline">\(P^\dagger(\emptyset) = 0\)</span> and <span class="math inline">\(P^\dagger(\Omega) = \EXP[ \Lambda] = 1\)</span>. Since <span class="math inline">\(\Lambda\)</span> is almost surely non-negative, <span class="math inline">\(P^\dagger(A) \ge 0\)</span>. Hence, <span class="math inline">\(P^\dagger\)</span> is a probability measure.</p>
<p>The second and the third part follow from observing that <span class="math display">\[ dP^\dagger(\omega) = \Lambda(\omega) dP(\omega). \]</span></p>
<hr />
<p>Given two measures <span class="math inline">\(\mu\)</span> and <span class="math inline">\(\nu\)</span> on a measurable space <span class="math inline">\((\Omega, \mathcal F)\)</span>, we say that the measure <span class="math inline">\(\mu\)</span> is <em>absolutely continuous</em> with respect to <span class="math inline">\(\nu\)</span> (denoted by <span class="math inline">\(\mu \ll \nu\)</span>) if for any <span class="math inline">\(A \in \mathcal F\)</span>, <span class="math display">\[
  \nu(A) = 0 \implies \mu(A) = 0.
\]</span></p>
<div class="highlight">
<dl>
<dt><span id="thm:Radon-Nikodym" class="pandoc-numbering-text thm"><strong>Theorem 2</strong></span></dt>
<dd><p><strong>(Radon-Nikodym).</strong> Given two probability measures <span class="math inline">\(P\)</span> and <span class="math inline">\(P^\dagger\)</span> on a measurable space, if <span class="math inline">\(P^\dagger\)</span> is absolutely continuous with respect to <span class="math inline">\(P\)</span>, then there exists an almost surely positive random variable <span class="math inline">\(\Lambda\)</span> such that <span class="math inline">\(\EXP[\Lambda] = 1\)</span> and for any <span class="math inline">\(A \in \mathcal F\)</span>, <span class="math display">\[
  P^\dagger(A) = \int_A \Lambda(\omega) dP(\omega). 
\]</span> Such a <span class="math inline">\(\Lambda\)</span> is called the <em>Radon-Nikodym derivative</em> of <span class="math inline">\(P^\dagger\)</span> with respect to <span class="math inline">\(P\)</span>, and is written as <span class="math display">\[
  \Lambda = \frac{ dP^\dagger } {dP}.
\]</span></p>
</dd>
</dl>
</div>
<dl>
<dt>Remark</dt>
<dd><ul>
<li><p>The Radon-Nikodym theorem provides the reverse property of <a href="#thm:change-of-measure" title="Theorem 1"><span class="pandoc-numbering-link thm">Theorem 1</span></a>. Given two measures <span class="math inline">\(μ \ll ν\)</span>, <span class="math display">\[
  \int_{A} f dν = \int_A f \frac{dν}{dμ} dμ.
\]</span> Thus, in <a href="#thm:change-of-measure" title="Theorem 1"><span class="pandoc-numbering-link thm">Theorem 1</span></a>, we are constructing a new probaility measure <span class="math inline">\(P^\dagger\)</span> such that <span class="math inline">\(dP^\dagger/dP = Λ\)</span>.</p></li>
<li><p>The Radon-Nikodym Theorem is typically stated for <span class="math inline">\(σ\)</span>-finite measures. The above statement is a specialization of Radon-Nikodym Theorem to probability measures.</p></li>
<li><p>In statistical signal processing literature, the Radon-Nikodym derivative is sometimes known as the likelihood ratio. In the reinforcement learning literature, it is called importance sampling.</p></li>
<li><p>The density of a random variable is the Radon-Nikodym derivative with respect to the Lebesgue measure.</p></li>
<li><p>The Radon-Nikodym derivative satisfies the product rule. If <span class="math inline">\(μ \ll ν \ll λ\)</span>, then <span class="math display">\[ 
  \frac {dμ}{dλ} = \frac {dμ}{dν} \frac {dν}{dλ},
  \quad λ~\text{a.s.}.
\]</span></p></li>
<li><p>The Kullback-Leibler divergence between two probability measures <span class="math inline">\(P\)</span> and <span class="math inline">\(Q\)</span> defined on <span class="math inline">\((\Omega, \mathcal F)\)</span> may be written as <span class="math display">\[
  D_{\text{KL}}( P \| Q) = \int_\Omega \log \left ( \frac {dP}{dQ} \right)
  dP.
\]</span></p></li>
</ul>
</dd>
</dl>
<h1 data-number="2" id="conditional-expectation-under-change-of-measure"><span class="header-section-number">2</span> Conditional expectation under change of measure</h1>
<div class="highlight">
<dl>
<dt><span id="thm:conditional-change-of-measure" class="pandoc-numbering-text thm"><strong>Theorem 3</strong></span></dt>
<dd><p>Consider two probability measures <span class="math inline">\(P\)</span> and <span class="math inline">\(P^\dagger\)</span> on <span class="math inline">\((Ω, \mathcal F)\)</span> such that <span class="math inline">\(P^\dagger \ll P\)</span>. Let <span class="math inline">\(Λ\)</span> denote the Radon-Nikodym derivative of <span class="math inline">\(P^\dagger\)</span> with respect to <span class="math inline">\(P\)</span> and <span class="math inline">\(\mathcal G\)</span> be any sub sigma-field of <span class="math inline">\(\mathcal F\)</span>. Then, for any random variable <span class="math inline">\(X\)</span> <span class="math display">\[
  \EXP^\dagger[ X | \mathcal G ] = 
  \dfrac{ \EXP[ Λ X | \mathcal G ] } { \EXP [ Λ | \mathcal G ] },
  \quad P^\dagger~\text{a.s.}
\]</span></p>
</dd>
</dl>
</div>
<h4 class="unnumbered" data-number="" id="proof-1">Proof</h4>
<p>Let <span class="math inline">\(G \in \mathcal G\)</span>. Then:</p>
<p><span class="math display">\[\begin{align*}
  \int_G \EXP[ Λ X | \mathcal G] dP 
  &amp;\stackrel{(a)}= \int_G Λ X dP \\
  &amp;\stackrel{(b)}= \int_G X dP^\dagger \\
  &amp;\stackrel{(c)}= \int_G \EXP^\dagger[ X | \mathcal G] dP^\dagger \\
  &amp;\stackrel{(d)}= \int_G \EXP^\dagger[ X | \mathcal G] Λ dP \\
  &amp;\stackrel{(e)}= \int_G \EXP[ \EXP^\dagger[ X | \mathcal G]  Λ | \mathcal G] dP \\
  &amp;\stackrel{(f)}= \int_G \EXP^\dagger[ X | \mathcal G]  \EXP[ Λ | \mathcal G] dP \\
\end{align*}\]</span> where (a), (c), and (e) follow from the definition of conditional expectation, (b) and (d) follow from change of measures, and (f) follows because <span class="math inline">\(\EXP^\dagger[ X | \mathcal G]\)</span> is <span class="math inline">\(\mathcal G\)</span>-measurable. Thus,</p>
<p><span class="math display">\[ \EXP[ Λ X | \mathcal G ] = \EXP^\dagger[ X | \mathcal G ] \EXP[ Λ | \mathcal G]. \]</span></p>
<h1 data-number="3" id="change-of-measure-for-a-process"><span class="header-section-number">3</span> Change of measure for a process</h1>
<p>Consider a probability space <span class="math inline">\((Ω, \mathcal F)\)</span> and let <span class="math inline">\(P\)</span> and <span class="math inline">\(P^\dagger\)</span> be two probability measures on <span class="math inline">\((Ω, \mathcal F)\)</span> such that <span class="math inline">\(P^\dagger \ll P\)</span>. Let <span class="math inline">\(Λ\)</span> denote the Radon-Nikodym derivative of <span class="math inline">\(P^\dagger\)</span> with respect to <span class="math inline">\(P\)</span>.</p>
<p>Let <span class="math inline">\(\{\mathcal F_t\}_{t \ge 0}\)</span> be a filtration on <span class="math inline">\((Ω, \mathcal F)\)</span>. Then, we can define the <em>Radon-Nikodym derivative process</em> <span class="math display">\[
  Λ_t = \EXP[ Λ | \mathcal F_t ].
\]</span></p>
<div class="highlight">
<dl>
<dt><span id="thm:derivative-process" class="pandoc-numbering-text thm"><strong>Theorem 4</strong></span></dt>
<dd><ul>
<li><p>The Radon-Nikodym derivative process <span class="math inline">\(\{Λ_t\}_{t \ge 0}\)</span> is a martingale with respect to <span class="math inline">\(\{\mathcal F_t\}_{t \ge 0}\)</span>, i.e., for any <span class="math inline">\(s \le t\)</span>, <span class="math display">\[ \EXP[ Λ_t | \mathcal F_s ] = Λ_s. \]</span></p></li>
<li><p>Let <span class="math inline">\(X_t\)</span> be an <span class="math inline">\(\mathcal F_t\)</span> measurable random variable. Then <span class="math display">\[ \EXP^\dagger[X_t] = \EXP[Λ X_t ] = \EXP[ Λ_t X_t ]. \]</span></p>
<p>Thus, <span class="math inline">\(Λ_t\)</span> may be viewed as <span class="math inline">\(\dfrac {dP^\dagger}{dP} \Bigg|_{\mathcal F_t}\)</span>.</p></li>
<li><p>Let <span class="math inline">\(X_t\)</span> be an <span class="math inline">\(\mathcal F_t\)</span> measurable random varaible. Then for any <span class="math inline">\(s &lt; t\)</span>, <span class="math display">\[ \EXP^\dagger[X_t | \mathcal F_s ] =
   \dfrac{1}{Λ_s} \EXP[ Λ_t X_t | \mathcal F_s ] .
\]</span></p></li>
</ul>
</dd>
</dl>
</div>
<p>An immediate implication of <a href="#thm:derivative-process" title="Theorem 4"><span class="pandoc-numbering-link thm">Theorem 4</span></a> is the following.</p>
<dl>
<dt>Corollary</dt>
<dd><p>A process <span class="math inline">\(\{X_t\}_{t \ge 0}\)</span> is a <span class="math inline">\(P^\dagger\)</span>-martingale with respect to <span class="math inline">\(\{\mathcal F_t\}_{t \ge 0}\)</span> if and only if the process <span class="math inline">\(\{ Λ_t X_t \}_{t \ge 0}\)</span> is a <span class="math inline">\(P\)</span>-martingale.</p>
</dd>
</dl>
<h4 class="unnumbered" data-number="" id="proof-2">Proof</h4>
<p>The fact Radon-Nikodym derivate process is a martingale immediately follows from the towering property of conidtional expectation:</p>
<p><span class="math display">\[
\EXP[ Λ_t | \mathcal F_s ] = \EXP[ \EXP[ Λ | \mathcal F_t ] | \mathcal F_s ]
= \EXP[ Λ | \mathcal F_s ] = Λ_s.
\]</span></p>
<p>By definition of Radon-Nikodym derivative, <span class="math inline">\(\EXP^\dagger[X_t] = \EXP[Λ X_t]\)</span>. Now, by the towering property of conditional expectation, we have <span class="math display">\[
  \EXP[Λ X_t ] = \EXP[ \EXP[ Λ X_t | \mathcal F_t ] ] 
  = \EXP[ X_t \EXP[ Λ | \mathcal F_t ] ] = \EXP [Λ_t X_t].
\]</span> This proves the second part.</p>
<p>To prove the third part, <a href="#thm:conditional-change-of-measure" title="Theorem 3"><span class="pandoc-numbering-link thm">Theorem 3</span></a> implies that</p>
<p><span class="math display">\[\begin{equation}
\EXP^\dagger[ X_t | \mathcal F_s ] =
   \frac{ \EXP[ Λ X_t | \mathcal F_s ]} { \EXP[ Λ | \mathcal F_s ] } =
   \frac{ \EXP[ Λ X_t | \mathcal F_s ]} { Λ_s }.
   \label{eq:step-1}
\end{equation}\]</span></p>
<p>Now, consider the numerator:</p>
<p><span class="math display">\[
\EXP[ Λ X_t | F_s ] = \EXP[ \EXP [ Λ X_t | \mathcal F_t ] | \mathcal F_s ] 
= \EXP [ X_t \EXP[ Λ | \mathcal F_t ] ] = \EXP [ X_t Λ_t ] .
\]</span> Substituting this in \eqref{eq:step-1} completes the proof of the third part.</p>


<p class="categories">
This entry 

 was last updated on 13 Jun 2020</p>



      <script type="text/javascript">
      
            var _gaq = _gaq || [];
            _gaq.push(['_setAccount', 'UA-6887174-4']);
            _gaq.push(['_trackPageview']);
            (function() {
                var ga   = document.createElement('script');
                ga.type  = 'text/javascript';
                ga.async = true;
                ga.src   = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
                var s = document.getElementsByTagName('script')[0];
                s.parentNode.insertBefore(ga, s);
              })();
      
      </script>
    </div>
  </body>
</html>


