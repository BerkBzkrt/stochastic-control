<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Risk-sensitive on ECSE 506: Stochastic Control and Decision Theory</title>
    <link>https://adityam.github.io/stochastic-control/risk-sensitive/</link>
    <description>Recent content in Risk-sensitive on ECSE 506: Stochastic Control and Decision Theory</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language><atom:link href="https://adityam.github.io/stochastic-control/risk-sensitive/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Prelim: Risk Sensitive Utility</title>
      <link>https://adityam.github.io/stochastic-control/risk-sensitive/risk-sensitive-utility/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://adityam.github.io/stochastic-control/risk-sensitive/risk-sensitive-utility/</guid>
      <description>Risk sensitivity is relative to the idea of utility. The value of a sum of money \(z\) to a decision maker may not be proportional to \(z\) itself but may be some general increasing function \(\mathsf{U}(z)\), known as the utility function. For example, in the example on optimal gambling considered earlier, we had assumed that the utility for wealth \(z\) is \(\log z\). If a decision maker has utility function \(\mathsf{U}\), then the value of a random outcome \(Z\) will be defined by the expected utility \(\EXP[\mathsf{U}(Z)]\).</description>
    </item>
    
    <item>
      <title>Theory: Risk Sensitive MDP</title>
      <link>https://adityam.github.io/stochastic-control/risk-sensitive/risk-sensitive-mdp/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://adityam.github.io/stochastic-control/risk-sensitive/risk-sensitive-mdp/</guid>
      <description>1 Finite horizon setup Consider the matrix formulation of an MDP with state space \(\ALPHABET X\), action space \(\ALPHABET U\), per-step cost \(c \colon \ALPHABET X × \ALPHABET U \to \reals\), and controlled transition matrix \(P\). However, instead of the risk neutral optimization criteria that we consider previously, we consider a risk-sensitive objective. In particular, the performance of any (possibly non-Markovian) strategy \(g = (g_1, \dots, g_T)\) is given by \[ \bar J_θ(g) = \frac{1}{θ} \log \EXP\Bigl[ \exp\Bigl( θ \sum_{t=1}^T c(X_t, U_t) \Bigr) \Bigr].</description>
    </item>
    
    <item>
      <title>Prelim: Change of Measure</title>
      <link>https://adityam.github.io/stochastic-control/risk-sensitive/change-of-measure/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://adityam.github.io/stochastic-control/risk-sensitive/change-of-measure/</guid>
      <description>1 Change of measure of a single random variable. Theorem 1 Let \((\Omega, \mathcal F, P)\) be a probability space and \(\Lambda\) be an almost surely non-negative random variable such that \(\EXP[\Lambda] = 1\). For any \(A \in \mathcal F\), define \[ P^\dagger(A) = \int_A \Lambda(\omega) dP(\omega). \] Then,
\(P^\dagger\) is a probability measure. For any random variable \(X\), \[ \EXP^\dagger[X] = \EXP[ \Lambda X]. \] If \(\Lambda\) is almost surely positive, then \[ \EXP[X] = \EXP^\dagger \left[ \frac{X}{\Lambda} \right].</description>
    </item>
    
    <item>
      <title>Linear Exponential of Quadratic Gaussian (LEQG)</title>
      <link>https://adityam.github.io/stochastic-control/risk-sensitive/leqg/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://adityam.github.io/stochastic-control/risk-sensitive/leqg/</guid>
      <description>1 Preliminaries Lemma 1 Suppose that \(Q(z,w)\) is a quadratic function of vectors \(z\) and \(w\), positive definite in \(w\).
Let \(Q_{ww} = ∂^2 Q(z,w)/∂w^2\). Since \(Q(z,w)\) is a quadratic function, \(Q_{ww}\) does not depend on \(z\). Since \(Q\) is positive definite in \(w\), \(Q_{ww} &amp;gt; 0\).
Suppose \(w \in \reals^r\). Define \(q = \log[ (2π)^{r/2} \det(Q_{ww})^{-1/2}]\). Then, for a fixed value of \(z\) \[ \int \exp\bigl[ -Q(z,w)\bigr] dw = \exp\bigl[ q - \inf_{w \in \reals^r} Q(z,w) \bigr].</description>
    </item>
    
  </channel>
</rss>
