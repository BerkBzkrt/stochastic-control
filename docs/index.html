<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<head>
  <meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="author" content="Aditya Mahajan" />
  <meta name="title" content="ECSE 506: Stochastic Control and Decision Theory" />
  <title>ECSE 506: Stochastic Control and Decision Theory</title>
  

  <link rel="stylesheet" href="https://adityam.github.io/stochastic-control//css/style.css" type="text/css" /><script type="text/javascript"
    src="https://adityam.github.io/stochastic-control/js/mathjax-local.js" defer>
  </script>
  <script type="text/javascript" id="MathJax-script" defer
    src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-svg.js">
  </script>

  <script type="module" defer
    src="//instant.page/3.0.0"
    integrity="sha384-OeDn4XE77tdHo8pGtE1apMPmAipjoxUQ++eeJa6EtJCfHlvijigWiJpD7VDPWXV1">
  </script>

  <script>var clicky_site_ids = clicky_site_ids || []; clicky_site_ids.push(101261731);</script>
  <script async src="//static.getclicky.com/js"></script>

</head>
<body>
<div id="content">
<div class="title">
  <h1>ECSE 506: Stochastic Control and Decision Theory </h1>
  <h2><a href="http://www.cim.mcgill.ca/~adityam/">Aditya Mahajan</a> <br/>
      Winter 2022
  </h2>
  <h3><a href="https://adityam.github.io/stochastic-control/ ">About</a>
	&nbsp;<small><small>|</small></small>&nbsp;
    <a href="https://adityam.github.io/stochastic-control//lectures">Lectures</a></span>
	&nbsp;<small><small>|</small></small>&nbsp;
    <a href="https://adityam.github.io/stochastic-control//notes">Notes</a></span>
	&nbsp;<small><small>|</small></small>&nbsp;
    <a href="https://adityam.github.io/stochastic-control//coursework">Coursework</a>
</h3>
</div>



<dl>
<dt>Location</dt>
<dd>
<p>Zoom (Tuesday and Thursday 10:05am to 11:25am) <br /></p>
<p>The course will start as an online course until announced otherwise. Classes will take place via <a href="https://mcgill.zoom.us/j/88256076541?pwd=OWtxVk1pZ2tYNC83RW8zdkFrOTV6UT09">zoom</a>.</p>
<p><del>The course will be delivered in-person. I teach in a ‘chalk and board’ style in a room which does not have video recording facilities. So, it is strongly recommended that you register for the course only if you can attend classes in person.</del></p>
<p><strong>In person classes will resume from the week of 24th Jan. The course will take place in BURN 1234</strong></p>
</dd>
</dl>
<dl>
<dt>Office hours</dt>
<dd>
<p>TBA</p>
</dd>
<dt>Course Outline</dt>
<dd>
<p>Modeling of Markov decision processes, dynamic programming, stochastic monotonicity and the structure of optimal policies, value iteration, policy iteration, approximate dynamic programming, imperfect and delayed observations, linear quadratic and Gaussian (LQG) systems, team theory, information structures, static and dynamic teams, dynamic programming for teams.</p>
</dd>
<dt>Course pre-requisites</dt>
<dd>
<ul>
<li>A graduate course on Probability (ECSE 509 or equivalent) is a <em>required</em> pre-requisite.</li>
<li>A graduate course on Stochastic processes (ECSE 510 or equivalent) is a <em>recommended</em> co-requisite.</li>
</ul>
</dd>
<dt>Grading policy</dt>
<dd>
<ul>
<li><p><strong>35% weekly assignments</strong>. Typically only one question per-assignment will be graded. Late submissions will be penalized by 10% per day. The lowest assignment will be dropped.</p></li>
<li><p><strong>40% mid-terms</strong>. If in-person classes resume, then we will have an in-class mid-term on March 29th. If classes remain online, we will have an online mid-term in the week of March 28th: the exam will be posted on 9:00am on March 28th and will remain available for 72 hours. Once you start the exam, you will have 2.5 hours to finish the exam.</p></li>
<li><p><strong>25% term project</strong>. A month long project to be done either along or in groups of two. Present one or two papers on any topic of your interest related to the material covered in class. Deliverables are a 10–15 page report and a 10 minute in-class presentations. <!--
-   **35% final**. During the exam period, scheduled by
    the university.
   --></p></li>
</ul>
</dd>
<dt>Textbooks</dt>
<dd>
<ul>
<li><p>Kumar and Varaiya, <a href="http://bookstore.siam.org/cl75/"><em>Stochastic Systems: Estimation, Identification, and Adaptive Control,</em></a> Prentice Hall, 1986. Reprinted by SIAM 2015</p></li>
<li><p>Bertsekas, <a href="http://www.athenasc.com/dpbook.html"><em>Dynamic programming and optimal control</em>,</a> vol 1 and 2, Athena Publications, 2005.</p>
<p>Perhaps the most comprehensive book of different topics in dynamic programming.</p></li>
<li><p>Puterman, <a href="http://onlinelibrary.wiley.com/book/10.1002/9780470316887"><em>Markov decision processes: discrete time dynamic programming</em></a>, Wiley 1994.</p>
<p>Excellent source algorithms for perfectly observed systems, in particular, infinite horizon dynamic programs.</p></li>
</ul>
<p>The flow of the course is largely based on my interpretation of the research landscape in Stochastic Control. The emphasis is on developing a strong theoretical foundations and selected material is taken from all three books listed above (in addition to specific material taken from research papers).</p>
</dd>
<dt>Reference books</dt>
<dd>
<ul>
<li><p>Ross, <a href="https://www.elsevier.com/books/introduction-to-stochastic-dynamic-programming/ross/978-0-12-598420-1"><em>Introduction to Stochastic Dynamic Programming,</em></a> Academic Press, 1983.</p>
<p>Excellent introduction to dynamic programming, from the point-of-view of applied mathematics.</p></li>
<li><p>Dernardo, <em>Dynamic Programming: Models and Applications,</em> Prentice Hall, 1982.</p>
<p>Excellent introduction to dynamic programming, from the point-of-view of operations research.</p></li>
<li><p>Powell, <a href="http://adp.princeton.edu"><em>Approximate Dynamic Programming</em></a>, John Wiley and Sons, 2011.</p>
<p>Comprehensive overview of approximate dynamic programming</p></li>
<li><p>Krishnamurty, <a href="https://www.cambridge.org/core/books/partially-observed-markov-decision-processes"><em>Partially Observable Markov Decision Processes</em></a>, Cambridge University Press, 2016.</p>
<p>Comprehensive overview of POMDPs</p></li>
</ul>
</dd>
</dl>


    </div>
  </body>
</html>


