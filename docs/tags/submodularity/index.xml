<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>submodularity on ECSE 506: Stochastic Control and Decision Theory</title>
    <link>https://adityam.github.io/stochastic-control/tags/submodularity/</link>
    <description>Recent content in submodularity on ECSE 506: Stochastic Control and Decision Theory</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language><atom:link href="https://adityam.github.io/stochastic-control/tags/submodularity/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Theory: Monotone value functions and policies</title>
      <link>https://adityam.github.io/stochastic-control/mdp/monotonicity/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://adityam.github.io/stochastic-control/mdp/monotonicity/</guid>
      <description>TL;DR General conditions are presented under which the optimal policy is monotone. Such a structural property is useful because it makes it easy to search and implement the optimal policy.
Consider the matrix formulation of MDPs and suppose the state space \(\ALPHABET S\) is totally ordered. In many applications, it is useful to know if the value function is increasing (or decreasing) in state.
 Theorem 1  Consider an MDP where the state space \(\ALPHABET S\) is totally ordered.</description>
    </item>
    
  </channel>
</rss>
