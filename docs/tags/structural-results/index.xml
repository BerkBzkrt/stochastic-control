<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>structural results on ECSE 506: Stochastic Control and Decision Theory</title>
    <link>https://adityam.github.io/stochastic-control/tags/structural-results/</link>
    <description>Recent content in structural results on ECSE 506: Stochastic Control and Decision Theory</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language><atom:link href="https://adityam.github.io/stochastic-control/tags/structural-results/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Example: Inventory Management (revisited)</title>
      <link>https://adityam.github.io/stochastic-control/inf-mdp/inventory-management/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://adityam.github.io/stochastic-control/inf-mdp/inventory-management/</guid>
      <description>TL;DR One of the potential benefits of modeling a system as infinite horizon discounted cost MDP is that it can be simpler to identify an optimal policy. We illustrate this using the inventory management example.
Consider the model for inventory management and assume that it runs for an infinite horizon. We assume that the per-step cost is given by \[c(s,a,s_{+}) = p a + Î³ h(s), \] where \[ h(s) = \begin{cases} c_h s, &amp;amp; \text{if $s \ge 0$} \\ -c_s s, &amp;amp; \text{if $s &amp;lt; 0$}, \end{cases}\] where \(a\) is the per-unit holding cost, \(b\) is the per-unit shortage cost, and \(p\) is the per-unit procurement cost.</description>
    </item>
    
    <item>
      <title>Example: Service Migration in Mobile Edge Computing</title>
      <link>https://adityam.github.io/stochastic-control/inf-mdp/service-migration-in-mec/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://adityam.github.io/stochastic-control/inf-mdp/service-migration-in-mec/</guid>
      <description>TL;DR Another benefit of infinite horizon models is that it is possible to prove structural properties of the optimal policy which might not hold for a finite horizon model. We illustrate this using a model for service migration in mobile edge computing.
There are many mobile applications which consist of a front-end component running on a mobile device and a back-end component running on a cloud, where the cloud provides additional data processing and computing resources.</description>
    </item>
    
    <item>
      <title>Example: Optimal choice of the best alternative</title>
      <link>https://adityam.github.io/stochastic-control/optimal-stopping/optimal-choice/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://adityam.github.io/stochastic-control/optimal-stopping/optimal-choice/</guid>
      <description>A decision maker (DM) wants to select the best alternative from a set of \(T\) alternatives. The DM evaluates the alternatives sequentially. After evaluating alternative \(t\), the DM knows whether alternative \(t\) was the best alternative so far or not. Based on this information, the DM must decide whether to choose alternative \(t\) and stop the search, or to permanently reject alternative \(t\) and evaluate remaining alternatives. The DM may reject the last alternative and not make a choice at all.</description>
    </item>
    
    <item>
      <title>Example: Call options</title>
      <link>https://adityam.github.io/stochastic-control/optimal-stopping/call-options/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://adityam.github.io/stochastic-control/optimal-stopping/call-options/</guid>
      <description>An investor has a call option to buy one share of a stock at a fixed price \(p\) dollars and has \(T\) days to exercise this option. For simplicity, we assume that the investor makes a decision at the beginning of each day.
The investory may decide not to exercise the option but if he does exercise the option when the stock price is \(x\), he effectively gets \((x-p)\).
Assume that the price of the stoch varies with independent increments, i.</description>
    </item>
    
    <item>
      <title>Example: Inventory Management</title>
      <link>https://adityam.github.io/stochastic-control/mdp/inventory-management/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://adityam.github.io/stochastic-control/mdp/inventory-management/</guid>
      <description>Image credit: https://hbr.org/2015/06/inventory-management-in-the-age-of-big-data TL;DR The inventory management example illustrates that a dynamic programming formulation is useful even when a closed form solution does not exist. This model also introduces the idea of post-decision state, which is useful in many contexts.
Imagine a retail store that stockpiles products in its warehouse to meet random demand. Suppose the store procures new stocks at the end of each day (and that there is no lead time and stocks are available next morning).</description>
    </item>
    
    <item>
      <title>Example: Power-delay trade-off in wireless communication</title>
      <link>https://adityam.github.io/stochastic-control/mdp/power-delay-tradeoff/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://adityam.github.io/stochastic-control/mdp/power-delay-tradeoff/</guid>
      <description>TL;DR This stylized example of power-delay trade-off in wireless communications illustrates that a dynamic programming formulation can be used to identify qualitative properties of the value function and optimal policies.
In a cell phone, higher layer applications such as voicecall, email, browsers, etc. generate data packets. These packets are buffered in a queue and the transmission protocol decides how many packets to transmit at each time depending the number of packets in the queue and the quality of the wireless channel.</description>
    </item>
    
  </channel>
</rss>
