<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>monotone policies on ECSE 506: Stochastic Control and Decision Theory</title>
    <link>https://adityam.github.io/stochastic-control/tags/monotone-policies/</link>
    <description>Recent content in monotone policies on ECSE 506: Stochastic Control and Decision Theory</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language><atom:link href="https://adityam.github.io/stochastic-control/tags/monotone-policies/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Theory: Optimality of threshold policies in optimal stopping</title>
      <link>https://adityam.github.io/stochastic-control/optimal-stopping/monotonicity-optimal-stopping/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://adityam.github.io/stochastic-control/optimal-stopping/monotonicity-optimal-stopping/</guid>
      <description>Let \(\{X_t\}_{t \ge 1}\) be a Markov chain. At each time \(t\), a decision maker observes the state \(X_t\) of the Markov chain and decides whether to continue or stop the process. If the decision maker decides to continue, he incurs a continuation cost \(c_t(X_t)\) and the state evolves. If the DM decides to stop, he incurs a stopping cost of \(s_t(X_t)\) and the problem is terminated. The objective is to determine an optimal stopping time \(\tau\) to minimize \[J(\tau) := \EXP\bigg[ \sum_{t=1}^{\tau-1} c_t(X_t) + s_\tau(X_\tau) \bigg].</description>
    </item>
    
    <item>
      <title>Theory: Monotone value functions and policies</title>
      <link>https://adityam.github.io/stochastic-control/mdp/monotonicity/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://adityam.github.io/stochastic-control/mdp/monotonicity/</guid>
      <description>Consider the matrix formulation of MDPs and suppose the state space \(\ALPHABET S\) is totally ordered. In many applications, it is useful to know if the value function is increasing (or decreasing) in state.
 Theorem Consider an MDP where the state space \(\ALPHABET S\) is totally ordered. Suppose the following conditions are satisfied.
C1. For every \(a \in \ALPHABET A\), the per-step cost \(c_t(s,a)\) is weakly inceasing in \(s\).</description>
    </item>
    
  </channel>
</rss>
