<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>belief state on ECSE 506: Stochastic Control and Decision Theory</title>
    <link>https://adityam.github.io/stochastic-control/tags/belief-state/</link>
    <description>Recent content in belief state on ECSE 506: Stochastic Control and Decision Theory</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    
	<atom:link href="https://adityam.github.io/stochastic-control/tags/belief-state/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Theory: Basic model of a POMDP</title>
      <link>https://adityam.github.io/stochastic-control/pomdp/pomdp/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://adityam.github.io/stochastic-control/pomdp/pomdp/</guid>
      <description>So far, we have considered a setup where the decision maker perfectly observes the state of the system. In many applications, the decision maker may not directly observe the state of the system but only observe a noisy version of it. Such systems are modeled as partially observable Markov decision processes (POMDPs). We will describe the simplest model of POMDPs, which builds upon the model of MDPs descibed earlier.
We assume that the system has a state \(X_t \in \ALPHABET X\), control input \(U_t \in \ALPHABET U\), and process noise \(W_t \in \ALPHABET W\).</description>
    </item>
    
  </channel>
</rss>