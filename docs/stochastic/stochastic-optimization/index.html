<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<head>
  <meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="author" content="Aditya Mahajan" />
  <meta name="title" content="ECSE 506: Stochastic Control and Decision Theory" />
  <title>ECSE 506: Stochastic Control and Decision Theory</title>
  
  <meta content="stochastic optimization,principle of irrelevant information" name="keywords" />
  

  <link rel="stylesheet" href="https://adityam.github.io/stochastic-control//css/style.css" type="text/css" /><script type="text/javascript"
    src="https://adityam.github.io/stochastic-control/js/mathjax-local.js" defer>
  </script>
  <script type="text/javascript" id="MathJax-script" defer
    src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-svg.js">
  </script>

  <script type="module" defer
    src="//instant.page/3.0.0"
    integrity="sha384-OeDn4XE77tdHo8pGtE1apMPmAipjoxUQ++eeJa6EtJCfHlvijigWiJpD7VDPWXV1">
  </script>

  <script>var clicky_site_ids = clicky_site_ids || []; clicky_site_ids.push(101261731);</script>
  <script async src="//static.getclicky.com/js"></script>

</head>
<body>
<div id="content">
<div class="title">
  <h1>ECSE 506: Stochastic Control and Decision Theory </h1>
  <h2><a href="http://www.cim.mcgill.ca/~adityam/">Aditya Mahajan</a> <br/>
      Winter 2022
  </h2>
  <h3><a href="https://adityam.github.io/stochastic-control/ ">About</a>
	&nbsp;<small><small>|</small></small>&nbsp;
    <a href="https://adityam.github.io/stochastic-control//lectures">Lectures</a></span>
	&nbsp;<small><small>|</small></small>&nbsp;
    <a href="https://adityam.github.io/stochastic-control//notes">Notes</a></span>
	&nbsp;<small><small>|</small></small>&nbsp;
    <a href="https://adityam.github.io/stochastic-control//coursework">Coursework</a>
</h3>
</div>



<div class="h1-title">Prelim: Stochastic optimization</div>

<p>Let’s start with the simplest optimization problem. A decision maker has to choose an action <span class="math inline">\(a \in \ALPHABET A\)</span>. Upon choosing the action <span class="math inline">\(a\)</span>, the decision maker incurs a cost <span class="math inline">\(c(a)\)</span>. What action should the decision maker pick to minimize the cost?</p>
<p>Formally, the above optimization problem may be written as <span class="math display">\[ \begin{equation} \label{eq:basic}
 \min_{a \in \ALPHABET A} c(a).
\end{equation}\]</span></p>
<p>When the <em>action space</em> <span class="math inline">\(\ALPHABET A\)</span> is finite, say <span class="math inline">\(\ALPHABET A = \{1, \dots, m\}\)</span>, solving the optimization problem \eqref{eq:basic} is conceptually straight-forward: enumerate the cost of all possible actions, i.e., enumerate the set <span class="math inline">\(C = \{ c(a) : a \in \ALPHABET A \}\)</span> and find the smallest element.</p>
<p>When the action space <span class="math inline">\(\ALPHABET A\)</span> is continuous, say a compact subset of a Euclidean space, solving the optimization problem \eqref{eq:basic} is conceptually straight-forward only when the cost function <span class="math inline">\(c\)</span> satisfies some regularity conditions. For example, when <span class="math inline">\(c\)</span> is convex, the optimal action can be obtained for solving <span class="math display">\[ \dfrac {d c(a) }{ da } = 0. \]</span></p>
<p>In the absence of appropriate regularity conditions, it is not possible to solve an optimization problem over continuous action spaces.</p>
<hr />
<p>Now consider the simplest stochastic optimization problem. A decision maker has to choose an action <span class="math inline">\(a \in \ALPHABET A\)</span>. Upon choosing the action <span class="math inline">\(a\)</span>, the decision maker incurs a cost <span class="math inline">\(c(a,W)\)</span>, where <span class="math inline">\(W \in \ALPHABET W\)</span> is a random variable with known probability distribution. Assume that the decision maker is <em>risk neutral</em> and, therefore, wants to minimize <span class="math inline">\(\EXP[ c(a, W) ]\)</span>, where the expectation is with respect to the random variable <span class="math inline">\(W\)</span>.</p>
<p>Formally, the above optimization problem may be written as <span class="math display">\[\begin{equation} \label{eq:stochastic}
  \min_{a \in \ALPHABET A} \EXP[ c(a, W) ]. 
\end{equation}\]</span></p>
<p>Define <span class="math inline">\(J(a) = \EXP[ c(a, W) ]\)</span>. Then Problem \eqref{eq:stochastic} is conceptually the same as Problem \eqref{eq:basic} with the cost function <span class="math inline">\(J(a)\)</span>. Numerically, Problem \eqref{eq:stochastic} is more difficult because computing <span class="math inline">\(J(a)\)</span> involves evaluating an expectation, but we ignore the computational complexity for the time being.</p>
<hr />
<p>In the stochastic optimization problems considered above, the decision maker does not observe any data before making a decision. In many situations, the decision maker does observe some data, which is captured by the following model. Suppose a decision maker observes a random variable <span class="math inline">\(S \in \ALPHABET S\)</span> and then chooses an action <span class="math inline">\(A \in \ALPHABET A\)</span> as a function of his observation according to a <em>decision rule</em> <span class="math inline">\(π\)</span>, i.e., <span class="math display">\[ A = π(S). \]</span></p>
<p>Upon choosing the action <span class="math inline">\(A\)</span>, the decision maker incurs a cost <span class="math inline">\(c(S,A,W)\)</span>, where <span class="math inline">\(W \in \ALPHABET W\)</span> is a random variable. We assume that the <em>primitive random variables</em> <span class="math inline">\((S,W)\)</span> are defined on a common probability space and have a known joint distribution. Assume that the decision maker is risk neutral and, therefore, wants to minimize <span class="math inline">\(\EXP[ c(S, π(S), W)]\)</span>, where the expectation is taken with respect to the joint probability distribution of <span class="math inline">\((S,W)\)</span>.</p>
<p>Formally, the above optimization problem may be written as <span class="math display">\[\begin{equation} \label{eq:obs} \tag{P1}
  \min_{π \colon \ALPHABET S \to \ALPHABET A} \EXP[ c(S, π(S), W) ].
\end{equation}\]</span></p>
<p>Define <span class="math inline">\(J(π) = \EXP[ c(S, π(S), W) ]\)</span>. Then, Problem \eqref{eq:obs} is conceptually the same as Problem \eqref{eq:basic} with one difference: In Problem \eqref{eq:basic}, the minimization is over a parameter <span class="math inline">\(a\)</span>, while in Problem \eqref{eq:obs}, the minimization is over a function <span class="math inline">\(π\)</span>.</p>
<p>When <span class="math inline">\(\ALPHABET S\)</span> and <span class="math inline">\(\ALPHABET A\)</span> are finite sets, the optimal policy can be obtained by an exhaustive search over all policies as follows: for each policy <span class="math inline">\(π\)</span> compute the performance <span class="math inline">\(J(π)\)</span> and then pick the policy <span class="math inline">\(π\)</span> with the smallest expected cost.</p>
<p>Such an exhaustive search is not satisfying for two reasons. First, it has a high computational cost. There are <span class="math inline">\(| \ALPHABET A |^{| \ALPHABET S |}\)</span> policies and, for each policy, we have to evaluate an expectation, which can be expensive. Second, the above enumeration procedure does not work when <span class="math inline">\(\ALPHABET S\)</span> or <span class="math inline">\(\ALPHABET A\)</span> are continuous sets.</p>
<p>There is an alternative way of viewing the problem that simplifies it considerably. Instead of viewing the optimization problem before the system starts running, imagine that the decision maker waits until he sees the realization <span class="math inline">\(s\)</span> of <span class="math inline">\(S\)</span>. He then asks what action <span class="math inline">\(a\)</span> should he take to minimize the expected <em>conditional</em> cost <span class="math inline">\(Q(s,a) := \EXP[ c(s,a, W) | S = s]\)</span>, i.e., he considers the problem</p>
<p><span class="math display">\[\begin{equation} \label{eq:cond-1} \tag{P2}
  \min_{a \in \ALPHABET A} \EXP[ c(s,a,W) | S = s], \quad
  \forall s \in \ALPHABET S.
\end{equation}\]</span></p>
<p>Thus, Problem \eqref{eq:obs}, which is a functional optimization problem, has been reduced to a collection of parameter optimization problems (Problem \eqref{eq:cond-1}), one for each possible of <span class="math inline">\(s\)</span>.</p>
<p>Now define <span class="math display">\[ \begin{equation} \label{eq:cond} \tag{P2-policy}
  π^∘(s) = \arg \min_{a \in \ALPHABET A} \EXP[ c(s,a, W) | S = s]
\end{equation} \]</span> where ties (in the minimization) are broken arbitrarily.</p>
<div class="proclaim">
<p><strong>Basic fact.</strong> The decision rule <span class="math inline">\(π^∘\)</span> defined in \eqref{eq:cond} is optimal for Problem \ref{eq:basic}.</p>
</div>
<dl>
<dt>Remark</dt>
<dd><p>We restricted the proof finite <span class="math inline">\(\ALPHABET S\)</span>, <span class="math inline">\(\ALPHABET A\)</span>, <span class="math inline">\(\ALPHABET W\)</span>. This is to avoid any measurability issues. If <span class="math inline">\(\ALPHABET S\)</span> and <span class="math inline">\(\ALPHABET A\)</span> are continuous sets, we need to restrict to <em>measurable</em> <span class="math inline">\(π\)</span> in Problem \ref{eq:basic} (otherwise the expectation is not well defined; of course the cost <span class="math inline">\(c\)</span> also has to be measurable). However, it is not immediately obvious that <span class="math inline">\(π^∘\)</span> defined in \eqref{eq:cond} is measurable. Conditions that ensure this are known as <em>measurable selection theorems</em>.</p>
</dd>
</dl>
<details>
<summary>
<h4 class="unnumbered" id="proof">Proof</h4>
</summary>
<div>
<p>Let <span class="math inline">\(π\)</span> be any other decision rule. Then, <span class="math display">\[ \begin{align*}
  \EXP[ c(S, π(S), W) ] &amp;\stackrel{(a)}= \EXP[ \EXP[c(S, π(S), W) | S ] ] \\
  &amp;\stackrel{(b)}\ge \EXP[\EXP[ c(S, π^∘(S), W) | S ] ] \\
  &amp;\stackrel{(c)}= \EXP[ c(S, π^∘(S), W) ],
\end{align*} \]</span> where <span class="math inline">\((a)\)</span> and <span class="math inline">\((c)\)</span> follow from the law of iterated expectations and <span class="math inline">\((b)\)</span> follows from the definition of <span class="math inline">\(π^∘\)</span> in \eqref{eq:cond}.</p>
</div>
</details>
<p>We can also provide a partial converse of the basic fact.</p>
<div class="proclaim">
<p><strong>Converse of basic fact.</strong> If <span class="math inline">\(\PR(S = s) &gt; 0\)</span> for all <span class="math inline">\(s\)</span>, then any optimal policy <span class="math inline">\(π^∘\)</span> for Problem <span class="math inline">\(\ref{eq:basic}\)</span> must satisfy \eqref{eq:cond}.</p>
</div>
<details>
<summary>
<h4 class="unnumbered" id="proof-1">Proof</h4>
</summary>
<div>
<p>We prove this by contradiction. Suppose <span class="math inline">\(π^*\)</span> is an optimal policy that does not satisfy \eqref{eq:cond}. By definition of <span class="math inline">\(π^∘\)</span>, it must be the case that for all states <span class="math display">\[\begin{equation} 
   \EXP[ c(s, π^∘(s), W) | S = s ] 
   \le
   \EXP[ c(s, π^*(s), W) | S = s ] .
   \label{eq:ineq:1}
\end{equation}\]</span> Now, since <span class="math inline">\(π^*\)</span> does not satisfy \eqref{eq:cond}, there exists some state <span class="math inline">\(s^∘ \in \ALPHABET S\)</span> such that <span class="math display">\[\begin{equation}
   \EXP[ c(s^∘, π^*(s^∘), W) | S = s^∘ ] 
   &gt; 
   \EXP[ c(s^∘, π^∘(s^∘), W) | S = s^∘ ] .
   \label{eq:ineq:2}
\end{equation}\]</span> Therefore, <span class="math display">\[\begin{align*}
   \EXP[ c(S, π^*(S), W) ]
   &amp;=
   \sum_{s \in \ALPHABET S} \PR(S = s) 
   \EXP[ \EXP[ c(s, π^*(s), W) | S = s ] ]
   \\
   &amp; \stackrel{(a)}&gt; 
   \sum_{s \in \ALPHABET S} \PR(S = s) 
   \EXP[ \EXP[ c(s, π^∘(s), W) | S = s ] ]
   \\
   &amp;=
   \EXP[ c(S, π^∘(S), W) ]
\end{align*}\]</span> where <span class="math inline">\((a)\)</span> follows from \eqref{eq:ineq:1} and \eqref{eq:ineq:2} and the inequality is strict becase <span class="math inline">\(\PR(S = s^∘) &gt; 0\)</span>. Thus, <span class="math inline">\(J(π^*) &gt; J(π^∘)\)</span> and, hence, <span class="math inline">\(π^*\)</span> cannot be an optimal policy. <span class="math inline">\(\Box\)</span></p>
</div>
</details>
<hr />
<p>In many scenarios, the decision maker may observe data which is irrelevant for evaluating performance. In such instances, the decision maker may ignore such information without affecting performance. Formally, we have the following result, which is known as <strong>Blackwell’s principle of irrelevant information</strong>.</p>
<div class="highlight">
<dl>
<dt><span id="thm:1"></span><span id="thm:blackwell" class="pandoc-numbering-text thm"><strong>Theorem 1</strong></span></dt>
<dd><p>Let <span class="math inline">\(\ALPHABET S\)</span>, <span class="math inline">\(\ALPHABET Y\)</span>, <span class="math inline">\(\ALPHABET W\)</span>, and <span class="math inline">\(\ALPHABET A\)</span> be standard Borel spaces and <span class="math inline">\(S \in \ALPHABET S\)</span>, <span class="math inline">\(Y \in \ALPHABET Y\)</span>, <span class="math inline">\(W \in \ALPHABET W\)</span> be random variables defined on a common probability space.</p>
<p>A decision maker observes <span class="math inline">\((S,Y)\)</span> and chooses <span class="math inline">\(A = π(S,Y)\)</span> to minimize <span class="math inline">\(\EXP[c(S,A,W)]\)</span>, where <span class="math inline">\(c \colon \ALPHABET S \times \ALPHABET A \times \ALPHABET W \to \reals\)</span> is a measurable function.</p>
<p><strong>Then, if <span class="math inline">\(W\)</span> is conditionally independent of <span class="math inline">\(Y\)</span> given <span class="math inline">\(S\)</span>, then there is no loss of optimality in choosing <span class="math inline">\(A\)</span> only as a function of <span class="math inline">\(S\)</span>.</strong></p>
<p>Formally, there exists a <span class="math inline">\(π^* \colon \ALPHABET S \to \ALPHABET A\)</span> such that for all <span class="math inline">\(π \colon \ALPHABET S \times \ALPHABET Y \to \ALPHABET A\)</span>, <span class="math display">\[ \EXP[c(S, π^*(S), W)] \le \EXP[ c(S, π(S,Y), W) ]. \]</span></p>
</dd>
</dl>
</div>
<details>
<summary>
<h4 class="unnumbered" id="proof-2">Proof</h4>
</summary>
<div>
<p>We prove the result for the case when <span class="math inline">\(\ALPHABET S\)</span>, <span class="math inline">\(\ALPHABET Y\)</span>, <span class="math inline">\(\ALPHABET W\)</span>, <span class="math inline">\(\ALPHABET A\)</span> are finite.</p>
<p>Define <span class="math display">\[π^*(s) = \arg \min_{a \in \ALPHABET A} \EXP[ c(s,a, W) | S = s]. \]</span> Then, by construction, for any <span class="math inline">\(s \in \ALPHABET S\)</span> and <span class="math inline">\(a \in \ALPHABET A\)</span>, we have that <span class="math display">\[ \EXP[ c(s, π^*(s), W ) | S = s]  \le \EXP[ c(s,a,W) | S = s]. \]</span> Hence, for any <span class="math inline">\(π \colon \ALPHABET S \times \ALPHABET Y \to \ALPHABET A\)</span>, and for any <span class="math inline">\(s \in \ALPHABET S\)</span> and <span class="math inline">\(y \in \ALPHABET Y\)</span>, we have <span class="math display">\[ \begin{equation} \label{eq:opt}
  \EXP[ c(s, π^*(s), W) | S = s] \le \EXP[ c(s, π(s,y),W) | S = s]. 
\end{equation} \]</span> The result follows by taking the expectation of both sides of \eqref{eq:opt}. <span class="math inline">\(\Box\)</span></p>
<p>The above proof doesn’t work for general Borel spaces because <span class="math inline">\(π^*\)</span> defined above may not exist (inf vs min) or may not be measurable. See <span class="citation" data-cites="Blackwell1964">Blackwell (<a href="#ref-Blackwell1964" role="doc-biblioref">1964</a>)</span> for a formal proof.</p>
</div>
</details>
<h1 class="unnumbered" id="exercises">Exercises</h1>
<ol type="1">
<li><p>Suppose <span class="math inline">\(\ALPHABET S = \{1, 2 \}\)</span>, <span class="math inline">\(\ALPHABET A = \{1, 2, 3\}\)</span>, and <span class="math inline">\(\ALPHABET W = \{1, 2, 3\}\)</span>. Let <span class="math inline">\((S,W)\)</span> be random variables taking values in <span class="math inline">\(\ALPHABET S × \ALPHABET W\)</span> with joint distribution <span class="math inline">\(P\)</span> shown below.</p>
<p><span class="math display">\[ P = \MATRIX{ 0.25 &amp; 0.15 &amp; 0.05  \\ 0.30 &amp; 0.10 &amp; 0.15 } \]</span></p>
<p>Here the row corresponds to the value of <span class="math inline">\(s\)</span> and the column corresponds to the value of <span class="math inline">\(w\)</span>. For example <span class="math inline">\(\PR(S=2, W=1) = P_{21} = 0.30\)</span>.</p>
<p>The cost function <span class="math inline">\(c \colon \ALPHABET S \times \ALPHABET A \times \ALPHABET W \to \reals\)</span> is shown below</p>
<p><span class="math display">\[
 c(\cdot,\cdot,1) = \MATRIX{3 &amp; 5 &amp; 1 \\ 2 &amp; 3 &amp; 1 }, \quad
 c(\cdot,\cdot,2) = \MATRIX{4 &amp; 3 &amp; 1 \\ 1 &amp; 2 &amp; 8 }, \quad
 c(\cdot,\cdot,3) = \MATRIX{1 &amp; 2 &amp; 2 \\ 4 &amp; 1 &amp; 3 }.
\]</span></p>
<p>Here the row corresponds to the value of <span class="math inline">\(s\)</span> and the column corresponds to the value of <span class="math inline">\(a\)</span>. For example <span class="math inline">\(c(s=1,a=2,w=1) = 5\)</span>.</p>
<p>Find the policy <span class="math inline">\(π \colon \ALPHABET S \to \ALPHABET A\)</span> that minimizes <span class="math inline">\(\EXP[ c(S, π(S), W) ]\)</span>.</p></li>
<li><p>Suppose <span class="math inline">\(\ALPHABET S = \{1, 2\}\)</span>, <span class="math inline">\(\ALPHABET Y = \{1, 2\}\)</span>, <span class="math inline">\(\ALPHABET A = \{1, 2, 3\}\)</span>, and <span class="math inline">\(\ALPHABET W = \{1, 2, 3\}\)</span>. Let <span class="math inline">\((S,Y,W)\)</span> be random variables taking values in <span class="math inline">\(\ALPHABET S × \ALPHABET Y × \ALPHABET W\)</span>, with joint distribution <span class="math inline">\(Q\)</span> shown below. <span class="math display">\[
 Q_{Y = 1} = \MATRIX{0.15 &amp; 0.10 &amp; 0.00 \\ 0.15 &amp; 0.05 &amp; 0.10}
 \qquad
 Q_{Y = 2} = \MATRIX{0.10 &amp; 0.05 &amp; 0.05 \\ 0.15 &amp; 0.05 &amp; 0.05}
\]</span> For a fixed value of <span class="math inline">\(y\)</span>, the row corresponds to the value of <span class="math inline">\(s\)</span> and the column corresponds to the value of <span class="math inline">\(w\)</span>. For example <span class="math inline">\(\PR(S = 1, Y = 1, W = 3) = 0\)</span>.</p>
<p>The cost function <span class="math inline">\(c \colon \ALPHABET S × \ALPHABET A × \ALPHABET W \to \reals\)</span> is the same as the previous exercise.</p>
<ol type="a">
<li><p>Find the policy <span class="math inline">\(π \colon \ALPHABET S × \ALPHABET Y \to \ALPHABET A\)</span> that minimizes <span class="math inline">\(\EXP[c(S, π(S,Y), W)]\)</span>.</p></li>
<li><p>Compare the solution with the solution of the previous exercise in view of Blackwell’s principle of irrelevant information. Clearly explain your observations.</p></li>
</ol></li>
</ol>
<!-- From page 172 of Whittle, Optimal Control: Basics and Beyond -->
<ol start="3" type="1">
<li><p>Consider the problem of monitoring the pollution level of a river. The river can have a high pollution level if there is a catastrophic failure of a factory upstream. There are then two “pollution states” indicating whether such a failure has not occured. We denote them by <span class="math inline">\(S = 0\)</span> (indicating no failure) and <span class="math inline">\(S = 1\)</span> (indicating catastrophic failure). Let <span class="math inline">\([p, 1-p]\)</span> denote the prior probability mass function of <span class="math inline">\(S\)</span>.</p>
<p>The pollution monitoring system has a sensor which takes a measurement <span class="math inline">\(y\)</span> of the pollution level. Let <span class="math inline">\(f_s(y)\)</span> denote the probabiity density of the observation <span class="math inline">\(y\)</span> conditional on the value of <span class="math inline">\(s\)</span>, <span class="math inline">\(s \in \{0, 1\}\)</span>. Two actions are available at the monitoring system: raise an alarm or not raise an alarm. The cost of raising the alarm is <span class="math inline">\(C_0\)</span> if the state <span class="math inline">\(S\)</span> is <span class="math inline">\(0\)</span> or zero if the state <span class="math inline">\(S\)</span> is <span class="math inline">\(1\)</span>; the cost of not raising the alarm is zero if the state <span class="math inline">\(S\)</span> is <span class="math inline">\(0\)</span> or <span class="math inline">\(C_1\)</span> if the state <span class="math inline">\(S\)</span> is <span class="math inline">\(1\)</span>.</p>
<p>Show that it is optimal to raise the alarm if <span class="math display">\[ p f_0(y) C_0 &lt; (1 - p) f_1(y) C_1. \]</span> That is, it is optimal to raise the alarm if the <em>likelihood ratio</em> <span class="math inline">\(f_1(y)/f_0(y)\)</span> exceeds the threshold value <span class="math inline">\(p C_0/(1-p) C_1\)</span>.</p></li>
</ol>
<h1 class="unnumbered" id="references">References</h1>
<p>Theorem <a href="#thm:blackwell" title="Theorem 1"><span class="pandoc-numbering-link thm">Theorem 1</span></a> is due to <span class="citation" data-cites="Blackwell1964">Blackwell (<a href="#ref-Blackwell1964" role="doc-biblioref">1964</a>)</span> in a short 2.5 page paper. A similar result was used by <span class="citation" data-cites="Witsenhausen1979">Witsenhausen (<a href="#ref-Witsenhausen1979" role="doc-biblioref">1979</a>)</span> to show the structure of optimal coding strategies in real-time communication. Also see the <a href="https://infostructuralist.wordpress.com/2010/11/08/deadly-ninja-weapons-blackwells-principle-of-irrelevant-information/">blog post</a> by Maxim Ragisnsky.</p>
<p>Exercise 3 is adaptive from <span class="citation" data-cites="Whittle1996">Whittle (<a href="#ref-Whittle1996" role="doc-biblioref">1996</a>)</span>. It is a special instance of Bayesian hypothesis testing problem. We will study a generalization of this model later in <a href="../../pomdp/sequential-hypothesis">sequential hypothesis testing</a></p>
<hr />
<div id="refs" class="references csl-bib-body hanging-indent" role="doc-bibliography">
<div id="ref-Blackwell1964" class="csl-entry" role="doc-biblioentry">
<span class="smallcaps">Blackwell, D.</span> 1964. Memoryless strategies in finite-stage dynamic programming. <em>The Annals of Mathematical Statistics</em> <em>35</em>, 2, 863–865. DOI: <a href="https://doi.org/10.1214/aoms/1177703586">10.1214/aoms/1177703586</a>.
</div>
<div id="ref-Whittle1996" class="csl-entry" role="doc-biblioentry">
<span class="smallcaps">Whittle, P.</span> 1996. <em>Optimal control: Basics and beyond</em>. Wiley.
</div>
<div id="ref-Witsenhausen1979" class="csl-entry" role="doc-biblioentry">
<span class="smallcaps">Witsenhausen, H.S.</span> 1979. On the structure of real-time source coders. <em>Bell System Technical Journal</em> <em>58</em>, 6, 1437–1451.
</div>
</div>


<p class="categories">
This entry 

 was last updated on 11 Jan 2022
 and posted in 

<a href="https://adityam.github.io/stochastic-control/categories/stochastics">
  Stochastics</a>
and tagged
<a href="https://adityam.github.io/stochastic-control/tags/stochastic-optimization">stochastic optimization</a>,
<a href="https://adityam.github.io/stochastic-control/tags/principle-of-irrelevant-information">principle of irrelevant information</a>.</p>



    </div>
  </body>
</html>


