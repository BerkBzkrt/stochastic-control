<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<head>
  <meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="author" content="Aditya Mahajan" />
  <meta name="title" content="ECSE 506: Stochastic Control and Decision Theory" />
  <title>ECSE 506: Stochastic Control and Decision Theory</title>
  
  <meta content="infinite horizon,discounted cost,sample complexity,value iteration" name="keywords" />
  

  <link rel="stylesheet" href="https://adityam.github.io/stochastic-control//css/style.css" type="text/css" /><script type="text/javascript"
    src="https://adityam.github.io/stochastic-control/js/mathjax-local.js" defer>
  </script>
  <script type="text/javascript" id="MathJax-script" defer
    src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-svg.js">
  </script>

  <script type="module" defer
    src="//instant.page/3.0.0"
    integrity="sha384-OeDn4XE77tdHo8pGtE1apMPmAipjoxUQ++eeJa6EtJCfHlvijigWiJpD7VDPWXV1">
  </script>

  <script>var clicky_site_ids = clicky_site_ids || []; clicky_site_ids.push(101261731);</script>
  <script async src="//static.getclicky.com/js"></script>

</head>
<body>
<div id="content">
<div class="title">
  <h1>ECSE 506: Stochastic Control and Decision Theory </h1>
  <h2><a href="http://www.cim.mcgill.ca/~adityam/">Aditya Mahajan</a> <br/>
      Winter 2020
  </h2>
  <h3><a href="https://adityam.github.io/stochastic-control/ ">About</a>
	&nbsp;<small><small>|</small></small>&nbsp;
    <a href="https://adityam.github.io/stochastic-control//lectures">Lectures</a></span>
	&nbsp;<small><small>|</small></small>&nbsp;
    <a href="https://adityam.github.io/stochastic-control//notes">Notes</a></span>
	&nbsp;<small><small>|</small></small>&nbsp;
    <a href="https://adityam.github.io/stochastic-control//coursework">Coursework</a>
</h3>
</div>



<div class="h1-title">Theory: Sample complexity of value iteration</div>

<p>How many computations are needed to run the value or policy iteration algorithm to obtain a policy that in within <span class="math inline">\(ε\)</span> of the optimal? In this section, we provide an answer for this question for the value iteration algorithm.</p>
<p>Conisder an MDP with a finite state space <span class="math inline">\(\ALPHABET X = \{1, \dots, n \}\)</span> with a finite non-empty set of actions <span class="math inline">\(\ALPHABET U(x)\)</span> available at each <span class="math inline">\(x \in \ALPHABET X\)</span>. Each action set consists of <span class="math inline">\(M_x\)</span> actions with a total number of <span class="math inline">\(M = \sum_{x=1}^n M_x\)</span> actions. This number can be interpreted as the total number of state-action pairs. Let <span class="math inline">\(β \in (0, 1)\)</span> be the discount factor. We present the value iteration algorithm from the <a href="../discounted-mdp#value-iteration-algorithm">notes on discounted MDP</a> to achieve a pre-specified accuracy <span class="math inline">\(ε\)</span>.</p>
<div class="highlight">
<p><strong>Value Iteration Algorithm</strong></p>
<p>For given MDP, discount factor <span class="math inline">\(β \in (0,1)\)</span>, and constant <span class="math inline">\(ε &gt; 0\)</span></p>
<ol type="1">
<li>Start with any <span class="math inline">\(V_0 \in \reals^n\)</span>.</li>
<li>Recursively compute <span class="math inline">\(V_{k} = \mathcal B V_{k-1} = \mathcal B_{g_{k-1}} V_{k-1}.\)</span></li>
<li>Define <span class="math display">\[ Δ_k = \max\{ V_k(x) - V_{k-1}(x) \} - \min \{ V_k(x) - V_{k-1}(x) \}. \]</span></li>
<li>If <span class="math inline">\(Δ_k &gt; \frac{1 - β}{β} ε\)</span>, continue to step 2. Else carry out one more step of value update and choose the policy <span class="math inline">\(g_k\)</span>.</li>
</ol>
</div>
<p>As established in the <a href="../discounted-mdp#value-iteration-algorithm">notes on discounted MDP</a>, the algorithm stops in a finite number of iterations and the resulting policy is <span class="math inline">\(ε\)</span>-optimal.</p>
<h1 data-number="1" id="span-norm-contraction"><span class="header-section-number">1</span> Span norm contraction</h1>
<p>Let <span class="math inline">\(\SPAN(v) = \max(v) - \min(v)\)</span> denotes the span semi-norm. We start by stating some basic properties of span semi-norm.</p>
<ol type="1">
<li><span class="math inline">\(\SPAN(v) \ge 0\)</span> for all <span class="math inline">\(v \in \reals^n\)</span></li>
<li><span class="math inline">\(\SPAN(v + w) \le \SPAN(v) + \SPAN(w)\)</span> for all <span class="math inline">\(v, w \in \reals^n\)</span>.</li>
<li><span class="math inline">\(\SPAN(m v) \le |m| \SPAN(v)\)</span> for all <span class="math inline">\(v \in \reals^n\)</span> and <span class="math inline">\(m \in \reals\)</span>.</li>
<li><span class="math inline">\(\SPAN(v + m \mathbf{1}) = \SPAN(v)\)</span> for all <span class="math inline">\(m \in \reals\)</span>.</li>
<li><span class="math inline">\(\SPAN(v) = \SPAN(-v)\)</span>.</li>
<li><span class="math inline">\(\SPAN(v) \le 2\|v\|\)</span>.</li>
</ol>
<p>Properties 1–3 imply that <span class="math inline">\(\SPAN(v)\)</span> is a semi-norm. However, it is not a norm because of property 4; that is, <span class="math inline">\(\SPAN(v) = 0\)</span> does not imply that <span class="math inline">\(v = 0\)</span>. If <span class="math inline">\(\SPAN(v) = 0\)</span>, then <span class="math inline">\(v = m \mathbf{1}\)</span> for some scalar <span class="math inline">\(m\)</span>.</p>
<p>A basic result for our analysis is the following:</p>
<div class="highlight">
<dl>
<dt><span id="prop:span-matrix" class="pandoc-numbering-text prop"><strong>Prop. 1</strong></span></dt>
<dd><p>Let <span class="math inline">\(v \in \reals^n\)</span> and <span class="math inline">\(P\)</span> be any matrix of compatible dimensions. Then, <span class="math display">\[ \SPAN(P v) \le γ_P \SPAN(v), \]</span> where <span class="math display">\[\begin{equation} \label{eq:span-matrix}
γ_P = 1 - \min {x, y \in \ALPHABET X}
\sum_{z \in \ALPHABET X} \min\{ P_{xz}, P_{yz} \}.
  \end{equation}\]</span> Furhermore, <span class="math inline">\(γ_P \in [0, 1]\)</span> and there exists a <span class="math inline">\(v \in \reals^n\)</span> such that <span class="math inline">\(\SPAN(Pv) = γ_P \SPAN(v)\)</span>.</p>
</dd>
</dl>
</div>
<p><a href="#prop:span-matrix" title="Prop. 1"><span class="pandoc-numbering-link prop">Prop. 1</span></a> illustrates the “averaging” property of a transition matrix. By multiplying a vector by a transition matrix, the resulting vector has components which are more nearly equal. When <span class="math inline">\(P\)</span> is a square matrix, the quantity <span class="math inline">\(γ_P\)</span> is called the ergodicity coefficient, which is often written in an alternative form by using the relation <span class="math inline">\(|a - b| = (a + b) - 2 \min(a,b)\)</span>: <span class="math display">\[
  γ_P = \frac12
  \max_{x,y \in \ALPHABET X} \sum_{z \in \ALPHABET X}
  \bigl| P_{xz} - P_{yz} \bigr|. \]</span> The ergodicity coefficient is an upper bound on the second largest eigenvalue of <span class="math inline">\(P\)</span>. <span class="math inline">\(γ_P\)</span> equals <span class="math inline">\(0\)</span> if all rows of <span class="math inline">\(P\)</span> are equal and equals <span class="math inline">\(1\)</span> if at least two rows of <span class="math inline">\(P_d\)</span> are orthogonal. From a different perspective, <span class="math inline">\(γ_P &lt; 1\)</span> if for each pair of states there exists at least one state which they both can reach with positive probability in one step.</p>
<dl>
<dt><span id="rem:bound" class="pandoc-numbering-text rem"><strong>Remark 1</strong></span></dt>
<dd><p>Note that <span class="math display">\[ γ_P \le 1 - \sum_{z \in \ALPHABET X} \min_{x \in \ALPHABET X} P_{xz} 
=: γ_P&#39; \]</span> which is easier to compute.</p>
</dd>
</dl>
<h4 class="unnumbered" data-number="" id="proof">Proof</h4>
<p>Note that for any <span class="math inline">\(v \in \reals^n\)</span> <span class="math display">\[\begin{align*}
\SPAN(Pv) &amp;= \max_{x \in \ALPHABET X} \sum_{z \in \ALPHABET X} P_{xz} v_z 
- \min_{x \in \ALPHABET X} \sum_{z \in \ALPHABET X} P_{yz} v_z \\
&amp;= \max_{x, y \in \ALPHABET X} 
  \sum_{z \in \ALPHABET X} P_{xz} v_z - \sum_{z \in \ALPHABET X} P_{yz} v_z 
\end{align*}\]</span> Let <span class="math inline">\(B(z; x,y) = \min\{ P_{xz}, P_{yz} \}\)</span>. Then consider <span class="math display">\[\begin{align*}
  \sum_{z \in \ALPHABET X} P_{xz} v_z - \sum_{z \in \ALPHABET X} P_{yz} v_z 
  &amp;=
  \sum_{z \in \ALPHABET X} [ P_{xz} - B(z; x,y) ] v_z - 
  \sum_{z \in \ALPHABET X} [ P_{yz} - B(z; x,y) ] v_z \\
  &amp;\le 
  \sum_{z \in \ALPHABET X} [ P_{xz} - B(z; x,y) ] \max(v) -
  \sum_{z \in \ALPHABET X} [ P_{yz} - B(z; x,y) ] \min(v) 
  \\
  &amp;= \biggl[ 1 - \sum_{z \in \ALPHABET X} B(z; x, y) \biggr] \SPAN(v).
\end{align*}\]</span> Hence, <span class="math display">\[ \SPAN(Pv) \le \max_{x, y \in \ALPHABET X} \biggl[
  1 - \sum_{z \in \ALPHABET X} B(z; x, ) \biggr] \SPAN(v). \]</span></p>
<p>Now we show that there exists a <span class="math inline">\(v\)</span> such that \eqref{eq:span-matrix} holds with equality. If <span class="math inline">\(γ_P = 0\)</span>, then <span class="math inline">\(P\)</span> has equal rows, so that <span class="math inline">\(\SPAN(Pv) = 0 = 0 \cdot \SPAN(v)\)</span> for all <span class="math inline">\(v \in \reals^n\)</span>. Suppose <span class="math inline">\(γ_P &gt; 0\)</span>. Using the identity <span class="math inline">\([ a - b]^{+} = a - \min(a,b)\)</span>, we can write <span class="math display">\[
`γ_P = \max_{x,y \in \ALPHABET X} 
\sum_{z \in \ALPHABET  X} \bigl[ P_{xz} - P_{yz} \bigr]^{+}.
\]</span> Let <span class="math inline">\(x^*\)</span> and <span class="math inline">\(y^*\)</span> be such that <span class="math display">\[
  γ_P = \sum_{z \in \ALPHABET X}  
\sum_{z \in \ALPHABET  X} \bigl[ P_{x^*z} - P_{y^*z} \bigr]^{+}.
\]</span> Define <span class="math inline">\(v\)</span> by <span class="math display">\[ 
  v_z = \IND\{ P_{x^*z} &gt; P_{y^*z} \}.
\]</span> Then, note that <span class="math inline">\(\SPAN(v) = 1\)</span> and <span class="math display">\[\begin{align*}
  \SPAN(Pv) &amp;\ge 
  \sum_{z \in \ALPHABET X} P_{x^* z} v_z - 
  \sum_{z \in \ALPHABET X} P_{y^* z} v_z \\
  &amp;=
  \sum_{z \in \ALPHABET  X} \bigl[ P_{x^*z} - P_{y^*z} \bigr]^{+}
  \\
  &amp;= γ_P \SPAN(v).
\end{align*}\]</span> Combining with \eqref{eq:span-matrix}, we get <span class="math inline">\(\SPAN(Pv) = γ_P \SPAN(v)\)</span>. <span class="math inline">\(\Box\)</span></p>
<p>Define the contraction factor <span class="math display">\[\begin{equation}\label{eq:contraction}
  γ = \max_{\substack{ x,y \in \ALPHABET X \\ u \in \ALPHABET U(x), w \in
  \ALPHABET U(y)}}
  \biggl[ 1 - \sum_{z \in \ALPHABET X} 
    \min\{ P(z | x,u), P(z | y, w) \biggr].
\end{equation}\]</span> Note that <span class="math inline">\(γ \in [0, 1]\)</span>.</p>
<div class="highlight">
<dl>
<dt><span id="theorem:span-contraction" class="pandoc-numbering-text theorem"><strong>Theorem 1</strong></span></dt>
<dd><p>For any <span class="math inline">\(V_1, V_2 \in \reals^n\)</span>, <span class="math display">\[ \SPAN(\mathcal B V_1 - \mathcal B V_2) \le β γ\, \SPAN(V_1 - V_2). \]</span></p>
</dd>
</dl>
</div>
<h4 class="unnumbered" data-number="" id="proof-1">Proof</h4>
<p>Let <span class="math inline">\(g_i\)</span> be such that <span class="math inline">\(\mathcal B V_i = \mathcal B_{g_i}V_i\)</span>. Let <span class="math display">\[\begin{align*}
  x^* &amp;= \arg \max_{x \in \ALPHABET X}(\mathcal B V_1(x) - \mathcal B V_2(x)), 
  \\
  x_* &amp;= \arg \min_{x \in \ALPHABET X}(\mathcal B V_1(x) - \mathcal B V_2(x)),
\end{align*}\]</span> Then, <span class="math display">\[
  \mathcal B V_1(x^*) - \mathcal B V_2(x^*) \le 
  \mathcal B_{g_2} V_1(x^*) - \mathcal B_{g_2} V_2(x^*) 
  = β P_{g_2}(V_1 - V_2)(x^*)
\]</span> and <span class="math display">\[
  \mathcal B V_1(x_*) - \mathcal B V_2(x_*) \ge 
  \mathcal B_{g_1} V_1(x^*) - \mathcal B_{g_1} V_2(x^*) 
  = β P_{g_1}(V_1 - V_2)(x^*).
\]</span> Therefore, <span class="math display">\[\begin{align*}
  \SPAN(\mathcal B V_1 - \mathcal B V_2) &amp;\le
  β P_{g_2}(V_1 - V_2)(x^*) - β P_{g_1}(V_1 - V_2)(x_*) \\
  &amp;\le \max_{x \in \ALPHABET X} β P_{g_2} (V_1 - V_2)(x) -
  \min_{x \in \ALPHABET X} β P_{g_1}(V_1 - V_2)(x)
  \\
  &amp;\le \SPAN(β\, \ROWS(P_{g_2}, P_{g_1})(V_1 - V_2).
\end{align*}\]</span> By applying <a href="#prop:span-matrix" title="Prop. 1"><span class="pandoc-numbering-link prop">Prop. 1</span></a>, we get <span class="math display">\[ \SPAN(\mathcal B V_1 - \mathcal B V_2) \le βγ_{\bar P} \SPAN(V_1 - V_2), \]</span> where <span class="math inline">\(γ_{\bar P}\)</span> is given by \eqref{eq:span-matrix} with <span class="math inline">\(\bar P = \ROWS(P_{g_2}, P_{g_1})\)</span>. The result follows by noting that <span class="math inline">\(γ_{\bar P}\)</span> is at most <span class="math inline">\(γ\)</span>. <span class="math inline">\(\Box\)</span></p>
<h1 data-number="2" id="sample-complexity-of-value-iteration"><span class="header-section-number">2</span> Sample complexity of value iteration</h1>
<p>Note that <span class="math inline">\(γ \in [0, 1]\)</span>. We will first rule out the case <span class="math inline">\(γ = 0\)</span>. If <span class="math inline">\(γ = 0\)</span>, then <span class="math inline">\(P(z | x, u) = P(z | y, w)\)</span> for all <span class="math inline">\(x, y, z \in \ALPHABET X\)</span> and <span class="math inline">\(u \in \ALPHABET U(x)\)</span> and <span class="math inline">\(w \in \ALPHABET U(y)\)</span>, which implies that all deterministic policies have the same transition probabilities. Therefore, a deterministic policy <span class="math inline">\(g\)</span> is optimal if and only if it minimize the one-step cost. Thus, the case with <span class="math inline">\(γ = 0\)</span> is trivial. So, in the rest of the analysis, we assume that <span class="math inline">\(γ \in (0, 1)\)</span>.</p>
<p>Suppose <span class="math inline">\(Δ_1 &gt; 0\)</span> (else we obtained an optimal policy at iteration 1). Define: <span class="math display">\[\begin{equation}\label{eq:K*}
  K^*(β) = \max \left\{ \left\lceil
  \frac{ \log \frac{(1-β) ε γ}{Δ_1} } {\log(βγ)}
  \right\rceil
  ,1 \right\}.
\end{equation}\]</span></p>
<div class="highlight">
<dl>
<dt><span id="theorem:VI-bound" class="pandoc-numbering-text theorem"><strong>Theorem 2</strong></span></dt>
<dd><p>For any <span class="math inline">\(ε &gt; 0\)</span>, value iteration finds an <span class="math inline">\(ε\)</span>-optimal policy in no more than <span class="math inline">\(K^*(β)\)</span> iterations. In addition, each iteration uses at most <span class="math inline">\(O(nM)\)</span> operations.</p>
</dd>
</dl>
</div>
<h4 class="unnumbered" data-number="" id="proof-2">Proof</h4>
<p>If follows from the definition of Bellman operator that each iteration uses at most <span class="math inline">\(O(nM)\)</span> iterations (to compute the <span class="math inline">\(Q\)</span> function, for each state-action pair, we need to compute a sum over <span class="math inline">\(n\)</span> terms).</p>
<p>From <a href="#theorem:span-contraction" title="Theorem 1"><span class="pandoc-numbering-link theorem">Theorem 1</span></a>, we get that <span class="math inline">\(Δ_k \le (βγ)^{k-1} Δ_1\)</span>. Therefore, the minimum number of iterations required to achieve <span class="math inline">\(Δ_k \le \frac{1-β}{β}ε\)</span> is given <span class="math inline">\(K^*(β)\)</span>. <span class="math inline">\(\Box\)</span></p>
<dl>
<dt><span id="rem:simple" class="pandoc-numbering-text rem"><strong>Remark 2</strong></span></dt>
<dd><p>Note that finding the value of <span class="math inline">\(γ\)</span> requires computing the sum in \eqref{eq:contraction} for all couples <span class="math inline">\(\{ (x,u), (y,w) \}\)</span> of state action pairs such that <span class="math inline">\((x,u) \neq (y,w)\)</span>. The total number of such pairs are <span class="math inline">\(M(M-1)/2 = O(M^2)\)</span>. Therefore, the number of arithematic operators in \eqref{eq:contraction}, which are additions, is <span class="math inline">\(n\)</span> for each couple. Therefore, computation of <span class="math inline">\(γ\)</span> requires <span class="math inline">\(O(nM^2)\)</span> operations, which can be significantly larger than the complexity of computing an <span class="math inline">\(ε\)</span>-optimal policy which is given by <a href="#theorem:VI-bound" title="Theorem 2"><span class="pandoc-numbering-link theorem">Theorem 2</span></a>! Based on <a href="#rem:bound" title="Remark 1"><span class="pandoc-numbering-link rem">Remark 1</span></a>, we can replace <span class="math inline">\(γ\)</span> by in \eqref{eq:K*} by <span class="math display">\[
  γ&#39; = 1 - \sum_{z \in \ALPHABET X} \min_{x \in \ALPHABET X, u \in \ALPHABET U}
   P(z | x,u)
\]</span> which requies <span class="math inline">\(O(nM)\)</span> operations.</p>
</dd>
</dl>
<h1 class="unnumbered" data-number="" id="references">References</h1>
<p>The material presented here is taken from <span class="citation" data-cites="Feinberg2020">Feinberg and He (<a href="#ref-Feinberg2020" role="doc-biblioref">2020</a>)</span>. Note that <a href="#theorem:VI-bound" title="Theorem 2"><span class="pandoc-numbering-link theorem">Theorem 2</span></a> is essentially a corollary of Theorems 6.6.5 and 6.6.6 of <span class="citation" data-cites="Puterman2014">Puterman (<a href="#ref-Puterman2014" role="doc-biblioref">2014</a>)</span>, but the explict form was not stated there.</p>
<div id="refs" class="references hanging-indent" role="doc-bibliography">
<div id="ref-Feinberg2020">
<p><span class="smallcaps">Feinberg, E.A. and He, G.</span> 2020. Complexity bounds for approximately solving discounted MDPs by value iterations. <em>Operations Research Letters</em>. DOI: <a href="https://doi.org/10.1016/j.orl.2020.07.001">10.1016/j.orl.2020.07.001</a>.</p>
</div>
<div id="ref-Puterman2014">
<p><span class="smallcaps">Puterman, M.L.</span> 2014. <em>Markov decision processes: Discrete stochastic dynamic programming</em>. John Wiley &amp; Sons. DOI: <a href="https://doi.org/10.1002/9780470316887">10.1002/9780470316887</a>.</p>
</div>
</div>


<p class="categories">
This entry 

 was last updated on 07 Jul 2020
 and posted in 

<a href="https://adityam.github.io/stochastic-control/categories/mdp">
  MDP</a>
and tagged
<a href="https://adityam.github.io/stochastic-control/tags/infinite-horizon">infinite horizon</a>,
<a href="https://adityam.github.io/stochastic-control/tags/discounted-cost">discounted cost</a>,
<a href="https://adityam.github.io/stochastic-control/tags/sample-complexity">sample complexity</a>,
<a href="https://adityam.github.io/stochastic-control/tags/value-iteration">value iteration</a>.</p>



    </div>
  </body>
</html>


