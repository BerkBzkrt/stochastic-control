<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<head>
  <meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="author" content="Aditya Mahajan" />
  <meta name="title" content="ECSE 506: Stochastic Control and Decision Theory" />
  <title>ECSE 506: Stochastic Control and Decision Theory</title>
  
  <meta content="Linear systems,Riccati equation,LQR,communication" name="keywords" />
  

  <link rel="stylesheet" href="https://adityam.github.io/stochastic-control//css/style.css" type="text/css" /><script type="text/javascript"
    src="https://adityam.github.io/stochastic-control/js/mathjax-local.js" defer>
  </script>
  <script type="text/javascript" id="MathJax-script" defer
    src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-svg.js">
  </script>

  <script type="module" defer
    src="//instant.page/3.0.0"
    integrity="sha384-OeDn4XE77tdHo8pGtE1apMPmAipjoxUQ++eeJa6EtJCfHlvijigWiJpD7VDPWXV1">
  </script>

  <script>var clicky_site_ids = clicky_site_ids || []; clicky_site_ids.push(101261731);</script>
  <script async src="//static.getclicky.com/js"></script>

</head>
<body>
<div id="content">
<div class="title">
  <h1>ECSE 506: Stochastic Control and Decision Theory </h1>
  <h2><a href="http://www.cim.mcgill.ca/~adityam/">Aditya Mahajan</a> <br/>
      Winter 2020
  </h2>
  <h3><a href="https://adityam.github.io/stochastic-control/ ">About</a>
	&nbsp;<small><small>|</small></small>&nbsp;
    <a href="https://adityam.github.io/stochastic-control//lectures">Lectures</a></span>
	&nbsp;<small><small>|</small></small>&nbsp;
    <a href="https://adityam.github.io/stochastic-control//notes">Notes</a></span>
	&nbsp;<small><small>|</small></small>&nbsp;
    <a href="https://adityam.github.io/stochastic-control//coursework">Coursework</a>
</h3>
</div>



<div class="h1-title">Networked control systems with communication cost</div>

<p>In this section, we extend the model of a <a href="../ncs">simple NCS</a> to one where there a cost associated with sending data from the sensor to the controller. This cost may be due to considerations of transmit power at the sensor or it may be a viewed as a Lagrange multiplier if multiple sensors are sharing the same communication channel with limited bandwidth.</p>
<p>As before, we consider a linear system with state <span class="math inline">\(x_t \in \reals^n\)</span> and control action <span class="math inline">\(u_t \in \reals^n\)</span> where the initial state <span class="math inline">\(x_1\)</span> has zero mean and finite variance <span class="math inline">\(Σ^x_1\)</span>. The system dynamics are given by <span class="math display">\[ x_{t+1} = A_t x_t + B_t u_t + w_t, \]</span> where <span class="math inline">\(A_t \in \reals^{n×n}\)</span> and <span class="math inline">\(B_t \in \reals^{n×m}\)</span> are known matrices and <span class="math inline">\(\{w_t\}_{t\ge 1}\)</span> is <span class="math inline">\(\reals^n\)</span>-valued i.i.d. noise process with zero mean and finite variance <span class="math inline">\(\Sigma^w\)</span>. We make the standard assumption that the primitive random variables <span class="math inline">\(\{x_1, w_1, \dots, w_T\}\)</span> are independent.</p>
<p>There is a sensor which is co-located with the plant. The key modeling assumption of this model is that the sensor decides whether or not to transmit to the controller. Let <span class="math inline">\(δ_t \in \{0, 1\}\)</span> denote the decision of the sensor, where <span class="math inline">\(δ_t = 0\)</span> denotes that the sensor decides not to transmit and <span class="math inline">\(δ_t = 1\)</span> denotes that the sensor decides to transmit.</p>
<p>As before, we assume that there is a i.i.d. packet-drop communication channel between the sensor and the controller. The packet-drop channel may be thought of as an ON-OFF channel. We use the variable <span class="math inline">\(γ_t \in \{0, 1\}\)</span> to denote the state of the channel, where <span class="math inline">\(γ_t = 0\)</span> denotes that the channel is OFF (which means that any transmitted packet is dropped) and <span class="math inline">\(γ_t = 1\)</span> denotes that the channel is ON (which means that any transmitted packet is delieved). We assume that <span class="math inline">\(\{γ_1, \dots, γ_T \}\)</span> is an i.i.d. Bernoulli process with success probability <span class="math inline">\(\PR(γ_t = 1) = 1-p\)</span>. We assume that the transmission over the packet-drop channel takes place using a TCP-like protocol, so the sensor gets an ACK (acknowledgment) or NACK (negative acknowledgment) to indicate whether the controller received the packet.</p>
<p>Let <span class="math inline">\(y_t \in \reals^n \cup \{\BLANK\}\)</span> denote the observation of the receiver, where <span class="math inline">\(\BLANK\)</span> denotes the event that the transmitted packet was dropped. Then, we have that <span class="math display">\[ y_t = \begin{cases}
    x_t, &amp; \text{if } δ_t γ_t = 1, \\
    \BLANK, &amp; \text{if } δ_t γ_t = 0. 
\end{cases}\]</span> For ease of notation, we use <span class="math inline">\(z_t = δ_t γ_t \in \{0, 1\}\)</span> to denote event whether the controller received a packet or not.</p>
<p>Let <span class="math inline">\(I^δ_t\)</span> and <span class="math inline">\(I^u_t\)</span> denote the information available to the sensor and the controller respectively. We assume that <span class="math display">\[\begin{align*}
  I^δ_t &amp;= \{ x_{1:t}, δ_{1:t-1}, z_{1:t-1} \}, \\
  I^u_t &amp;= \{ y_{1_t}, u_{1:t-1} \}.
\end{align*}\]</span> Thus, the sensor knows the history <span class="math inline">\(x_{1:t}\)</span> of its past observations, the history <span class="math inline">\(δ_{1:t-1}\)</span> of its past decisions and the history <span class="math inline">\(z_{1:t-1}\)</span> of the ACK/NACK received from the controller. The controller knows the history <span class="math inline">\(y_{1:t}\)</span> of the past channel outputs and the history <span class="math inline">\(u_{1:t-1}\)</span> of its past control actions.</p>
<p>The sensor generates the transmit decision <span class="math inline">\(δ_t\)</span> using the information <span class="math inline">\(I^δ_t\)</span> and the controller generates a control action <span class="math inline">\(u_t\)</span> using the information <span class="math inline">\(I^u_t\)</span>. Thus, <span class="math display">\[ δ_t = f_t(I^δ_t)
   \quad\text{and}\quad
   u_t = g_t(I^u_t), \]</span> where <span class="math inline">\(f = (f_1, \dots, f_T)\)</span> is called the transmission strategy and <span class="math inline">\(g = (g_1, \dots, g_T)\)</span> is called the control strategy.</p>
<p>It is helpful to work with an expanded information structure at the sensor. In particular, note that the sensor can infer <span class="math inline">\(y_{1:t-1}\)</span> from <span class="math inline">\(x_{1:t-1}\)</span> and <span class="math inline">\(z_{1:t-1}\)</span> and can recursively infer <span class="math inline">\(u_{1:t-1}\)</span> from <span class="math inline">\(y_{1:t-1}\)</span>. So, in the sequel, we assume that the information available at the sensor is given by <span class="math display">\[ I^δ_t = \{ x_{1:t}, δ_{1:t-1}, z_{1:t-1}, y_{1:t-1}, u_{1:t-1}\}. \]</span></p>
<p>There are two costs at each time. A communication cost <span class="math inline">\(λ δ_t\)</span>, where <span class="math inline">\(λ\)</span> denotes the cost of transmitting a packet and a regulation cost <span class="math inline">\(x_t^\TRANS Q_t x_t + u_t^\TRANS R_t u_t\)</span>, where <span class="math inline">\(Q_t\)</span> is a positive semi-definite matrix and <span class="math inline">\(R_t\)</span> is a postitive definite matrix. Thus, the performance of any strategy <span class="math inline">\((f,g)\)</span> is given by <span class="math display">\[\begin{equation} \label{eq:cost}
  J(f, g) = \EXP^{f,g} \Bigl[ \sum_{t=1}^{T-1} \bigl[ λδ_t + x_t^\TRANS Q_t x_t 
  + u_t^\TRANS R_t u_t \bigr] + x_T^\TRANS Q_T x_T \Bigr].
\end{equation} \]</span></p>
<p>Given the system dynamics, the noise statistics, and the channel statistics, we are interested in choosing a decision strategy <span class="math inline">\((f,g)\)</span> to minimize the total expected cost <span class="math inline">\(J(f,g)\)</span> given by \eqref{eq:cost}.</p>
<h1 data-number="1" id="completion-of-squares-argument"><span class="header-section-number">1</span> Completion of squares argument</h1>
<p>Again, we will follow the completion of squares based approach introduced in <a href="../lqr#astrom">the notes of LQR</a>.</p>
<p>Using Prop. 1 of <a href="../lqr#astrom">LQR</a>, the total cost of any strategy <span class="math inline">\(g\)</span> may be written as follows: <span class="math display">\[ \begin{align}
    J(g) = &amp; \EXP\bigg[ \sum_{t=1}^{T-1} (u_t + L_t x_t)^\TRANS [R_t + B_t^\TRANS
    S_{t+1}B_t] (u_t + L_t x_t) \bigg] \nonumber \\
    &amp; \quad + 
    \EXP\bigg[ x_1^\TRANS S_1 x_t + \sum_{t=1}^{T-1} w_t S_{t+1} w_t \bigg], \label{eq:astrom}
\end{align}\]</span> where the <em>gain matrices</em> <span class="math inline">\(\{L_t\}_{t\ge 1}\)</span> are given by: <span class="math display">\[ L_t = [R_t + B_t^\TRANS S_{t+1} B_t]^{-1} \Lambda_t \]</span> where <span class="math display">\[ \Lambda_t = B_t^\TRANS S_{t+1} A_t \]</span> and <span class="math inline">\(\{S_t\}_{t=1}^T\)</span> are determined by the solution of the <em>backward Riccati equation</em>: <span class="math inline">\(S_T = Q_T\)</span> and for <span class="math inline">\(t \in \{T-1, \dots, 1\}\)</span>: <span class="math display">\[\begin{equation}\label{eq:riccati}
  S_t = A_t^\TRANS S_{t+1} A_t + Q_t - 
  \Lambda_t^\TRANS [ R_t + B_t^\TRANS S_{t+1} B_t ] ^{-1} \Lambda_t.
\end{equation}\]</span></p>
<dl>
<dt>Remark</dt>
<dd><p>The matrices <span class="math inline">\(\{L_t\}_{t=1}^T\)</span> and <span class="math inline">\(\{S_t\}_{t=1}^T\)</span> are the same as in the basic LQR model.</p>
</dd>
</dl>
<p>Now, as in the solution to the LQR problem, we note that the second term of \eqref{eq:astrom} is a function of the primitive random variables and does not depend on the choice of the control strategy <span class="math inline">\(g\)</span>. Thus, in order to minimize the total expected cost, it sufficies to minimize the first term of \eqref{eq:astrom}. However, unlike the case in LQR with perfect state observation, we cannot simply choose <span class="math inline">\(u_t = -L_t x_t\)</span> because the state <span class="math inline">\(x_t\)</span> is not known to the observer at all time instances. In the next section, we use state splitting and orthogonal projection to minimize the first term of \eqref{eq:astrom}.</p>
<h1 data-number="2" id="state-splitting-and-static-reduction"><span class="header-section-number">2</span> State splitting and static reduction</h1>
<p>We split the state <span class="math inline">\(x_t\)</span> into two components: <span class="math inline">\(x_t = x^g_t + x^s_t\)</span>, where <span class="math display">\[\begin{align*}
  x^g_1 &amp;=0, &amp; x^s_1 &amp;= x_1, \\
  x^g_{t+1} &amp;= A_t x^g_t + B_t u_t, &amp;
  x^s_{t+1} &amp;= A_t x^s_t + w_t.
\end{align*}\]</span> We refer to <span class="math inline">\(x^g_t\)</span> and <span class="math inline">\(x^s_t\)</span> as the controlled and control-free components of the state, respectively. Now, define controlled and control-free components <span class="math inline">\((y^g_t, y^s_t)\)</span> of the observation as follows: <span class="math display">\[
  (y^g_t, y^s_t) = \begin{cases}
  (x^g_t, x^s_t), &amp; \text{if } z_t = 1, \\
  (\BLANK, \BLANK), &amp; \text{if } z_t = 0.
\end{cases}\]</span> If we define <span class="math inline">\(\BLANK + \BLANK = \BLANK\)</span>, then we have that <span class="math inline">\(y_t = y^g_t + y^s_t\)</span>. Now define the static reduction of the information structure: <span class="math display">\[
  I^{δ,s}_t = \{ x^s_{1:t} \} 
  \quad\text{and}\quad
  I^{u,s}_t = \{ y^s_{1:t} \}.
\]</span></p>
<div class="highlight">
<dl>
<dt><span id="lemma:1"></span><span id="lemma:static" class="pandoc-numbering-text lemma"><strong>Lemma 1</strong></span></dt>
<dd><p><strong>(Static reduction)</strong> For any strategy <span class="math inline">\((f,g)\)</span>, <span class="math display">\[ I^δ_t ≡ I^{δ,s}_t
   \quad\text{and}\quad
   I^u_t ≡ I^{u,s}_t, \]</span> that is, these information sets generate the same sigma algebras. Equivalently, <span class="math inline">\(I^δ_t\)</span> and <span class="math inline">\(I^{δ,s}_t\)</span> are functions of each other and so are <span class="math inline">\(I^u_t\)</span> and <span class="math inline">\(I^{u,s}_t\)</span>.</p>
</dd>
</dl>
</div>
<h4 class="unnumbered" id="proof">Proof</h4>
<p>To be written <span class="math inline">\(\Box\)</span></p>
<p>An implication of <a href="#lemma:static" title="Lemma 1"><span class="pandoc-numbering-link lemma">Lemma 1</span></a> is that we can replace conditioning on <span class="math inline">\(I^u_t\)</span> by conditioning on <span class="math inline">\(I^{u,s}_t\)</span> in any conditional probability expression.</p>
<p>Another implication is the following.</p>
<div class="highlight">
<dl>
<dt><span id="corollary:1"></span><span id="corollary:structure" class="pandoc-numbering-text corollary"><strong>Corollary 1</strong></span></dt>
<dd><p>For any strategy <span class="math inline">\((f,g)\)</span>, there exists a transmission strategy <span class="math inline">\(\tilde f = (\tilde f_1, \dots, \tilde f_{T-1})\)</span>, where <span class="math inline">\(\tilde f_t \colon I^{δ,s} \mapsto δ_t\)</span>, such that <span class="math inline">\(J(f, g) = J(\tilde f, g)\)</span>.</p>
</dd>
</dl>
</div>
<p>Now, in the rest of this section, we assume that the strategy at the sensor is of the form <span class="math inline">\(\tilde f\)</span> described in <a href="#corollary:structure" title="Corollary 1"><span class="pandoc-numbering-link corollary">Corollary 1</span></a>. Therefore, the transmission decision <span class="math inline">\(δ_t = \tilde f_t(I^{δ,s}_t\)</span> depends only on the primitive decisions. Thus, <span class="math inline">\(\{z_1, \dots, z_T\}\)</span>, where <span class="math inline">\(z_t = δ_t γ_t\)</span>, depends only on the primitive random variables. Note that <span class="math display">\[\begin{align*}
  \PR(z_{t+1} = 1 | z_{1:t}) &amp;= \PR(δ_{t+1} = 1, γ_{t+1} = 1 | z_{1:t}) \\
  &amp;= \PR(δ_{t+1} = 1 | z_{1:t}) \PR(γ_{t+1} = 1)
\end{align*}\]</span></p>
<h1 data-number="3" id="orthogonal-projection"><span class="header-section-number">3</span> Orthogonal projection</h1>
<p>To simplify the first term of \eqref{eq:astrom}, define <span class="math display">\[ \hat x_t = \EXP[ x_t | I^u_t ]\]</span> as the conditional estimate of the state given the observations at the controller and define <span class="math display">\[ \tilde x_t = x_t - \hat x_t\]</span> as the corresponding estimation error.</p>
<p>Then, these have the following properties.</p>
<div class="highlight">
<dl>
<dt><span id="lemma:2"></span><span id="lemma:properties" class="pandoc-numbering-text lemma"><strong>Lemma 2</strong></span></dt>
<dd><p>For any control strategy <span class="math inline">\(g\)</span>, we have</p>
<ol type="1">
<li>$x_t = x^s_t - $ is control-free and can be written just in terms of the primitive random variables.</li>
</ol>
<p>Furthermore, for any matrix <span class="math inline">\(M\)</span> of appropriate dimensions:</p>
<ol start="2" type="1">
<li><span class="math inline">\(\EXP[\hat x_t^\TRANS M \tilde x_t ] = 0\)</span>.</li>
<li><span class="math inline">\(\EXP[ u_t^\TRANS M \tilde x_t ] = 0\)</span>.</li>
</ol>
</dd>
</dl>
</div>
<h4 class="unnumbered" id="proof-1">Proof</h4>
<p>To prove part 1, we note that <span class="math display">\[\begin{align}
  \tilde x_t &amp;= x_t - \EXP[x_t | I^u_t ] \notag \\
  &amp;\stackrel{(a)}= x^g_t + x^s_t - \EXP[ x^g_t + x^s_t | I^u_t] \notag \\
  &amp;\stackrel{(b)}= x^s_t - \EXP[x^s_t | I^u_t ] \notag \\
  &amp;\stackrel{(c)}= x^s_t - \EXP[x^s_t | I^{u,s}_t ] \label{eq:tilde-x}
\end{align}\]</span> where <span class="math inline">\((a)\)</span> follows from state splitting, <span class="math inline">\((b)\)</span> follows from the fact that <span class="math inline">\(x^g_t\)</span> is a function of <span class="math inline">\(u_{1:t-1}\)</span> which is a part of <span class="math inline">\(I^u_t\)</span>, and <span class="math inline">\((c)\)</span> follows from <a href="#lemma:static" title="Lemma 1"><span class="pandoc-numbering-link lemma">Lemma 1</span></a>. Part 1 then follows by observing that \eqref{eq:tilde-x} depends only on primitive random variables.</p>
<p>To prove parts 2 and 3, let <span class="math inline">\(z_t\)</span> be a function of <span class="math inline">\(I^u_t\)</span> and <span class="math inline">\(M\)</span> be a matrix of appropriate dimensions. Then, <span class="math display">\[\begin{align}
  \EXP[z_t^\TRANS M \tilde x_t] 
  &amp;\stackrel{(d)}= \EXP[ \EXP[ z_t^\TRANS M \tilde x_t | I^u_t ] ] 
  \notag \\
  &amp;\stackrel{(e)}= \EXP[ z_t^\TRANS M \EXP[ \tilde x_t | I^u_t ] ] \notag \\
  &amp;\stackrel{(f)}= 0.
\end{align}\]</span> where <span class="math inline">\((d)\)</span> follows from the smoothing property of conditional expectation, <span class="math inline">\((e)\)</span> follows from the fact that <span class="math inline">\(z_t\)</span> is a function of <span class="math inline">\(I^u_t\)</span>, and <span class="math inline">\((f)\)</span> follows from the fact that <span class="math inline">\(\EXP[\tilde x_t | I^u_t] = 0\)</span> by construction.</p>
<p>Part 2 follows from observing that <span class="math inline">\(\hat x_t\)</span> is a function of <span class="math inline">\(I^u_t\)</span>. Part 3 follows from observing that <span class="math inline">\(u_t\)</span> is a function of <span class="math inline">\(I^u_t\)</span>. <span class="math inline">\(\Box\)</span></p>
<div class="highlight">
<dl>
<dt><span id="lemma:3"></span><span id="lemma:simplify" class="pandoc-numbering-text lemma"><strong>Lemma 3</strong></span></dt>
<dd><p>For any control strategy <span class="math inline">\(g\)</span>, the first term of \eqref{eq:astrom} may be written as <span class="math display">\[\begin{align}
  &amp; \EXP^{g}\Bigl[ \sum_{t=1}^{T-1} (u_t + L_t \hat x_t)^\TRANS
  [R_t + B_t^\TRANS S_{t+1} B_t](u_t + L_t \hat x_t) ] \notag \\
  &amp;\quad + 
  \EXP\Bigl[ \sum_{t=1}^{T-1} (L_t \tilde x_t)^\TRANS
  [R_t + B_t^\TRANS S_{t+1} B_t](L_t \tilde x_t) ] \label{eq:simple}
\end{align}\]</span></p>
</dd>
</dl>
</div>
<h4 class="unnumbered" id="proof-2">Proof</h4>
<p><a href="#lemma:properties" title="Lemma 2"><span class="pandoc-numbering-link lemma">Lemma 2</span></a> implies that for any matrix <span class="math inline">\(M\)</span> of appropriate dimensions, <span class="math display">\[ \EXP[ (u_t + L_t x_t)^\TRANS M (u_t + L_t x_t) =
\EXP[ (u_t + L_t \hat x_t)^\TRANS M (u_t + L_t \hat x_t) ] +
\EXP[ (L_t \tilde x_t)^\TRANS M (L_t \tilde x_t) ], \]</span> where the cross-terms are zero due to parts 2 and 3 of <a href="#lemma:properties" title="Lemma 2"><span class="pandoc-numbering-link lemma">Lemma 2</span></a>. The result of the Lemma follows by repeatedly using the above property at each time step.</p>
<h1 data-number="4" id="main-result"><span class="header-section-number">4</span> Main Result</h1>
<div class="highlight">
<dl>
<dt><span id="theorem:1"></span><span id="theorem:main" class="pandoc-numbering-text theorem"><strong>Theorem 1</strong></span></dt>
<dd><p>For any transmission strategy <span class="math inline">\(\tilde f\)</span> of the form given in <a href="#corollary:structure" title="Corollary 1"><span class="pandoc-numbering-link corollary">Corollary 1</span></a>, the best response control strategy for the networked control system discussed in this section is given by <span class="math display">\[\begin{equation} \label{eq:optimal}
  u_t = - L_t \hat x_t.
\end{equation}\]</span> Furthermore, the state estimate <span class="math inline">\(\hat x_t\)</span> is given by <span class="math display">\[\hat x_{t} = x^g_t + \EXP[ x^s_t | I^{u,s}_t]\]</span></p>
</dd>
</dl>
</div>
<h4 class="unnumbered" id="proof-3">Proof</h4>
<p>The proof of the structure of the optimal controller follows by combining various properties described above. In particular, we have shown that for any any control strategy <span class="math inline">\(g\)</span>, the total cost can be written as \eqref{eq:astrom}, where the second term depends just on the primitive random variables. Moreover, the first term of \eqref{eq:astrom} can be written as \eqref{eq:simple}, where (by <a href="#lemma:properties" title="Lemma 2"><span class="pandoc-numbering-link lemma">Lemma 2</span></a>, part 1) the second term is control free and depends just on the primitive random variables. Therefore, it suffices to minimize the first term of \eqref{eq:simple} to minimizing <span class="math inline">\(J(g)\)</span>. By assumption, <span class="math inline">\(S_T = Q_T\)</span> is positive semi-definite. It can be recursively shown that <span class="math inline">\(S_t\)</span> is also positive definite. Therefore, the first term of \eqref{eq:simple} is greater than or equal to zero, with equality if and only if the strategy is given by \eqref{eq:optimal}. Since the policy \eqref{eq:optimal} achieves the minimal value of the cost, it is optimal.</p>
<p>We now show the structure of the state estimate. Note that <span class="math display">\[\begin{align*}
  \hat x_{t} &amp;= \EXP[ x_{t} | I^{u}_{t} ] = \EXP[ x^g_t + x^s_t | I^u_t ] \\
  &amp;\stackrel{(a)}= x^g_t + \EXP[ x^s_t | I^u_t ] \\
  &amp;\stackrel{(b)}= x^g_t + \EXP[ x^s_t | I^{u,s}_t ] 
\end{align*}\]</span> where <span class="math inline">\((a)\)</span> follows from the fact that <span class="math inline">\(x^g_t\)</span> is a function of <span class="math inline">\(u_{1:t-1}\)</span> which is a part of <span class="math inline">\(I^u_t\)</span> and <span class="math inline">\((b)\)</span> follows from <a href="#lemma:static" title="Lemma 1"><span class="pandoc-numbering-link lemma">Lemma 1</span></a>. <span class="math inline">\(\Box\)</span></p>
<hr />
<p>Note that unlike the <a href="../ncs">previous model of NCS</a>, in the current model, we cannot identify the update rule for the state estimator in closed form. This is because the state estimator will depend on the transmission strategy. However, the problem of choosing the best transmission strategy is <em>separate</em> from that of choosing the control strategy. We have shown that for any given transmission strategy <span class="math inline">\(\tilde f\)</span>, if we choose the best response strategy at the controller, the performance is given by <span class="math display">\[\begin{align}
 J^*(\tilde f) &amp;= 
      \EXP\Bigl[ \sum_{t=1}^{T-1} (L_t \tilde x_t)^\TRANS
      [R_t + B_t^\TRANS S_{t+1} B_t](L_t \tilde x_t) \Bigr] \notag \\
    &amp; \quad + 
    \EXP\bigg[ x_1^\TRANS S_1 x_t + \sum_{t=1}^{T-1} w_t S_{t+1} w_t \bigg], 
\end{align}\]</span> where <span class="math inline">\(\tilde x_t = x^s_t - \EXP[ x^s_t | I^{u,s}_t]\)</span>. Note that the second term of the above expression depends only on the primitive random variable. Thus, to find the optimal transmission strategy, we need to minimize the first term, which is a purely communication/estimation problem known as remote state estimation in the literature. The optimal solution to the remote state estimation problem for the case of scalar state is derived in <span class="citation" data-cites="Lipsa2009">@Lipsa2009</span> and <span class="citation" data-cites="Chakravorty2020">@Chakravorty2020</span> (using basic proof idea developed in <span class="citation" data-cites="Lipsa2011">@Lipsa2011</span>).</p>
<h1 class="unnumbered" id="references">References</h1>


<p class="categories">
This entry 

 was last updated on 19 Oct 2020
 and posted in 

<a href="https://adityam.github.io/stochastic-control/categories/ncs">
  NCS</a>
and tagged
<a href="https://adityam.github.io/stochastic-control/tags/linear-systems">linear systems</a>,
<a href="https://adityam.github.io/stochastic-control/tags/riccati-equation">riccati equation</a>,
<a href="https://adityam.github.io/stochastic-control/tags/lqr">lqr</a>,
<a href="https://adityam.github.io/stochastic-control/tags/communication">communication</a>.</p>



    </div>
  </body>
</html>


