<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<head>
  <meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="author" content="Aditya Mahajan" />
  <meta name="title" content="ECSE 506: Stochastic Control and Decision Theory" />
  <title>ECSE 506: Stochastic Control and Decision Theory</title>
  
  <meta content="Linear systems,Output feedback,Riccati equation,LQR,LQG" name="keywords" />
  

  <link rel="stylesheet" href="https://adityam.github.io/stochastic-control//css/style.css" type="text/css" /><script type="text/javascript"
    src="https://adityam.github.io/stochastic-control/js/mathjax-local.js" defer>
  </script>
  <script type="text/javascript" id="MathJax-script" defer
    src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-svg.js">
  </script>

  <script type="module" defer
    src="//instant.page/3.0.0"
    integrity="sha384-OeDn4XE77tdHo8pGtE1apMPmAipjoxUQ++eeJa6EtJCfHlvijigWiJpD7VDPWXV1">
  </script>

  <script>var clicky_site_ids = clicky_site_ids || []; clicky_site_ids.push(101261731);</script>
  <script async src="//static.getclicky.com/js"></script>

</head>
<body>
<div id="content">
<div class="title">
  <h1>ECSE 506: Stochastic Control and Decision Theory </h1>
  <h2><a href="http://www.cim.mcgill.ca/~adityam/">Aditya Mahajan</a> <br/>
      Winter 2022
  </h2>
  <h3><a href="https://adityam.github.io/stochastic-control/ ">About</a>
	&nbsp;<small><small>|</small></small>&nbsp;
    <a href="https://adityam.github.io/stochastic-control//lectures">Lectures</a></span>
	&nbsp;<small><small>|</small></small>&nbsp;
    <a href="https://adityam.github.io/stochastic-control//notes">Notes</a></span>
	&nbsp;<small><small>|</small></small>&nbsp;
    <a href="https://adityam.github.io/stochastic-control//coursework">Coursework</a>
</h3>
</div>



<div class="h1-title">Partially observed linear quadratic regulator</div>

<p>Consider a stochastic linear system as in the case of <a href="../lqr">LQR</a>. The system has state <span class="math inline">\(x_t \in \reals^n\)</span> and actions <span class="math inline">\(u_t \in \reals^m\)</span>. The initial state <span class="math inline">\(x_1\)</span> has zero mean and finite variance <span class="math inline">\(\Sigma^x_1\)</span>. The system dynamics are given by <span class="math display">\[ x_{t+1} = A_t x_t + B_t u_t + w_t, \]</span> where <span class="math inline">\(A_t \in \reals^{n×n}\)</span> and <span class="math inline">\(B_t \in \reals^{n×m}\)</span> are known matrices and <span class="math inline">\(\{w_t\}_{t \ge 1}\)</span> is <span class="math inline">\(\reals^n\)</span>-valued i.i.d. noise process with zero mean and finite variance <span class="math inline">\(\Sigma^w\)</span>. We make the standard assumption that the primitive random variables <span class="math inline">\(\{x_1, w_1, \dots, w_T\}\)</span> are independent.</p>
<p>Now unlike the <a href="../lqr">LQR</a> model, the controller does not have perfect observation of the state, rather observes the state with noise. In particular, the observation <span class="math inline">\(y_t \in \reals^{p}\)</span> is given by <span class="math display">\[ y_t = C_t x_t + v_t, \]</span> where <span class="math inline">\(C_t \in \reals^{p×n}\)</span> is a known matrix and <span class="math inline">\(\{v_t\}_{t \ge 1}\)</span> is <span class="math inline">\(\reals^p\)</span>-valued i.i.d. noise process with zero mean and finite variance <span class="math inline">\(\Sigma^v\)</span>. We assume that <span class="math inline">\(\{v_t\}_{t \ge 1}\)</span> is independent of <span class="math inline">\(\{x_1, w_1, \dots, w_T\}\)</span>.</p>
<p>The controller generates the control action <span class="math inline">\(u_t\)</span> using all the information <span class="math inline">\(I_t = \{y_{1:t}, u_{1:t-1}\}\)</span> available to it at time <span class="math inline">\(t\)</span>. Thus, <span class="math display">\[ u_t = g_t(I_t), \]</span> where <span class="math inline">\(g = (g_1, \dots, g_{T-1})\)</span> is called a control strategy. We consider the optimal regulation problem where the objective is to minimize the finite horizon cost given by <span class="math display">\[\begin{equation} \label{eq:cost}
  J(g) = \EXP^{g} \Bigl[ \sum_{t=1}^{T-1} \bigl[ x_t^\TRANS Q_t x_t + u_t^\TRANS
  R_t u_t \bigr] + x_T^\TRANS Q_T x_T \Bigr],
\end{equation} \]</span> where <span class="math inline">\(\{Q_t\}_{t=1}^T\)</span> are <a href="../../appendix/positive-definite-matrix">positive semi-definite matrices</a> and <span class="math inline">\(\{R_t\}_{t=1}^{T-1}\)</span> are <a href="../../appendix/positive-definite-matrix">positive definite matrices</a>.</p>
<p>Given the system dynamics and the noise statistics, we are interested in choosing a control strategy <span class="math inline">\(g\)</span> to minimize the total expected cost <span class="math inline">\(J(g)\)</span> given by \eqref{eq:cost}.</p>
<dl>
<dt>Remark</dt>
<dd><p>In the standard textbook treatment of this material, it is assumed that the process noise <span class="math inline">\(\{w_t\}_{t \ge 1}\)</span> and the observation noise <span class="math inline">\(\{v_t\}_{t \ge 1}\)</span> are Gaussian. We do not make this assumption.</p>
<p>It can be shown that when the noise is Gaussian, the belief state is also Gaussian and one can work with the conditional mean as an information state leading to a simpler dynamic program.</p>
</dd>
</dl>
<p>In this section, we will follow the completion of squares based approach introduced in <a href="../lqr">the notes on LQR</a>.</p>
<h1 data-number="1" id="completion-of-squares-argument"><span class="header-section-number">1</span> Completion of squares argument</h1>
<p>Using Prop. 1 of <a href="../lqr">LQR</a>, the total cost of any strategy <span class="math inline">\(g\)</span> may be written as follows: <span class="math display">\[ \begin{align}
    J(g) = &amp; \EXP\bigg[ \sum_{t=1}^{T-1} (u_t + L_t x_t)^\TRANS [R_t + B_t^\TRANS
    S_{t+1}B_t] (u_t + L_t x_t) \bigg] \nonumber \\
    &amp; \quad + 
    \EXP\bigg[ x_1^\TRANS S_1 x_t + \sum_{t=1}^{T-1} w_t S_{t+1} w_t \bigg], \label{eq:astrom}
\end{align}\]</span> where the <em>gain matrices</em> <span class="math inline">\(\{L_t\}_{t\ge 1}\)</span> are given by: <span class="math display">\[ L_t = [R_t + B_t^\TRANS S_{t+1} B_t]^{-1} \Lambda_t \]</span> where <span class="math display">\[ \Lambda_t = B_t^\TRANS S_{t+1} A_t \]</span> and <span class="math inline">\(\{S_t\}_{t=1}^T\)</span> are determined by the solution of the <em>backward Riccati equation</em>: <span class="math inline">\(S_T = Q_T\)</span> and for <span class="math inline">\(t \in \{T-1, \dots, 1\}\)</span>: <span class="math display">\[\begin{equation}\label{eq:riccati}
  S_t = A_t^\TRANS S_{t+1} A_t + Q_t - 
  \Lambda_t^\TRANS [ R_t + B_t^\TRANS S_{t+1} B_t ] ^{-1} \Lambda_t.
\end{equation}\]</span></p>
<dl>
<dt>Remark</dt>
<dd><p>The matrices <span class="math inline">\(\{L_t\}_{t=1}^T\)</span> and <span class="math inline">\(\{S_t\}_{t=1}^T\)</span> are the same as in the basic LQR model.</p>
</dd>
</dl>
<p>Now, as in the solution to the LQR problem, we note that the second term of \eqref{eq:astrom} is a function of the primitive random variables and does not depend on the choice of the control strategy <span class="math inline">\(g\)</span>. Thus, in order to minimize the total expected cost, it suffices to minimize the first term of \eqref{eq:astrom}. However, unlike the case in LQR with perfect state observation, we cannot simply choose <span class="math inline">\(u_t = -L_t x_t\)</span> because the state <span class="math inline">\(x_t\)</span> is not known to the observer. In the next section, we use state splitting and orthogonal projection to minimize the first term of \eqref{eq:astrom}.</p>
<h1 data-number="2" id="state-splitting-and-static-reduction"><span class="header-section-number">2</span> State splitting and static reduction</h1>
<p>We split the state <span class="math inline">\(x_t\)</span> into two components: <span class="math inline">\(x_t = x^g_t + x^s_t\)</span>, where <span class="math display">\[\begin{align*}
  x^g_1 &amp;=0, &amp; x^s_1 &amp;= x_1, \\
  x^g_{t+1} &amp;= A_t x^g_t + B_t u_t, &amp;
  x^s_{t+1} &amp;= A_t x^s_t + w_t.
\end{align*}\]</span> We refer to <span class="math inline">\(x^g_t\)</span> and <span class="math inline">\(x^s_t\)</span> as the controlled and control-free components of the state, respectively. Now, define controlled and control-free components <span class="math inline">\((y^g_t, y^s_t)\)</span> of the observation as follows: <span class="math display">\[y^g_t = C_t x^g_t
\quad\text{and}\quad
y^s_t = C_t x^s_t + v_t. \]</span></p>
<p>Define <span class="math inline">\(I^s_t = \{y^s_{1:t}\}\)</span>.</p>
<div class="highlight">
<dl>
<dt><span id="lemma:1"></span><span id="lemma:static" class="pandoc-numbering-text lemma"><strong>Lemma 1</strong></span></dt>
<dd><p><strong>(Static reduction)</strong> For any control strategy <span class="math inline">\(g\)</span>, the information sets <span class="math inline">\(I_t\)</span> and <span class="math inline">\(I^s_t\)</span> generate the same sigma algebra. Equivalently, <span class="math inline">\(I_t\)</span> and <span class="math inline">\(I^s_t\)</span> are functions of each other.</p>
</dd>
</dl>
</div>
<h4 class="unnumbered" id="proof">Proof</h4>
<p>We use the notation <span class="math inline">\(a \rightsquigarrow b\)</span> to denote that <span class="math inline">\(b\)</span> is a function of <span class="math inline">\(a\)</span>. We first show that <span class="math inline">\(I_t \rightsquigarrow I^s_t\)</span>.</p>
<p>Note that</p>
<ul>
<li><span class="math inline">\(I_t \rightsquigarrow u_{1:t} \rightsquigarrow x^g_{1:t} \rightsquigarrow y^g_{1:t}\)</span></li>
<li><span class="math inline">\(I_t \rightsquigarrow y_{1:t}\)</span>.</li>
<li>Combinining these two, we have <span class="math inline">\(I_t \rightsquigarrow y_{1:t} - y^g_{1:t} = y^s_{1:t} = I^s_{1:t}\)</span>.</li>
</ul>
<p>Thus, <span class="math inline">\(I_t \rightsquigarrow I^s_t\)</span>.</p>
<p>Now, we prove the other direction that <span class="math inline">\(I^s_t \rightsquigarrow I_t\)</span> by induction.</p>
<ul>
<li>Since <span class="math inline">\(x^g_1 = 0\)</span>, we have <span class="math inline">\(y^g_1 = 0\)</span>. Thus, <span class="math inline">\(y_t = y^s_t\)</span>. Hence <span class="math inline">\(I^s_1 \rightsquigarrow I_t\)</span>.</li>
<li>Let’s assume that <span class="math inline">\(I^s_t \rightsquigarrow I_t\)</span>.</li>
<li><span class="math inline">\(I_t \rightsquigarrow u_{1:t} \rightsquigarrow x^g_{1:t+1} \rightsquigarrow y^g_{1:t+1}\)</span>.</li>
<li>Therefore, by the induction assumption, <span class="math inline">\(I^s_t \rightsquigarrow I_t \rightsquigarrow y^g_{1:t+1}\)</span>.</li>
<li>By definition, <span class="math inline">\(I^s_{t+1} \rightsquigarrow y^s_{1:t+1}\)</span>.</li>
<li>Combining the previous two, we have <span class="math inline">\(I^s_{t+1} \rightsquigarrow y^g_{t+1} + y^s_{t+1} = y_{t+1}\)</span>. We have already shown that <span class="math inline">\(I^s_t \rightsquigarrow u_t\)</span>. Thus, <span class="math inline">\(I^s_t \rightsquigarrow (I_t, y_{t+1}, u_t) = I_{t+1}\)</span>.</li>
</ul>
<p>Thus, <span class="math inline">\(I^s_t \rightsquigarrow I_t\)</span>. <span class="math inline">\(\Box\)</span></p>
<p>An implication of <a href="#lemma:static" title="Lemma 1"><span class="pandoc-numbering-link lemma">Lemma 1</span></a> is that we can replace conditioning on <span class="math inline">\(I_t\)</span> by conditioning on <span class="math inline">\(I^s_t\)</span> in any conditional probability expression.</p>
<h1 data-number="3" id="orthogonal-projection"><span class="header-section-number">3</span> Orthogonal projection</h1>
<p>To simplify the first term of \eqref{eq:astrom}, define <span class="math display">\[ \hat x_t = \EXP[ x_t | I_t ]\]</span> as the conditional estimate of the state given the observations at the controller and define <span class="math display">\[ \tilde x_t = x_t - \hat x_t\]</span> as the corresponding estimation error.</p>
<p>Then, these have the following properties.</p>
<div class="highlight">
<dl>
<dt><span id="lemma:2"></span><span id="lemma:properties" class="pandoc-numbering-text lemma"><strong>Lemma 2</strong></span></dt>
<dd><p>For any control strategy <span class="math inline">\(g\)</span>, we have</p>
<ol type="1">
<li><span class="math inline">\(\tilde x_t = x^s_t - \EXP[x^s_t | I^s_t]\)</span> is control-free and may be written just in terms of the primitive random variables.</li>
</ol>
<p>Furthermore, for any matrix <span class="math inline">\(M\)</span> of appropriate dimensions:</p>
<ol start="2" type="1">
<li><span class="math inline">\(\EXP[\hat x_t^\TRANS M \tilde x_t ] = 0\)</span>.</li>
<li><span class="math inline">\(\EXP[ u_t^\TRANS M \tilde x_t ] = 0\)</span>.</li>
</ol>
</dd>
</dl>
</div>
<h4 class="unnumbered" id="proof-1">Proof</h4>
<p>To prove part 1, we note that <span class="math display">\[\begin{align}
  \tilde x_t &amp;= x_t - \EXP[x_t | I_t ] \notag \\
  &amp;\stackrel{(a)}= x^g_t + x^s_t - \EXP[ x^g_t + x^s_t | I_t] \notag \\
  &amp;\stackrel{(b)}= x^s_t - \EXP[x^s_t | I_t ] \notag \\
  &amp;\stackrel{(c)}= x^s_t - \EXP[x^s_t | I^s_t ] \label{eq:tilde-x}
\end{align}\]</span> where <span class="math inline">\((a)\)</span> follows from state splitting, <span class="math inline">\((b)\)</span> follows from the fact that <span class="math inline">\(x^g_t\)</span> is a function of <span class="math inline">\(u_{1:t-1}\)</span> which is a part of <span class="math inline">\(I_t\)</span>, and <span class="math inline">\((c)\)</span> follows from <a href="#lemma:static" title="Lemma 1"><span class="pandoc-numbering-link lemma">Lemma 1</span></a>. Part 1 then follows by observing that \eqref{eq:tilde-x} depends only on primitive random variables.</p>
<p>To prove parts 2 and 3, let <span class="math inline">\(ξ_t\)</span> be a function of <span class="math inline">\(I_t\)</span> and <span class="math inline">\(M\)</span> be a matrix of appropriate dimensions. Then, <span class="math display">\[\begin{align}
  \EXP[ξ_t^\TRANS M \tilde x_t] 
  &amp;\stackrel{(d)}= \EXP[ \EXP[ ξ_t^\TRANS M \tilde x_t | I_t ] ] 
  \notag \\
  &amp;\stackrel{(e)}= \EXP[ ξ_t^\TRANS M \EXP[ \tilde x_t | I_t ] ] \notag \\
  &amp;\stackrel{(f)}= 0.
\end{align}\]</span> where <span class="math inline">\((d)\)</span> follows from the smoothing property of conditional expectation, <span class="math inline">\((e)\)</span> follows from the fact that <span class="math inline">\(ξ_t\)</span> is a function of <span class="math inline">\(I_t\)</span>, and <span class="math inline">\((f)\)</span> follows from the fact that <span class="math inline">\(\EXP[\tilde x_t | I_t] = 0\)</span> by construction.</p>
<p>Part 2 follows from observing that <span class="math inline">\(\hat x_t\)</span> is a function of <span class="math inline">\(I_t\)</span>. Part 3 follows from observing that <span class="math inline">\(u_t\)</span> is a function of <span class="math inline">\(I_t\)</span>. <span class="math inline">\(\Box\)</span></p>
<div class="highlight">
<dl>
<dt><span id="lemma:3"></span><span id="lemma:simplify" class="pandoc-numbering-text lemma"><strong>Lemma 3</strong></span></dt>
<dd><p>For any control strategy <span class="math inline">\(g\)</span>, the first term of \eqref{eq:astrom} may be written as <span class="math display">\[\begin{align}
  &amp; \EXP^{g}\Bigl[ \sum_{t=1}^{T-1} (u_t + L_t \hat x_t)^\TRANS
  [R_t + B_t^\TRANS S_{t+1} B_t](u_t + L_t \hat x_t) ] \notag \\
  &amp;\quad + 
  \EXP\Bigl[ \sum_{t=1}^{T-1} (L_t \tilde x_t)^\TRANS
  [R_t + B_t^\TRANS S_{t+1} B_t](L_t \tilde x_t) ] \label{eq:simple}
\end{align}\]</span></p>
</dd>
</dl>
</div>
<h4 class="unnumbered" id="proof-2">Proof</h4>
<p><a href="#lemma:properties" title="Lemma 2"><span class="pandoc-numbering-link lemma">Lemma 2</span></a> implies that for any matrix <span class="math inline">\(M\)</span> of appropriate dimensions, <span class="math display">\[ \EXP[ (u_t + L_t x_t)^\TRANS M (u_t + L_t x_t) =
\EXP[ (u_t + L_t \hat x_t)^\TRANS M (u_t + L_t \hat x_t) ] +
\EXP[ (L_t \tilde x_t)^\TRANS M (L_t \tilde x_t) ], \]</span> where the cross-terms are zero due to parts 2 and 3 of <a href="#lemma:properties" title="Lemma 2"><span class="pandoc-numbering-link lemma">Lemma 2</span></a>. The result of the Lemma follows by repeatedly using the above property at each time step.</p>
<h1 data-number="4" id="main-result"><span class="header-section-number">4</span> Main Result</h1>
<div class="highlight">
<dl>
<dt><span id="theorem:1"></span><span id="theorem:main" class="pandoc-numbering-text theorem"><strong>Theorem 1</strong></span></dt>
<dd><p>The optimal control strategy for the networked control system discussed in this section is given by <span class="math display">\[\begin{equation} \label{eq:optimal}
  u_t = - L_t \hat x_t.
\end{equation}\]</span></p>
<p>Furthermore, the state estimate <span class="math inline">\(\hat x_t\)</span> is the mean of the conditional density <span class="math inline">\(p(x_t | I_t)\)</span>, which can be updated using the standard non-linear filtering equation:</p>
<p><strong>TODO</strong>: Write the filtering equation.</p>
</dd>
</dl>
</div>
<h4 class="unnumbered" id="proof-3">Proof</h4>
<p>The proof of the structure of the optimal controller follows by combining various properties described above. In particular, we have shown that for any any control strategy <span class="math inline">\(g\)</span>, the total cost can be written as \eqref{eq:astrom}, where the second term depends just on the primitive random variables. Moreover, the first term of \eqref{eq:astrom} can be written as \eqref{eq:simple}, where (by <a href="#lemma:properties" title="Lemma 2"><span class="pandoc-numbering-link lemma">Lemma 2</span></a>, part 1) the second term is control free and depends just on the primitive random variables. Therefore, it suffices to minimize the first term of \eqref{eq:simple} to minimizing <span class="math inline">\(J(g)\)</span>. By assumption, <span class="math inline">\(S_T = Q_T\)</span> is positive semi-definite. It can be recursively shown that <span class="math inline">\(S_t\)</span> is also positive definite. Therefore, the first term of \eqref{eq:simple} is greater than or equal to zero, with equality if and only if the strategy is given by \eqref{eq:optimal}. Since the policy \eqref{eq:optimal} achieves the minimal value of the cost, it is optimal.</p>
<p>TODO: Proof of the filtering equation.</p>
<hr />
<h1 data-number="5" id="an-alternative-proof"><span class="header-section-number">5</span> An alternative proof</h1>
<p>In this section, we present an alternative proof that does not use orthogonal projection. We do a change of variables and define <span class="math display">\[ u^s_t = u_t - L_t x^g_t. \]</span></p>
<p>Since the controller can compute <span class="math inline">\(x^g_t\)</span>, we may assume that the controller chooses <span class="math inline">\(u^s_t\)</span> instead of <span class="math inline">\(u_t\)</span>. With this change of variables, the first term of \eqref{eq:cost} becomes</p>
<p><span class="math display">\[ \EXP\Bigl[ \sum_{t=1}^{T-1}(u^s_t + L_t x^s_t)^\TRANS [ R_t + B_t^\TRANS S_{t+1}
B_t] (u^s_t + L_t x^s_t) \Bigr]. \]</span></p>
<p>Note that the optimization objective simply depends on primitive random variables. Furthermore, using <a href="#lemma:static" title="Lemma 1"><span class="pandoc-numbering-link lemma">Lemma 1</span></a>, we can assert that the decision <span class="math inline">\(u^s_t\)</span> is based on <span class="math inline">\(I^s_t\)</span> rather than <span class="math inline">\(I_t\)</span>, i.e., <span class="math display">\[ u^s_t = g^s_t(I^s_t). \]</span></p>
<p>Thus, we get the following optimization problem:</p>
<p><span class="math display">\[ \min_{g^s}
  \EXP\Bigl[ \sum_{t=1}^{T-1}(u^s_t + L_t x^s_t)^\TRANS [ R_t + B_t^\TRANS S_{t+1}
B_t] (u^s_t + L_t x^s_t) \Bigr]. \]</span></p>
<p>This is a purely estimation problem, which can be solved separately. Using standard results from optimal filtering, we know that the optimal solution of this estimation problem is given by <span class="math display">\[ u^s_t = \EXP[ x^s_t | I^s_t]. \]</span></p>
<!-- Maybe add the notes on the best linear strategy -->
<h1 class="unnumbered" id="references">References</h1>
<p>The separation of estimation and control for Guassian noise was first established by <span class="citation" data-cites="Joseph1961">Joseph and Tou (<a href="#ref-Joseph1961" role="doc-biblioref">1961</a>)</span>. The proof using state splitting and static reduction is based on <span class="citation" data-cites="Wonham1968">Wonham (<a href="#ref-Wonham1968" role="doc-biblioref">1968</a>)</span>. The alternate proof using change of variables is based on discussions with Mohammad Afshari.</p>
<div id="refs" class="references csl-bib-body hanging-indent" role="doc-bibliography">
<div id="ref-Joseph1961" class="csl-entry" role="doc-biblioentry">
<span class="smallcaps">Joseph, D.P. and Tou, T.J.</span> 1961. On linear control theory. <em>Transactions of the American Institute of Electrical Engineers, Part <span>II</span>: Applications and Industry</em> <em>80</em>, 4, 193–196. DOI: <a href="https://doi.org/10.1109/tai.1961.6371743">10.1109/tai.1961.6371743</a>.
</div>
<div id="ref-Wonham1968" class="csl-entry" role="doc-biblioentry">
<span class="smallcaps">Wonham, W.M.</span> 1968. On the separation theorem of stochastic control. <em><span>SIAM</span> Journal on Control</em> <em>6</em>, 2, 312–326. DOI: <a href="https://doi.org/10.1137/0306023">10.1137/0306023</a>.
</div>
</div>


<p class="categories">
This entry 

 was last updated on 02 Mar 2021
 and posted in 

<a href="https://adityam.github.io/stochastic-control/categories/pomdp">
  POMDP</a>
and tagged
<a href="https://adityam.github.io/stochastic-control/tags/linear-systems">linear systems</a>,
<a href="https://adityam.github.io/stochastic-control/tags/output-feedback">output feedback</a>,
<a href="https://adityam.github.io/stochastic-control/tags/riccati-equation">riccati equation</a>,
<a href="https://adityam.github.io/stochastic-control/tags/lqr">lqr</a>,
<a href="https://adityam.github.io/stochastic-control/tags/lqg">lqg</a>.</p>



    </div>
  </body>
</html>


