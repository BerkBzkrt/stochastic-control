<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Solutions on ECSE 506: Stochastic Control and Decision Theory</title>
    <link>https://adityam.github.io/stochastic-control/solutions/</link>
    <description>Recent content in Solutions on ECSE 506: Stochastic Control and Decision Theory</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    
	<atom:link href="https://adityam.github.io/stochastic-control/solutions/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title></title>
      <link>https://adityam.github.io/stochastic-control/solutions/03-1/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://adityam.github.io/stochastic-control/solutions/03-1/</guid>
      <description></description>
    </item>
    
    <item>
      <title></title>
      <link>https://adityam.github.io/stochastic-control/solutions/05-2/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://adityam.github.io/stochastic-control/solutions/05-2/</guid>
      <description></description>
    </item>
    
    <item>
      <title></title>
      <link>https://adityam.github.io/stochastic-control/solutions/06-2/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://adityam.github.io/stochastic-control/solutions/06-2/</guid>
      <description></description>
    </item>
    
    <item>
      <title></title>
      <link>https://adityam.github.io/stochastic-control/solutions/07-1/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://adityam.github.io/stochastic-control/solutions/07-1/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Assignment 1 (solution)</title>
      <link>https://adityam.github.io/stochastic-control/solutions/01/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://adityam.github.io/stochastic-control/solutions/01/</guid>
      <description>Problem 1 We first observe a simplification that can be done for this model, which makes the calculations a little easier. In principle, we need to compute \[ Q(x,u) = \EXP[ c(x,u,W) | X = x] = \sum_{w \in \ALPHABET W} P(W = w | X = x) c(x,u,w). \]
This means that we need to compute \(P(W|X)\). However, we can avoid that step by observing that \[P(W|X) = \dfrac{ P(X,W) }{ P(X) }.</description>
    </item>
    
    <item>
      <title>Assignment 2 (solution)</title>
      <link>https://adityam.github.io/stochastic-control/solutions/02/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://adityam.github.io/stochastic-control/solutions/02/</guid>
      <description>Problem 1 The result follows by writing the maximization in a nested manner \[\begin{align*} V_t(a) &amp;amp;= \max_{(u_1, \dots u_t) \ge 0 : \sum_{i=1}^t u_i = a} u_1 \cdots u_t \\ &amp;amp;= \max_{u_t \in [0,a]} \Bigl\{ \max_{(u_1, \dots, u_{t-1}) \ge 0 : \sum_{i=1}^{t-1} u_i = a-u_t} u_1 \cdots u_{t-1} \Bigr\} \cdot u_t \\ &amp;amp; = \max_{u_t \in [0,a]} V_t(a-u_t) \cdot u_t \end{align*}\]
 We use induction to show that \(V_t(a) = (a/t)^t\).</description>
    </item>
    
    <item>
      <title>Assignment 3 (solution)</title>
      <link>https://adityam.github.io/stochastic-control/solutions/03/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://adityam.github.io/stochastic-control/solutions/03/</guid>
      <description>Problem 1 The code for computing the optimal policy is available here. The code is written for ease of reading, not efficiency.
# State spaces n, m = 8, 3 X = 1:n+1 U = 1:m+1 # Transition probability q = 0.6 p = [0.0,0.25,0.5,0.8] P = [ zeros(n+1,n+1) for u in U ] # We are using 1-indexed arrays, so need to be careful with the indices for u in U @views Pu = P[u] for x in X if x == 1 Pu[x,x] = 1 - q Pu[x,x+1] = q elseif x == n+1 Pu[x,x-1] = (1-q)*p[u] Pu[x,x ] = 1 - (1-q)*p[u] else Pu[x,x-1] = (1-q)*p[u] Pu[x,x ] = (1-q)*(1-p[u]) + q*p[u] Pu[x,x+1] = q*(1-p[u]) end end end P_concat = vcat(P.</description>
    </item>
    
    <item>
      <title>Assignment 4 (solution)</title>
      <link>https://adityam.github.io/stochastic-control/solutions/04/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://adityam.github.io/stochastic-control/solutions/04/</guid>
      <description>Problem 1 This is an optimal stopping problem. Let \(X_t\) denote the population at time \(t\) and \(U_t \in \{0,1\}\) deote the decision to stop (\(U_t = 0\)) or not (\(U_t = 1\)). If the hunter has not made a stopping decision, the dynamics of \(\{X_t\}_{t \ge 1}\) are given by \[ X_{t+1} = \begin{cases} X_t, &amp;amp; \text{with probability $1 - p(X_t)$} \\ X_t - 1, &amp;amp; \text{with probability $p(X_t)$} \end{cases} \]</description>
    </item>
    
    <item>
      <title>Assignment 5 (solution)</title>
      <link>https://adityam.github.io/stochastic-control/solutions/05/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://adityam.github.io/stochastic-control/solutions/05/</guid>
      <description>Problem 1 For the reward maximization case, the dynamic program is given as follows:
\[V_T(x) = s_T(x)\] and for \(t \in \{T-1,\dots, 1\}\), we have \[V_t(x) = \max\{ s_t(x), c_t(x) + \EXP[V_{t+1}(X_{t+1} | X_t = x]. \]
We define the benefit funciton as before. i.e., \[B_t(x) = c_t(x) + \EXP[ V_{t+1}(X_{t+1}) | X_t = x] - s_t(x). \] Then, it is optimal to stop whenever \(B_t(x) \le 0\).
Now, we write the value function in terms of the benefit function as follows:</description>
    </item>
    
    <item>
      <title>Assignment 7 (solution)</title>
      <link>https://adityam.github.io/stochastic-control/solutions/07/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://adityam.github.io/stochastic-control/solutions/07/</guid>
      <description>Part a. Let \(Y_t \in \{0, 1\}\) denote the observation of the player where \(Y_t = 0\) means that the output was a failure and \(Y_t = 1\) means that the output was a success. Let \(I_t = \{Y_{1:t-1}, U_{1:t-1} \}\) denote all the information available to the player.
From the definition of \((M_t, N_t)\), the evolution of \((M_t, N_t)\) can be written as \[ (M_{t+1}, N_{t+1}) = \begin{cases} (M_t, N_t), &amp;amp; U_t = A \\ (M_t + 1, N_t), &amp;amp; U_t = B, Y_t = 1 \\ (M_t , N_t + 1), &amp;amp; U_t = B, Y_t = 0 \end{cases}\]</description>
    </item>
    
  </channel>
</rss>