<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<head>
  <meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="author" content="Aditya Mahajan" />
  <meta name="title" content="ECSE 506: Stochastic Control and Decision Theory" />
  <title>ECSE 506: Stochastic Control and Decision Theory</title>
  
  <meta content="inventory management,post-decision state,base-stock policy,structural results" name="keywords" />
  

  <link rel="stylesheet" href="https://adityam.github.io/stochastic-control//css/style.css" type="text/css" /><script type="text/javascript"
    src="https://cdn.plot.ly/plotly-basic-latest.min.js">
  </script><script type="text/javascript"
          src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/MathJax.js?config=TeX-AMS-MML_SVG,https://adityam.github.io/stochastic-control/js/mathjax-local.js">
  </script>
</head>
<body>
<div id="content">
<div class="title">
  <h1>ECSE 506: Stochastic Control and Decision Theory </h1>
  <h2><a href="http://www.cim.mcgill.ca/~adityam/">Aditya Mahajan</a> <br/>
      Winter 2020
  </h2>
  <h3><a href="https://adityam.github.io/stochastic-control/ ">About</a>
	&nbsp;<small><small>|</small></small>&nbsp;
    <a href="https://adityam.github.io/stochastic-control//lectures">Lectures</a></span>
	&nbsp;<small><small>|</small></small>&nbsp;
    <a href="https://adityam.github.io/stochastic-control//notes">Notes</a></span>
	&nbsp;<small><small>|</small></small>&nbsp;
    <a href="https://adityam.github.io/stochastic-control//coursework">Coursework</a>
</h3>
</div>



<h1>Example: Inventory Management</h1>

<figure>
<img src="/stochastic-control/banners/inventory.jpg" title="How to manage inventory" alt="Image credit: https://hbr.org/2015/06/inventory-management-in-the-age-of-big-data" style="width:100.0%" /><figcaption>Image credit: https://hbr.org/2015/06/inventory-management-in-the-age-of-big-data</figcaption>
</figure>
<p>TL;DR <em>The inventory management example illustrates that a dynamic programming formulation is useful even when a closed form solution does not exist. This model also introduces the idea of <em>post-decision state</em>, which is useful in many contexts.</em></p>
<hr />
<p>Imagine a retail store that stockpiles products in its warehouse to meet random demand. Suppose the store procures new stocks at the end of each day (and that there is no lead time and stocks are available next morning). Let</p>
<ul>
<li><span class="math inline">\(X_t\)</span> denote the amount of stock at the beginning of day <span class="math inline">\(t\)</span>,</li>
<li><span class="math inline">\(U_t\)</span> denote the stock ordered (and immediately delivered) at the beginning of day <span class="math inline">\(t\)</span>, and</li>
<li><span class="math inline">\(W_t\)</span> denote the demand during day <span class="math inline">\(t\)</span>.</li>
</ul>
<p>The random variables <span class="math inline">\(\{W_t\}_{t \ge 1}\)</span> are i.i.d. with known probability distribution.</p>
<p>Excess demand is backlogged and filled when new inventory becomes available. Thus, the stock evolves according to <span class="math display">\[X_{t+1} = X_t + U_t - W_t,\]</span> where negative stock denotes backlogged demand.</p>
<p>The cost incurred during day <span class="math inline">\(t\)</span> consists of two components:</p>
<ul>
<li>A procurement cost of <span class="math inline">\(p\, U_t\)</span>, where <span class="math inline">\(p\)</span> is the cost per unit.</li>
<li><p>At the end of the day, if the stock <span class="math inline">\(X_{t+1}\)</span> is positive, then there is a holding cost of <span class="math inline">\(a X_{t+1}\)</span> for storing excess inventory; if <span class="math inline">\(X_{t+1}\)</span> is negative, then a shortage cost of <span class="math inline">\(-bX_{t+1}\)</span> for unfilled demand.</p>
<p>We denote this cost by <span class="math inline">\(h(X_{t+1})\)</span>, where <span class="math display">\[ h(x) = \begin{cases} 
     ax, &amp; \text{if } x \ge 0 \\
    -bx, &amp; \text{if } x &lt; 0
  \end{cases}\]</span></p></li>
</ul>
<h2 id="structure-of-optimal-procurement-strategy">Structure of optimal procurement strategy</h2>
<p>The above model is a Markov decision process.<a href="#fn1" class="footnote-ref" id="fnref1"><sup>1</sup></a> Therefore, the optimal solution is given by dynamic programming.</p>
<div class="highlight">
<dl>
<dt>Dynamic programming</dt>
<dd><p>Define the following value functions <span class="math inline">\(V_t \colon \reals \to \reals\)</span> <span class="math display">\[V_{T+1}(x) = 0\]</span> and for <span class="math inline">\(t \in \{T, \dots, 1\}\)</span> <span class="math display">\[ Q_t(x, u) = p u + \EXP[ h(x + u - W_t) + V_{t+1}( x + u - W_t ) ]\]</span> and <span class="math display">\[ \begin{align*}
V_t(x) &amp;= \min_{u \in \reals_{\ge 0}} Q_t(x,u) \\
g_t(x) &amp;= \arg \min_{u \in \reals_{\ge 0}} Q_t(x,u) 
\end{align*}
  \]</span> Then the strategy <span class="math inline">\(g = (g_1, \dots, g_T)\)</span> is optimal.</p>
</dd>
</dl>
</div>
<p>It is possible to simplify the above dynamic program by exploiting a feature of the model. Notice that the dynamics can be split into two parts: <span class="math display">\[ \begin{align*}
    Y_t &amp;= X_t + U_t,  \\
    X_{t+1} &amp;= Y_t - W_t.
   \end{align*}
\]</span> The first part, <span class="math inline">\(Y_t\)</span>, depends only on the current state and action. The second part depends only on <span class="math inline">\(Y_t\)</span> and a primitive random variable. In this particular model, <span class="math inline">\(Y_t\)</span> is a deterministic function of <span class="math inline">\(X_t\)</span> and <span class="math inline">\(U_t\)</span>; but, in general, it could be stochastic as well; what is important is that the second part should only depend on <span class="math inline">\(Y_t\)</span> and a primitive random variable. The variable <span class="math inline">\(Y_t\)</span> is sometimes called the <em>post-decision state</em>.</p>
<p>Now write the dynamic program in terms of the post-decision state as follows. Define <span class="math display">\[ \bar Q(y) = \EXP[ h(y - W) + V_{t+1}(y-W) ].\]</span> Then the value function and optimal policy at time <span class="math inline">\(t\)</span> can be written as: <span class="math display">\[ \begin{align*}
  V_t(x) &amp;= \min_{u \in \reals_{\ge 0}} \bigl\{ pu + \bar Q(x + u) \bigr\}, \\
  g_t(x) &amp;= \arg \min_{u \in \reals_{\ge 0}} \bigl\{ pu + \bar Q(x + u) \bigr\}.
\end{align*} \]</span></p>
<p>The optimal policy is then characterized as follows.</p>
<div class="highlight">
<dl>
<dt>Theorem</dt>
<dd><p>Define <span class="math display">\[ S_t = \arg \min_{y \in \reals} \bigl\{ p y + \bar Q(y) \bigr\} . \]</span> Then, <span class="math display">\[\begin{equation} \label{eq:V}
V_t(x) = \begin{cases}
  \bar Q_t(S_t) + p (S_t - x), &amp;\text{if } x \le S_t \\
  \bar Q_t(x)   , &amp; \text{otherwise }
\end{cases} 
\end{equation}\]</span> and <span class="math display">\[g_t(x) = \begin{cases}
  S_t - x, &amp;\text{if } x \le S_t \\
  0, &amp; \text{otherwise }
\end{cases} \]</span></p>
<p>Furthermore, for all <span class="math inline">\(t\)</span>, <span class="math inline">\(\bar Q_t(y)\)</span> and <span class="math inline">\(V_t(x)\)</span> are convex in <span class="math inline">\(y\)</span> and <span class="math inline">\(x\)</span>, respectively.</p>
</dd>
</dl>
</div>
<h4 id="proof">Proof</h4>
<p>We first establish some preliminary results.</p>
<ol type="1">
<li><p>For any convex function <span class="math inline">\(\theta \colon \reals \to \reals\)</span>, <span class="math inline">\(\Theta(x) = \EXP[ \theta(x - W) ]\)</span> is convex.</p>
<p><strong>Proof</strong> For any realization of <span class="math inline">\(W\)</span>, <span class="math inline">\(\theta(x - w)\)</span> is convex in <span class="math inline">\(x\)</span>. The expectation w.r.t. <span class="math inline">\(W\)</span> is simply the sum of convex functions and is, therefore, convex.</p></li>
<li><p>For any convex function <span class="math inline">\(\theta \colon \reals \to \reals\)</span>, let <span class="math inline">\(s = \arg \min_{x \in \reals} \theta(x)\)</span>. Then, <span class="math display">\[\arg \min_{u \in \reals_{\ge 0}} \theta(x + u) = \begin{cases}
0, &amp; \text{if } x &gt; s, \\
s - x, &amp; \text{if } x \le s
\end{cases}\]</span> and <span class="math display">\[\Theta(x) = \min_{u \in \reals_{\ge 0}} \theta(x+u) = \begin{cases}
 \theta(x), &amp; \text{if } x &gt; s \\
 \theta(s), &amp; \text{if } x \le s
 \end{cases}\]</span> and <span class="math inline">\(\Theta(x)\)</span> is convex in <span class="math inline">\(x\)</span>.</p>
<p>If there were no constraint on <span class="math inline">\(u\)</span>, then the minimizer will be <span class="math inline">\(u = s -  x\)</span>. If <span class="math inline">\(x \le s\)</span>, then <span class="math inline">\(u = s -x \in \reals_{\ge 0}\)</span> is the minimizer for the constrained problem as well. On the other hand, if <span class="math inline">\(x \ge s\)</span>, then the function <span class="math inline">\(\theta(x + u)\)</span> is increasing as a function of <span class="math inline">\(u\)</span>. Hence, the minimizer for the constrained problem is <span class="math inline">\(u = 0\)</span>. See the figures below.</p></li>
</ol>
<div class="flex">
<div id="function:f" style="width:400px; height:250px;">

</div>
<div id="function:g" style="width:400px; height:250px;">

</div>
</div>
<script>
  var state = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10];
  var Q     = [16, 10, 6.5, 4, 3, 4, 7, 12, 19, 28];
  var Qmin  = [3,  3, 3,   3, 3, 4, 7, 12, 19, 28];

  function show_plot(dom, x, y, xtitle, ytitle) {
    var data = [{ 
        x: x,
        y: y,
        line : { 
          shape: "spline",
        },
        mode: "lines", 
    }];

    var layout = { 
        paper_bgcolor: "#fffff8",
        plot_bgcolor:  "#fffff8",
        xaxis : {
          title: xtitle,
          showgrid: true,
          showline: true,
          zeroline: false,
          showticklabels: false,
        },
        yaxis : {
          title: ytitle,
          showgrid: true,
          showline: true,
          zeroline: false,
          showticklabels: false,
          range: [-5,30],
        },
        automargin: true,
        margin: {
          l : 50,
          r : 15,
          b : 15,
          t : 15,
          pad : 15
        } ,
        hovermode: false,
    };

    var options = {
        staticPlot: true,
        displayModeBar: false,
    };

    Plotly.plot(dom, data, layout, options);
  }

  show_plot('function:f', state, Q, "$x$", "$\\theta(x)$");
  show_plot('function:g', state, Qmin, "$x$",  "$\\Theta(x) = \\displaystyle \\min_{u \\ge 0} \\theta(x+u)$");
</script>
<p>Now to prove the result, we define <span class="math display">\[ \theta_t(y) = py + \bar Q_t(y). \]</span> Then, <span class="math display">\[ V_t(x) = \min_{u \in \reals_{\ge 0}} \bigl\{ p(x + u) + \bar Q_t(x + u)
\bigr\} - p x 
= \min_{u \in \reals_{\ge 0}} \theta_t(x+u) - p x.
\]</span></p>
<p>As usual, we prove the result by backward induction. For <span class="math inline">\(t=T\)</span>, <span class="math display">\[\bar Q_T(y) = \EXP[ h(y - W) ] \]</span> which is convex because <span class="math inline">\(h(y)\)</span> is convex. <span class="math inline">\(\theta_T(y) = p y + Q_T(y)\)</span> is the sum of a linear function and convex function and is, therefore, convex. Then, by fact 2 above, <span class="math display">\[g_T(x) = \arg \min_{u \in \reals_{\ge 0}} \theta_T(x+u) = \max(S_T - x, 0)
\]</span> and <span class="math display">\[V_T(x) = \min_{u \in \reals_{\ge 0}} \theta_T(x + u) - px = 
  \begin{cases}
    \theta_T(x) - p x, &amp; \text{if } x &gt; S_T \\
    \theta_T(S_T) - px, &amp; \text{if } x \le S_T.
  \end{cases}
\]</span> Substituting <span class="math inline">\(\theta_t(y) = p y + \bar Q_t(y)\)</span>, we get that both <span class="math inline">\(V_T\)</span> and <span class="math inline">\(g_T\)</span> have the desired form and <span class="math inline">\(V_T\)</span> is convex. This forms the basis of induction.</p>
<p>Now assume that <span class="math inline">\(V_{t+1}(x)\)</span> is convex and of the form \eqref{eq:V}. Now note that, by fact 1, <span class="math display">\[ \bar Q_t(y) = \EXP[ h(y - W) + V_{t+1}(y - W) ]\]</span> is convex. Hence, <span class="math inline">\(\theta_t(y)\)</span> is convex. Therefore, by fact 2 above, <span class="math display">\[ g_t(x) = \max(S_t - x, 0)\]</span> and <span class="math inline">\(V_t(x)\)</span> is of the desired form and convex.</p>
<p>Thus, the result is holds by induction.</p>
<h2 id="references">References</h2>
<p>Inventory management models with deterministic demand were introduced by <span class="citation" data-cites="Harris1913">Harris (<a href="#ref-Harris1913">1913</a>)</span>. The mathematical model of inventory management considered here was originally proposed by <span class="citation" data-cites="Arrow1951">Arrow et al. (<a href="#ref-Arrow1951">1951</a>)</span>. The optimality of base-stock policy was established by <span class="citation" data-cites="Bellman1955">Bellman et al. (<a href="#ref-Bellman1955">1955</a>)</span>.</p>
<hr />
<div id="refs" class="references">
<div id="ref-Arrow1951">
<p><span class="smallcaps">Arrow, K.J., Harris, T., and Marschak, J.</span> 1951. Optimal inventory policy. <em>Econometrica: Journal of the Econometric Society</em>, 250–272. DOI: <a href="https://doi.org/10.2307/1907830">10.2307/1907830</a>.</p>
</div>
<div id="ref-Bellman1955">
<p><span class="smallcaps">Bellman, R., Glicksberg, I., and Gross, O.</span> 1955. On the optimal inventory equation. <em>Management Science</em> <em>2</em>, 1, 83–104. DOI: <a href="https://doi.org/10.1287/mnsc.2.1.83">10.1287/mnsc.2.1.83</a>.</p>
</div>
<div id="ref-Harris1913">
<p><span class="smallcaps">Harris, F.W.</span> 1913. How many parts to make at once. <em>The magazine of management</em> <em>10</em>, 2, 135–152. DOI: <a href="https://doi.org/10.1287/opre.38.6.947">10.1287/opre.38.6.947</a>.</p>
</div>
</div>
<section class="footnotes">
<hr />
<ol>
<li id="fn1"><p>Part of the per-step cost depends on the <em>future</em> state <span class="math inline">\(X_{t+1}\)</span>. It is easy to show that the standard MDP model works even when the per-step cost is a function of <span class="math inline">\((X_t, U_t, X_{t+1})\)</span><a href="#fnref1" class="footnote-back">↩</a></p></li>
</ol>
</section>


<p class="categories">
This entry 

 was last updated on 15 Jan 2020
 and posted in 

<a href="https://adityam.github.io/stochastic-control/categories/mdp">
  MDP</a>
and tagged
<a href="https://adityam.github.io/stochastic-control/tags/inventory-management">inventory management</a>,
<a href="https://adityam.github.io/stochastic-control/tags/post-decision-state">post-decision state</a>,
<a href="https://adityam.github.io/stochastic-control/tags/base-stock-policy">base-stock policy</a>,
<a href="https://adityam.github.io/stochastic-control/tags/structural-results">structural results</a>.</p>



      <script type="text/javascript">
      
            var _gaq = _gaq || [];
            _gaq.push(['_setAccount', 'UA-6887174-4']);
            _gaq.push(['_trackPageview']);
            (function() {
                var ga   = document.createElement('script');
                ga.type  = 'text/javascript';
                ga.async = true;
                ga.src   = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
                var s = document.getElementsByTagName('script')[0];
                s.parentNode.insertBefore(ga, s);
              })();
      
      </script>
    </div>
  </body>
</html>


