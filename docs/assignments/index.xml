<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Assignments on ECSE 506: Stochastic Control and Decision Theory</title>
    <link>https://adityam.github.io/stochastic-control/assignments/</link>
    <description>Recent content in Assignments on ECSE 506: Stochastic Control and Decision Theory</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language><atom:link href="https://adityam.github.io/stochastic-control/assignments/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Assignment 1</title>
      <link>https://adityam.github.io/stochastic-control/assignments/01/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://adityam.github.io/stochastic-control/assignments/01/</guid>
      <description>Exercise 1 from the notes on stochastic optimization. Write a computer program in any language of your choice to find the optimal policy. You must submit your code along with your solution.
 Exercise 2 from the notes on stochastic optimization. Write a computer program in any language of your choice to find the optimal policy. You must submit your code along with your solution.
 Exercise 3 from the notes on the newsvendor problem.</description>
    </item>
    
    <item>
      <title>Assignment 2</title>
      <link>https://adityam.github.io/stochastic-control/assignments/02/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://adityam.github.io/stochastic-control/assignments/02/</guid>
      <description>Inventory Management. Consider a variation of the inventory management problem considered in class. Suppose that the inventory \(S_t\) and the actions \(A_t\) takes values in the set \(\mathbb S = \{0, 1, \dots, L \}\), and the dynamics are given by \[ S_{t+1} = \bigl[ S_t + A_t - W_t \bigr]_0^L, \] where \([ s ]_{0}^L\) is a function which clips the values between \(0\) and \(L\), i.e., \[ [ s ]_0^L = \begin{cases} 0, &amp;amp; \text{if $s &amp;lt; 0$} \\ s, &amp;amp; \text{if $0 \le s \le L$} \\ L, &amp;amp; \text{if $s &amp;gt; L$}.</description>
    </item>
    
    <item>
      <title>Assignment 3</title>
      <link>https://adityam.github.io/stochastic-control/assignments/03/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://adityam.github.io/stochastic-control/assignments/03/</guid>
      <description>Service rate control in queueing systems
Consider a queueing system where \(S_t \in \{0, 1, \dots, n\}\) denotes the number of jobs in the queue at time \(t\), \(W_t \in \integers_{\ge 0}\) denotes the number of new job arrivals in time \(t\), \(Z_t \in \{0,1\}\) denotes whether the job being processed gets completed in time \(t\). The dynamics of the system are given by \[ S_{t+1} = \bigl[ [ S_t - Z_t]^{+} + W_t \bigr]^{n}_{0} \] where \([s]^{+} = \max\{s,0\}\), and \([s]_{0}^n\) is the clip function (defined in Assignment 2).</description>
    </item>
    
    <item>
      <title>Assignment 4</title>
      <link>https://adityam.github.io/stochastic-control/assignments/04/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://adityam.github.io/stochastic-control/assignments/04/</guid>
      <description>Exercise 1 of the notes on power-delay trade-off in wireless communication.
 Exercise 2 of notes on stochastic dominance.
  </description>
    </item>
    
    <item>
      <title>Assignment 5</title>
      <link>https://adityam.github.io/stochastic-control/assignments/05/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://adityam.github.io/stochastic-control/assignments/05/</guid>
      <description>Consider the infinite horizon version of the machine repair model presented in Section 3 of the notes on matrix formulation of MDPs with \(θ = 0.3\), \(λ = 8\), and \(γ = 0.9\).
Using the results on stochastic monotonicity, show that the optimal policy is weakly decreasing.
 Note that there are 4 possible weakly decreasing policies. Evaluate the performance of each of these policies using the policy evaluation formula derived in class.</description>
    </item>
    
    <item>
      <title>Assignment 6</title>
      <link>https://adityam.github.io/stochastic-control/assignments/06/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://adityam.github.io/stochastic-control/assignments/06/</guid>
      <description>Exercise 1 of the notes on discounted mdp
 Consider the infinite horizon version of the machine repair model presented in Section 3 of the notes on matrix formulation of MDPs with \(θ = 0.3\), \(λ = 8\), and \(γ = 0.9\).
  Start with an initial guess of \(V_0 = [0, 0, 0]\). Use value iteration to find a policy \(π\) such that \(\NORM{V_π - V^*} \le 10^{-6}\). How many iterations does it take to converge?</description>
    </item>
    
  </channel>
</rss>
