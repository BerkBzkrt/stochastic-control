<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<head>
  <meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="author" content="Aditya Mahajan" />
  <meta name="title" content="ECSE 506: Stochastic Control and Decision Theory" />
  <title>ECSE 506: Stochastic Control and Decision Theory</title>
  

  <link rel="stylesheet" href="https://adityam.github.io/stochastic-control//css/style.css" type="text/css" /><script type="text/javascript"
    src="https://adityam.github.io/stochastic-control/js/mathjax-local.js" defer>
  </script>
  <script type="text/javascript" id="MathJax-script" defer
    src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-svg.js">
  </script>

  <script type="module" defer
    src="//instant.page/3.0.0"
    integrity="sha384-OeDn4XE77tdHo8pGtE1apMPmAipjoxUQ++eeJa6EtJCfHlvijigWiJpD7VDPWXV1">
  </script>

  <script>var clicky_site_ids = clicky_site_ids || []; clicky_site_ids.push(101261731);</script>
  <script async src="//static.getclicky.com/js"></script>

</head>
<body>
<div id="content">
<div class="title">
  <h1>ECSE 506: Stochastic Control and Decision Theory </h1>
  <h2><a href="http://www.cim.mcgill.ca/~adityam/">Aditya Mahajan</a> <br/>
      Winter 2022
  </h2>
  <h3><a href="https://adityam.github.io/stochastic-control/ ">About</a>
	&nbsp;<small><small>|</small></small>&nbsp;
    <a href="https://adityam.github.io/stochastic-control//lectures">Lectures</a></span>
	&nbsp;<small><small>|</small></small>&nbsp;
    <a href="https://adityam.github.io/stochastic-control//notes">Notes</a></span>
	&nbsp;<small><small>|</small></small>&nbsp;
    <a href="https://adityam.github.io/stochastic-control//coursework">Coursework</a>
</h3>
</div>



<div class="h1-title">Assignment 2</div>

<ol type="1">
<li><p><strong>Inventory Management</strong>. Consider a variation of the <a href="../../mdp/inventory-management">inventory management</a> problem considered in class. Suppose that the inventory <span class="math inline">\(S_t\)</span> and the actions <span class="math inline">\(A_t\)</span> takes values in the set <span class="math inline">\(\mathbb S = \{0, 1, \dots, L \}\)</span>, and the dynamics are given by <span class="math display">\[
   S_{t+1} = \bigl[ S_t + A_t - W_t \bigr]_0^L,
\]</span> where <span class="math inline">\([ s ]_{0}^L\)</span> is a function which clips the values between <span class="math inline">\(0\)</span> and <span class="math inline">\(L\)</span>, i.e., <span class="math display">\[
   [ s ]_0^L =
   \begin{cases}
   0, &amp; \text{if $s &lt; 0$} \\
   s, &amp; \text{if $0 \le s \le L$} \\
   L, &amp; \text{if $s &gt; L$}.
   \end{cases}
\]</span> The demand <span class="math inline">\(W_t\)</span> takes values in the set <span class="math inline">\(\ALPHABET W = \{0, 1, 2\}\)</span> with probability mass function <span class="math inline">\(P_W = [ 0.1, 0.7, 0.2 ]\)</span>.</p>
<p>The per-step cost is given by <span class="math display">\[
   c_t(S_t, A_t, W_t) = (S_t + A_t - W_t)^2.
\]</span> Note that in this case, the inventoy cannot be negative but the per-step cost does take shortage into account.</p>
<p>Write the dynamic programming equation and numerically solve it for a horizon <span class="math inline">\(T = 10\)</span> and inventory level <span class="math inline">\(L = 5\)</span>. Plot the value function and the optimal policy for <span class="math inline">\(t=1\)</span> and <span class="math inline">\(t=2\)</span>.</p></li>
</ol>
<ol start="2" type="1">
<li><p><strong>Monotonicity in time</strong>. Consider the standard model of finite-horizon MDP discussed in class. Suppose that the dynamics is time homogeneous and so is the per-step cost <span class="math inline">\(c_t(\cdot)\)</span> (except, possibly at the terminal time <span class="math inline">\(t=T\)</span>). Suppose we have that <span class="math inline">\(V_{T-1}(s) \le V_T(s)\)</span> for all <span class="math inline">\(s \in \ALPHABET S\)</span>. Then, show that <span class="math display">\[ V_{t}(s) \le V_{t+1}(s), \quad
   \text{for all $s \in \ALPHABET S$ and $t$}.\]</span></p>
<p>Similarly, if we have that <span class="math inline">\(V_{T-1}(s) \ge V_T(s)\)</span> for all <span class="math inline">\(s \in \ALPHABET S\)</span>, then <span class="math display">\[ V_{t}(s) \ge V_{t+1}(s), \quad
   \text{for all $s \in \ALPHABET S$ and $t$}.\]</span></p></li>
<li><p><strong>Dynamic programming for maximizing tail probabilities.</strong> Consider a dynamical system that evolves as follows: <span class="math display">\[
  S_{t+1} = f_t(S_t, A_t, W_t)
\]</span> where <span class="math inline">\(\{S_1, W_1, \dots, W_T\}\)</span> are independent random variables and the control actions <span class="math inline">\(A_t\)</span> are chosen according to a history dependent policy <span class="math inline">\(π = (π_1, \dots, π_T)\)</span>: <span class="math display">\[
  A_t = π_t(S_{1:t}, A_{1:t-1}).
\]</span> Given a sequence of functions <span class="math inline">\(h_t \colon \ALPHABET S \mapsto \reals\)</span>, the cost of a policy <span class="math inline">\(π\)</span> is given by the probability that <span class="math inline">\(h_t(S_t)\)</span> exceeds a given threshold <span class="math inline">\(α \in \reals\)</span> at some time, i.e., <span class="math display">\[
  J(π) = \PR^{π}\left( \max_{0 \le t \le T} h_t(S_t) \ge α \right).
\]</span></p>
<p>Show that the above cost can be put in an additive form that would enable us to use the theory developed in the class to tackle this setup.</p></li>
</ol>


<p class="categories">
This entry 

 was last updated on 17 Jan 2022</p>



    </div>
  </body>
</html>


