<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<head>
  <meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="author" content="Aditya Mahajan" />
  <meta name="title" content="ECSE 506: Stochastic Control and Decision Theory" />
  <title>ECSE 506: Stochastic Control and Decision Theory</title>
  

  <link rel="stylesheet" href="https://adityam.github.io/stochastic-control//css/style.css" type="text/css" /><script type="text/javascript"
    src="https://adityam.github.io/stochastic-control/js/mathjax-local.js" defer>
  </script>
  <script type="text/javascript" id="MathJax-script" defer
    src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-svg.js">
  </script>

  <script type="module" defer
    src="//instant.page/3.0.0"
    integrity="sha384-OeDn4XE77tdHo8pGtE1apMPmAipjoxUQ++eeJa6EtJCfHlvijigWiJpD7VDPWXV1">
  </script>

  <script>var clicky_site_ids = clicky_site_ids || []; clicky_site_ids.push(101261731);</script>
  <script async src="//static.getclicky.com/js"></script>

</head>
<body>
<div id="content">
<div class="title">
  <h1>ECSE 506: Stochastic Control and Decision Theory </h1>
  <h2><a href="http://www.cim.mcgill.ca/~adityam/">Aditya Mahajan</a> <br/>
      Winter 2022
  </h2>
  <h3><a href="https://adityam.github.io/stochastic-control/ ">About</a>
	&nbsp;<small><small>|</small></small>&nbsp;
    <a href="https://adityam.github.io/stochastic-control//lectures">Lectures</a></span>
	&nbsp;<small><small>|</small></small>&nbsp;
    <a href="https://adityam.github.io/stochastic-control//notes">Notes</a></span>
	&nbsp;<small><small>|</small></small>&nbsp;
    <a href="https://adityam.github.io/stochastic-control//coursework">Coursework</a>
</h3>
</div>



<div class="h1-title">Assignment 8</div>

<ol type="1">
<li><p>Exercise 1 of notes on <a href="../../pomdp/pomdp#exercises">POMDPs</a></p></li>
<li><p>Exercise 1 of notes on <a href="../../pomdp/hypothesis-testing#exercises">Sequential hypothesis testin</a></p></li>
<li><p>Consider a Markov chain <span class="math inline">\(\{X_t, t= 1, 2, \dots \}\)</span> with state space <span class="math inline">\(\mathcal X = \{0, 1\}\)</span> and transition matrix shown below.</p>
<p><img src="markov.png" /></p>
<p>The state <span class="math inline">\(0\)</span> denotes a <em>safe state</em> while the state <span class="math inline">\(1\)</span> denotes a <em>faulty state</em>. Assume that <span class="math inline">\(\PR(X_1 = 0) = q_0\)</span>.</p>
<p>A decision makers observes the state with noise as follows <span class="math display">\[ Y_t = h(X_t,
 N_t), \quad t= 1, 2, \dots\]</span> where <span class="math inline">\(\{N_t\} _ {t=1}^{T}\)</span> is the observation noise process and <span class="math inline">\(h\)</span> is a known function. It is assumed that all primitive random variables are mututally independent.</p>
<p>Let <span class="math inline">\(\theta\)</span> denote the (random) time at which the Markov chain jumps from state <span class="math inline">\(0\)</span> to state <span class="math inline">\(1\)</span> (with <span class="math inline">\(\theta = 0\)</span> is the Markov chain starts in state <span class="math inline">\(1\)</span>).</p>
<p>At each time step, the decision maker has two alternatives: stop and declare that a fault has occured (denoted by <span class="math inline">\(u_t = 1\)</span>) or take another measurement (denoted by <span class="math inline">\(u_t = 0\)</span>). The system runs for a finite horizon <span class="math inline">\(T\)</span>. Let <span class="math inline">\(\tau\)</span> denote the (random) time the decision maker declares that the jump has occured (if the decision maker does not declare to stop, then <span class="math inline">\(\tau\)</span> is assumed to be <span class="math inline">\(T+1\)</span>).</p>
<p>The objective is to determine the strategy of the decision maker that minimizes the exptected cost <span class="math display">\[ \EXP^{\bf g} [ \IND(X _ \tau = 0) \IND
 (\tau &lt; T + 1) + k \sum_{t=0}^{\tau - 1} \IND(X_t = 1) ]\]</span> where <span class="math inline">\(k\)</span> is a poistive constant, and <span class="math inline">\(\IND(\cdot)\)</span> is an indicator function.</p>
<ol type="a">
<li><p>Show that the above model is a POMDP. Identify an information state, and write the dynamic programming decomposition.</p></li>
<li><p>Show that an optimal strategy <span class="math inline">\(g\)</span> is of the following form:</p>
<ul>
<li>If <span class="math inline">\(\PR(\theta &gt; t | Y _ {1:t} ) &gt; \ell_t\)</span>, continue;</li>
<li>If <span class="math inline">\(\PR(\theta &gt; t | Y _ {1:t} ) \le\ell_t\)</span>, stop and declare that the fault as occured.</li>
</ul></li>
<li><p>Specify the equations that determine the thresholds <span class="math inline">\(\ell_t\)</span>, <span class="math inline">\(t=1,\dots,T\)</span>.</p></li>
</ol></li>
</ol>


<p class="categories">
This entry 

 was last updated on 16 Dec 2021</p>



    </div>
  </body>
</html>


