---
title: Martingales
---

Consider a probability space $(Ω, \mathcal F, P)$. We define a few key terms:

1. A **filteration** $\{\mathcal F_t\}_{t \ge 1}$ is an increasing familty of sub-sigma-fields of $\mathcal F$, i.e., for any $t_1 < t_2$, $\mathcal F_{t_1} \subseteq \mathcal F_{t_2}$. 

2. The most common way of generating a filtration is through a stochastic process. In particular, given a stochastic process $\{X_t\}_{t \ge 1}$, the filtration $\{\mathcal F_t\}_{t \ge 1}$ given by
   $$
     \mathcal F_t = σ(X_{1:t}), \quad t \ge 1
   $$
   is called the **filtration generated by $\{X_t\}_{t \ge 1}$** or the **natural filtration** of $\{X_t\}_{t \ge 1}$. 

3. A family of integrable random variables $\{X_t\}_{t \ge 1}$ is said to be **adapted** with respect to the filtration $\{\mathcal F_t\}_{t \ge 1}$ if $X_t$ is $\mathcal F_t$-measurable for each $t$.

4. A family of integrable random variables $\{X_t\}_{t \ge 1}$ is said to be **predictable** with respect to the filtration $\{\mathcal F_t\}_{t \ge 1}$ if $X_t$ is $\mathcal F_{t-1}$-measurable for each $t$.

:::{.callout-tip}
### Intuition
Intuitively, a process $\{X_t\}_{t \ge 1}$ is adapted with respect to the filtration $\{\mathcal F_t\}_{t \ge 1}$ the value of $X_t$ is fully known at time $t$ based on the information $\mathcal F_t$.
:::

:::{#def-martingale}
A family of integrable random vabiables $\{X_t\}_{t \ge 1}$ adapted to a filtration $\{\mathcal F_t\}_{t \ge 1}$ is said to be a **martingale** if
\begin{equation}\label{eq:martingale}
  X_s = \EXP[X_{t} \mid \mathcal F_s], \quad \forall s < t. 
\end{equation}
:::

:::{.callout-tip}
### Intuition
Property \\eqref{eq:martingale} has the interpretation that $X_s$ is the best predictor for $X_t$ based on the information available at time $s$. 
:::

Several desirable properties of martingales are shared by families of random variables for which \\eqref{eq:martingale} is replaced by an inequality. 

1. A family of integrable random variables $\{X_t\}_{t \ge 1}$ adapted to a filtration $\{\mathcal F_t\}_{t \ge 1}$ is said to be a **submartingale** if 
  \begin{equation}\label{eq:submartingale}
    X_s \le \EXP[X_{t} \mid \mathcal F_s], \quad \forall s < t. 
  \end{equation}

2. A family of integrable random variables $\{X_t\}_{t \ge 1}$ adapted to a filtration $\{\mathcal F_t\}_{t \ge 1}$ is said to be a **supermartingale** if 
  \begin{equation}\label{eq:supermartingale}
    X_s \ge \EXP[X_{t} \mid \mathcal F_s], \quad \forall s < t. 
  \end{equation}

## Examples

1. **Martingales generalize the theory of sums of independent random variables.**
   Let $ξ_1, ξ_2, \dots$ be indepdent, integrable random variables with $\EXP[ξ_t] = 0$ for $t \ge 1$. Define $X_0 = 0$ and $X_t = ξ_1 + \dots + ξ_t$. The sequence $\{X_t\}_{t \ge 1}$ is a martingale with respect to the natural filtration. 

2. Let $\{X_t\}_{t \ge 1}$ be martingale and let $f$ be a convex function for which each $f(X_t)$ is integrable. Then, a direct application of Jensen's inequality implies that $\{f(X_t)\}_{t \ge 1}$ is a submartingale.

3. Let $\{X_t\}_{t \ge 1}$ be **sub**martingale and let $f$ be a convex **and increasing** function for which each $f(X_t)$ is integrable. Then, $\{f(X_t)\}_{t \ge 1}$ is a submartingale because
   $$
      \EXP[ f(X_{t+1}) \mid \mathcal F_t] 
      \ge
      f( \EXP[ X_{t+1} \mid \mathcal F_t ])
      \ge
      f(X_t)
   $$
   where the first inequality follows from Jensen's inequality and the second from the fact that $\{X_t\}_{t \ge 1}$ is a sub-martingale and $f$ is increasing.

4. If $\{X_t\}_{t \ge 1}$ is a martingale and each $X_t$ is square integrable, then $\{X_t^2\}_{t \ge 1}$ is a submartingale.

5. If $\{X_t\}_{t \ge 1}$ is a submartingale then $\{X_t^{+}\}_{t \ge 1}$ is also a submartingale.

6. Suppose $X$ is an integrable random variable and $\{\mathcal F_t\}_{t \ge 1}$ is a filtration. Define $X_t \coloneqq \EXP[X \mid \mathcal F_t]$. Then $\{X_t\}_{t \ge 1}$ is a martingale with respect to the filtration (follows from the smoothing property of conditional expectations).

7. A martingale $\{X_t\}_{t \ge 1}$ may be written as a sum of increments: $X_t = X_0 + ξ_1 + \dots + ξ_t$. The increments $\{ξ_t\}_{t \ge 1}$ are called **martingale differences**. Each $ξ_t$ is integrable and $\EXP[ξ_t \mid \mathcal F_{t-1}] = 0$ for all $t$.

:::{#thm-doob-decomposition}
### Doob's decomposition
  Every sequence $\{X_t\}_{t \ge 1}$ of integrable random variables adapted to a filtration $\{\mathcal F_t\}_{t \ge 1}$ can be decomposed into a sum of a martingale and an adapted process, i.e., 
  $$
    X_t = M_t + A_t
  $$
  where $\{M_t\}_{t \ge 1}$ is a martingale and $\{A_t\}_{t \ge 1}$ is a predictable sequence. 

:::

## Convergence of nonnegative supermartingales

We state certain properties of nonnegative supermartingales without proof. This material is taken from @Neveu1975.

1. **Maximal inequality for nonnegative supermartingales.**
For every nonnegative supermartingale $\{X_t\}_{t \ge 1}$, the random variable $\sup_{t \ge 1} X_t$ is a.s.\ finite on the set $\{X_0 < ∞\}$ and, more precisely, satisfies the following inequality:
$$
  \PR\Bigl( \sup_{t \ge 1} X_t \ge a \Bigm| \mathcal F_t \Bigr)
  \le
  \max\biggl( \frac{X_0}{a}, 1 \biggr)
$$
2. **Switching principle for supermartingales.** Given two nonnegative supermartingales $\{X^{(i)}_t\}_{t \ge 1}$, $i \in \{1, 2\}$, and a stopping time $τ$ such that $X^{(1)}_{τ} \ge X^{(2)}_{τ}$ on $\{τ < ∞\}$, the formula
   $$
    X_t(ω) = \begin{cases}
    X^{(1)}_t(ω), & \text{if $t < τ(ω)$} \\
    X^{(2)}_t(ω), & \text{if $t \ge τ(ω)$}
    \end{cases}
    $$
    defines a new nonnegative supermartingale.

3. **Supermartingale convergence theorem.** Every nonnegative supermartingale $\{X_t\}_{t \ge 1}$ converges almost surely. Furthermore, the limit $X_{∞} = \lim_{t \to ∞} X_t$ satisfies the inequality
   $$
     \EXP[ X_{∞} \mid \mathcal F_t] \le X_t.
   $$

4. A nonnegative supermartingale converges in $\mathcal L^1$ to its limit $X_{∞}$ if and only if $\EXP[X_t] \to \EXP[X_{∞}]$.

5. Let $\{X_t\}_{t \ge 1}$ be a nonnegative supermartingale. Then, for any stopping times $τ_1$ and $τ_2$, we have
   $$
    X_{τ_1} \ge \EXP[ X_{τ_2} \mid \mathcal F_{τ_1},
    \quad \text{ on } \{τ_1 \le τ_2 \}.
   $$

6. For a nonnegative supermartingale $\{X_t\}_{t \ge 1}$ and a stopping time $τ$, the sequnce $\{X_{τ \wedge t}\}_{t \ge 1}$ "stopped at the stopping time $τ$" is also a non-negative supermartingale.

The converges result continues to hold for "almost" supermartingales.

:::{#thm-almost-supermartingale}
## Almost supermartingale convergence theorem
Suppose $\{X_t\}_{t \ge 1}$, $\{β_t\}_{t \ge 1}$, $\{Y_t\}_{t \ge 1}$, $\{Z_t\}_{t \ge 1}$ are nonnegative stochastic processes adapted to some filtration $\{\mathcal F_t\}_{t \ge 1}$ that satisfy
\begin{equation}\label{eq:almost-supermartingale}
  \EXP[X_{t+1} \mid \mathcal F_t ] \le 
  (1 + β_t) X_t + Y_t - Z_t, 
  \quad t \ge 1
\end{equation}
Define the set $Ω_0$ by
$$
  Ω_0 = \biggl\{ ω : \sum_{t \ge 1} β_t(ω) < ∞ \biggr\}
  \cap
  \biggl\{ ω : \sum_{t \ge 1} Y_t(ω) < ∞ \biggr\}.
$$
Then, for all $ω \in Ω_0$, we have that

(i) $\lim_{t \to ∞} X_t(ω)$ exists and is finite
(ii) $\sum_{t \ge 1} Z_t(ω) < ∞$.
:::

## Convergence of submartingales

:::{#thm-krickeberg}
### Krickeberg decomposition
Let $\{S_t\}_{t \ge 1}$ be a submartingale for which $\sup_t \EXP[S_t^{+}] < ∞$. Then, there exists a positive martingale $\{M_t\}_{t \ge 1}$ and a positive supermartingale $\{X_t\}_{t \ge 1}$ such that $S_t = M_t - X_t$ almost sure for each $t$.
:::

:::{.callout-tip}
### Remark
The finiteness of $\sup_{t} \EXP[ S_{t}^{+}]$ is equivalent to the finiteness of $\sup_{t} \EXP[|S_t|]$ because $|S_t| = 2S_t{+} - (S_t^{+} - S_t^{-})$ and by the submartingale property, $\EXP[S_t^{+} - S_t^{-}] = \EXP[S_t]$ increases with $t$. 
:::

:::{#cor-submartingale}
  A submartingale with $\sup_{t} \EXP[S_t^{+}] < ∞$ converges almost surely to an integrable limit.
:::

## Notes {-}

The material in the introduction is taken from @Pollard2002.

@thm-almost-supermartingale is from @Robbins1971. A version of @thm-almost-supermartingale with $Z_t = 0$ is stated as Exercise II-4 of @Neveu1975.
